{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.6f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "       0_0      0_1      1_0      1_1       2_0       2_1       3_0       3_1  \\\n0 1.000000 1.000000 0.640000 0.500000 -0.240000 -0.140000 -0.460000 -0.500000   \n1 1.000000 1.000000 0.700000 0.480000  0.160000 -0.320000 -0.560000 -0.640000   \n2 1.000000 1.000000 0.780000 0.520000  0.280000 -0.180000 -0.020000 -0.500000   \n3 1.000000 1.000000 0.720000 0.340000 -0.060000 -0.480000 -0.540000 -0.720000   \n4 1.000000 1.000000 0.540000 0.500000 -0.160000 -0.300000 -0.460000 -0.500000   \n\n        4_0       4_1  ...       7_1       8_0       8_1       9_0      9_1  \\\n0 -0.060000  0.000000  ... -0.740000 -0.200000 -0.180000  0.740000 0.660000   \n1 -0.520000 -0.280000  ... -0.380000 -0.480000 -0.040000 -0.800000 0.700000   \n2  0.060000  0.060000  ... -0.900000  0.400000 -0.520000  0.040000 0.280000   \n3 -0.180000 -0.080000  ...  0.060000 -0.940000  0.860000 -0.580000 0.880000   \n4 -0.320000 -0.240000  ... -0.500000 -0.540000 -0.020000  0.020000 0.800000   \n\n    decay_0  decay_1      W_0      W_1      J_0  \n0 -0.022797 0.875160 3.356484 3.394981 4.338458  \n1 -0.305637 0.199690 2.780008 3.992448 3.203716  \n2  1.312289 1.518685 0.739418 2.991809 4.583140  \n3 -0.060531 0.683886 2.639658 4.466349 3.975715  \n4  0.897697 0.344014 3.249551 3.779017 3.552987  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_0</th>\n      <th>0_1</th>\n      <th>1_0</th>\n      <th>1_1</th>\n      <th>2_0</th>\n      <th>2_1</th>\n      <th>3_0</th>\n      <th>3_1</th>\n      <th>4_0</th>\n      <th>4_1</th>\n      <th>...</th>\n      <th>7_1</th>\n      <th>8_0</th>\n      <th>8_1</th>\n      <th>9_0</th>\n      <th>9_1</th>\n      <th>decay_0</th>\n      <th>decay_1</th>\n      <th>W_0</th>\n      <th>W_1</th>\n      <th>J_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.640000</td>\n      <td>0.500000</td>\n      <td>-0.240000</td>\n      <td>-0.140000</td>\n      <td>-0.460000</td>\n      <td>-0.500000</td>\n      <td>-0.060000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-0.740000</td>\n      <td>-0.200000</td>\n      <td>-0.180000</td>\n      <td>0.740000</td>\n      <td>0.660000</td>\n      <td>-0.022797</td>\n      <td>0.875160</td>\n      <td>3.356484</td>\n      <td>3.394981</td>\n      <td>4.338458</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.700000</td>\n      <td>0.480000</td>\n      <td>0.160000</td>\n      <td>-0.320000</td>\n      <td>-0.560000</td>\n      <td>-0.640000</td>\n      <td>-0.520000</td>\n      <td>-0.280000</td>\n      <td>...</td>\n      <td>-0.380000</td>\n      <td>-0.480000</td>\n      <td>-0.040000</td>\n      <td>-0.800000</td>\n      <td>0.700000</td>\n      <td>-0.305637</td>\n      <td>0.199690</td>\n      <td>2.780008</td>\n      <td>3.992448</td>\n      <td>3.203716</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.780000</td>\n      <td>0.520000</td>\n      <td>0.280000</td>\n      <td>-0.180000</td>\n      <td>-0.020000</td>\n      <td>-0.500000</td>\n      <td>0.060000</td>\n      <td>0.060000</td>\n      <td>...</td>\n      <td>-0.900000</td>\n      <td>0.400000</td>\n      <td>-0.520000</td>\n      <td>0.040000</td>\n      <td>0.280000</td>\n      <td>1.312289</td>\n      <td>1.518685</td>\n      <td>0.739418</td>\n      <td>2.991809</td>\n      <td>4.583140</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.720000</td>\n      <td>0.340000</td>\n      <td>-0.060000</td>\n      <td>-0.480000</td>\n      <td>-0.540000</td>\n      <td>-0.720000</td>\n      <td>-0.180000</td>\n      <td>-0.080000</td>\n      <td>...</td>\n      <td>0.060000</td>\n      <td>-0.940000</td>\n      <td>0.860000</td>\n      <td>-0.580000</td>\n      <td>0.880000</td>\n      <td>-0.060531</td>\n      <td>0.683886</td>\n      <td>2.639658</td>\n      <td>4.466349</td>\n      <td>3.975715</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.540000</td>\n      <td>0.500000</td>\n      <td>-0.160000</td>\n      <td>-0.300000</td>\n      <td>-0.460000</td>\n      <td>-0.500000</td>\n      <td>-0.320000</td>\n      <td>-0.240000</td>\n      <td>...</td>\n      <td>-0.500000</td>\n      <td>-0.540000</td>\n      <td>-0.020000</td>\n      <td>0.020000</td>\n      <td>0.800000</td>\n      <td>0.897697</td>\n      <td>0.344014</td>\n      <td>3.249551</td>\n      <td>3.779017</td>\n      <td>3.552987</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(filepath_or_buffer=\"Z_values_10000.csv\")\n",
    "test_df = pd.read_csv(filepath_or_buffer=\"Z_values_100.csv\")\n",
    "validation_df = pd.read_csv(filepath_or_buffer=\"Z_values_100.csv\")\n",
    "\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.regularizers import L2\n",
    "import re\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "keys = train_df.keys()\n",
    "keys.drop(['W_0', 'W_1', 'J_0'])\n",
    "inputs = {key:tf.keras.layers.Input(shape=(1,), name=key) for key in keys}\n",
    "concatenated_inputs = tf.keras.layers.concatenate(inputs.values())\n",
    "# Prepare data for training\n",
    "train_features = {key: train_df[key] for key in inputs}\n",
    "train_labels = train_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "# Similarly prepare test and validation data\n",
    "test_features = {key: test_df[key] for key in inputs}\n",
    "test_labels = test_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "validation_features = {key: validation_df[key] for key in inputs}\n",
    "validation_labels = validation_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "#kernel_regularizer=L2(0.001)\n",
    "hidden_layer_1 = tf.keras.layers.Dense(10, activation='relu')(concatenated_inputs)\n",
    "hidden_layer_2 = tf.keras.layers.Dense(10, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = tf.keras.layers.Dense(10, activation='relu')(hidden_layer_2)\n",
    "hidden_layer_4 = tf.keras.layers.Dense(10, activation='relu')(hidden_layer_3)\n",
    "\n",
    "output = tf.keras.layers.Dense(3)(hidden_layer_4) #TODO magic number\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 11.1601 - val_loss: 11.2214\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 11.0801 - val_loss: 11.1429\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 11.0033 - val_loss: 11.0669\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 10.9287 - val_loss: 10.9938\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 10.8569 - val_loss: 10.9234\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.7876 - val_loss: 10.8556\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 10.7212 - val_loss: 10.7901\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.6567 - val_loss: 10.7270\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 10.5950 - val_loss: 10.6659\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 10.5351 - val_loss: 10.6069\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 10.4776 - val_loss: 10.5501\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.4222 - val_loss: 10.4951\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.3683 - val_loss: 10.4421\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 10.3164 - val_loss: 10.3908\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.2662 - val_loss: 10.3414\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.2180 - val_loss: 10.2937\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 10.1714 - val_loss: 10.2480\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.1269 - val_loss: 10.2041\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 10.0842 - val_loss: 10.1621\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.0433 - val_loss: 10.1221\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.0042 - val_loss: 10.0840\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.9669 - val_loss: 10.0477\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.9313 - val_loss: 10.0133\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.8976 - val_loss: 9.9809\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.8657 - val_loss: 9.9500\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.8353 - val_loss: 9.9206\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.8064 - val_loss: 9.8926\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.7786 - val_loss: 9.8657\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.7521 - val_loss: 9.8398\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.7264 - val_loss: 9.8148\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.7018 - val_loss: 9.7905\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.6777 - val_loss: 9.7669\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.6541 - val_loss: 9.7437\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.6308 - val_loss: 9.7206\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.6077 - val_loss: 9.6977\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.5848 - val_loss: 9.6748\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.5619 - val_loss: 9.6520\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.5389 - val_loss: 9.6292\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.5158 - val_loss: 9.6063\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.4924 - val_loss: 9.5830\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.4686 - val_loss: 9.5592\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.4444 - val_loss: 9.5349\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.4195 - val_loss: 9.5099\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.3939 - val_loss: 9.4841\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.3675 - val_loss: 9.4573\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.3398 - val_loss: 9.4295\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.3112 - val_loss: 9.4003\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.2810 - val_loss: 9.3697\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.2493 - val_loss: 9.3373\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.2158 - val_loss: 9.3032\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.1804 - val_loss: 9.2670\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.1427 - val_loss: 9.2285\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.1026 - val_loss: 9.1876\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.0603 - val_loss: 9.1443\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.0156 - val_loss: 9.0985\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.9681 - val_loss: 9.0503\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.9184 - val_loss: 8.9999\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.8667 - val_loss: 8.9475\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.8130 - val_loss: 8.8934\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 8.7576 - val_loss: 8.8377\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.7006 - val_loss: 8.7803\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.6419 - val_loss: 8.7216\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.5819 - val_loss: 8.6613\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 8.5202 - val_loss: 8.5997\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.4572 - val_loss: 8.5366\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.3927 - val_loss: 8.4721\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.3269 - val_loss: 8.4060\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.2595 - val_loss: 8.3385\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.1910 - val_loss: 8.2695\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 8.1204 - val_loss: 8.1990\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.0487 - val_loss: 8.1268\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.9752 - val_loss: 8.0530\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.9003 - val_loss: 7.9775\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.8237 - val_loss: 7.9003\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.7453 - val_loss: 7.8213\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.6651 - val_loss: 7.7407\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.5832 - val_loss: 7.6585\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 7.4996 - val_loss: 7.5744\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.4144 - val_loss: 7.4885\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.3273 - val_loss: 7.4011\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.2386 - val_loss: 7.3124\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.1486 - val_loss: 7.2223\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 7.0575 - val_loss: 7.1310\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.9649 - val_loss: 7.0387\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.8715 - val_loss: 6.9460\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.7778 - val_loss: 6.8529\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.6841 - val_loss: 6.7604\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.5909 - val_loss: 6.6691\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.4993 - val_loss: 6.5792\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.4091 - val_loss: 6.4914\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.3212 - val_loss: 6.4060\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 6.2359 - val_loss: 6.3236\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.1538 - val_loss: 6.2440\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.0748 - val_loss: 6.1675\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.9986 - val_loss: 6.0943\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.9260 - val_loss: 6.0242\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.8565 - val_loss: 5.9572\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.7903 - val_loss: 5.8933\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.7271 - val_loss: 5.8322\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.6667 - val_loss: 5.7736\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.6086 - val_loss: 5.7176\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.5530 - val_loss: 5.6637\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 5.4998 - val_loss: 5.6117\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.4483 - val_loss: 5.5615\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.3985 - val_loss: 5.5129\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.3506 - val_loss: 5.4657\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.3042 - val_loss: 5.4200\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.2590 - val_loss: 5.3755\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.2152 - val_loss: 5.3321\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.1726 - val_loss: 5.2899\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.1310 - val_loss: 5.2486\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0904 - val_loss: 5.2083\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0506 - val_loss: 5.1689\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.0119 - val_loss: 5.1303\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4.9737 - val_loss: 5.0924\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.9364 - val_loss: 5.0552\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.8999 - val_loss: 5.0185\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.8639 - val_loss: 4.9826\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.8285 - val_loss: 4.9472\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.7937 - val_loss: 4.9124\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.7595 - val_loss: 4.8781\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.7257 - val_loss: 4.8444\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.6927 - val_loss: 4.8110\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.6598 - val_loss: 4.7782\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.6276 - val_loss: 4.7458\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.5958 - val_loss: 4.7139\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.5643 - val_loss: 4.6824\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.5335 - val_loss: 4.6513\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.5029 - val_loss: 4.6206\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.4727 - val_loss: 4.5903\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.4429 - val_loss: 4.5603\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.4134 - val_loss: 4.5307\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3844 - val_loss: 4.5015\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3557 - val_loss: 4.4726\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.3273 - val_loss: 4.4440\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.2992 - val_loss: 4.4157\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 4.2716 - val_loss: 4.3878\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.2441 - val_loss: 4.3601\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.2169 - val_loss: 4.3328\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.1901 - val_loss: 4.3058\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.1636 - val_loss: 4.2790\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.1373 - val_loss: 4.2526\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.1113 - val_loss: 4.2263\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0855 - val_loss: 4.2003\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0600 - val_loss: 4.1747\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0348 - val_loss: 4.1492\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 4.0098 - val_loss: 4.1240\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.9850 - val_loss: 4.0991\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.9604 - val_loss: 4.0744\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.9361 - val_loss: 4.0499\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.9121 - val_loss: 4.0255\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.8882 - val_loss: 4.0015\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.8646 - val_loss: 3.9776\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.8410 - val_loss: 3.9539\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.8178 - val_loss: 3.9305\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7947 - val_loss: 3.9071\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7718 - val_loss: 3.8841\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7491 - val_loss: 3.8612\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.7265 - val_loss: 3.8385\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.7042 - val_loss: 3.8159\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.6821 - val_loss: 3.7935\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.6600 - val_loss: 3.7713\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.6382 - val_loss: 3.7493\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.6164 - val_loss: 3.7274\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.5949 - val_loss: 3.7056\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.5735 - val_loss: 3.6840\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.5523 - val_loss: 3.6626\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.5311 - val_loss: 3.6413\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.5102 - val_loss: 3.6201\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4893 - val_loss: 3.5991\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4686 - val_loss: 3.5782\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4481 - val_loss: 3.5574\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4275 - val_loss: 3.5368\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.4072 - val_loss: 3.5163\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3870 - val_loss: 3.4959\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3668 - val_loss: 3.4756\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3469 - val_loss: 3.4554\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.3270 - val_loss: 3.4353\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.3072 - val_loss: 3.4154\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.2875 - val_loss: 3.3955\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.2679 - val_loss: 3.3757\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.2484 - val_loss: 3.3560\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.2290 - val_loss: 3.3364\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.2097 - val_loss: 3.3169\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.1905 - val_loss: 3.2975\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.1713 - val_loss: 3.2782\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 3.1522 - val_loss: 3.2590\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.1333 - val_loss: 3.2398\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.1144 - val_loss: 3.2207\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0956 - val_loss: 3.2017\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0768 - val_loss: 3.1827\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0581 - val_loss: 3.1638\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0395 - val_loss: 3.1450\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0210 - val_loss: 3.1263\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.0024 - val_loss: 3.1076\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.9841 - val_loss: 3.0890\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.9657 - val_loss: 3.0704\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.9474 - val_loss: 3.0519\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.9292 - val_loss: 3.0335\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.9110 - val_loss: 3.0151\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.8928 - val_loss: 2.9967\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.8748 - val_loss: 2.9784\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.8567 - val_loss: 2.9602\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.8387 - val_loss: 2.9420\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.8207 - val_loss: 2.9238\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.8027 - val_loss: 2.9056\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.7847 - val_loss: 2.8873\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.7666 - val_loss: 2.8689\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7484 - val_loss: 2.8504\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.7301 - val_loss: 2.8317\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.7114 - val_loss: 2.8127\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6926 - val_loss: 2.7934\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6736 - val_loss: 2.7739\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6544 - val_loss: 2.7542\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6349 - val_loss: 2.7342\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.6152 - val_loss: 2.7141\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5954 - val_loss: 2.6939\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5755 - val_loss: 2.6734\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5553 - val_loss: 2.6529\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5351 - val_loss: 2.6323\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.5149 - val_loss: 2.6116\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4946 - val_loss: 2.5908\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4742 - val_loss: 2.5700\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4537 - val_loss: 2.5492\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.4333 - val_loss: 2.5283\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.4128 - val_loss: 2.5073\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3923 - val_loss: 2.4863\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3716 - val_loss: 2.4654\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3511 - val_loss: 2.4444\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.3306 - val_loss: 2.4233\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.3099 - val_loss: 2.4023\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2894 - val_loss: 2.3812\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2687 - val_loss: 2.3602\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2481 - val_loss: 2.3391\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2276 - val_loss: 2.3181\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.2069 - val_loss: 2.2970\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1864 - val_loss: 2.2760\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1658 - val_loss: 2.2549\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1452 - val_loss: 2.2340\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1247 - val_loss: 2.2130\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.1042 - val_loss: 2.1919\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.0837 - val_loss: 2.1710\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0633 - val_loss: 2.1500\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0429 - val_loss: 2.1291\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0224 - val_loss: 2.1082\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.0021 - val_loss: 2.0874\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.9818 - val_loss: 2.0667\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.9616 - val_loss: 2.0459\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.9414 - val_loss: 2.0252\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.9212 - val_loss: 2.0045\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.9011 - val_loss: 1.9839\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8811 - val_loss: 1.9634\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8611 - val_loss: 1.9430\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8413 - val_loss: 1.9226\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.8214 - val_loss: 1.9022\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.8017 - val_loss: 1.8820\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.7821 - val_loss: 1.8618\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.7625 - val_loss: 1.8417\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.7430 - val_loss: 1.8217\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.7237 - val_loss: 1.8018\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.7043 - val_loss: 1.7820\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6851 - val_loss: 1.7623\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6660 - val_loss: 1.7427\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.6471 - val_loss: 1.7232\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.6282 - val_loss: 1.7038\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.6094 - val_loss: 1.6845\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.5908 - val_loss: 1.6654\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.5723 - val_loss: 1.6464\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5539 - val_loss: 1.6275\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.5357 - val_loss: 1.6087\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.5176 - val_loss: 1.5900\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4995 - val_loss: 1.5715\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4817 - val_loss: 1.5532\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.4640 - val_loss: 1.5349\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4465 - val_loss: 1.5169\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.4290 - val_loss: 1.4990\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.4118 - val_loss: 1.4812\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3948 - val_loss: 1.4636\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3778 - val_loss: 1.4462\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.3610 - val_loss: 1.4289\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3445 - val_loss: 1.4119\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.3281 - val_loss: 1.3949\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3118 - val_loss: 1.3782\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.2957 - val_loss: 1.3617\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.2799 - val_loss: 1.3453\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.2642 - val_loss: 1.3291\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.2487 - val_loss: 1.3131\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.2334 - val_loss: 1.2973\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.2183 - val_loss: 1.2817\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.2034 - val_loss: 1.2664\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.1888 - val_loss: 1.2512\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.1743 - val_loss: 1.2363\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1602 - val_loss: 1.2216\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.1462 - val_loss: 1.2073\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1325 - val_loss: 1.1933\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1193 - val_loss: 1.1797\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.1064 - val_loss: 1.1664\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0939 - val_loss: 1.1537\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0819 - val_loss: 1.1415\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0704 - val_loss: 1.1299\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0593 - val_loss: 1.1189\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0488 - val_loss: 1.1085\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0390 - val_loss: 1.0986\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0296 - val_loss: 1.0892\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0207 - val_loss: 1.0804\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0124 - val_loss: 1.0720\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0043 - val_loss: 1.0641\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9968 - val_loss: 1.0565\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9896 - val_loss: 1.0493\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9827 - val_loss: 1.0423\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9760 - val_loss: 1.0356\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9697 - val_loss: 1.0291\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9634 - val_loss: 1.0228\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9574 - val_loss: 1.0168\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9515 - val_loss: 1.0108\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9458 - val_loss: 1.0050\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9402 - val_loss: 0.9993\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9348 - val_loss: 0.9938\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9294 - val_loss: 0.9884\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9242 - val_loss: 0.9830\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9191 - val_loss: 0.9777\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9140 - val_loss: 0.9726\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9091 - val_loss: 0.9675\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9042 - val_loss: 0.9626\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8995 - val_loss: 0.9576\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8947 - val_loss: 0.9528\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8901 - val_loss: 0.9481\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8856 - val_loss: 0.9434\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8811 - val_loss: 0.9387\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8767 - val_loss: 0.9342\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8724 - val_loss: 0.9297\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8681 - val_loss: 0.9253\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8639 - val_loss: 0.9209\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8598 - val_loss: 0.9166\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8557 - val_loss: 0.9123\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8517 - val_loss: 0.9081\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8477 - val_loss: 0.9040\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8438 - val_loss: 0.8999\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8399 - val_loss: 0.8959\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8361 - val_loss: 0.8920\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8324 - val_loss: 0.8880\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8287 - val_loss: 0.8842\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8251 - val_loss: 0.8804\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8215 - val_loss: 0.8766\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8180 - val_loss: 0.8729\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8145 - val_loss: 0.8693\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8111 - val_loss: 0.8656\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8077 - val_loss: 0.8621\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8044 - val_loss: 0.8586\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8011 - val_loss: 0.8551\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7979 - val_loss: 0.8517\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7947 - val_loss: 0.8484\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7916 - val_loss: 0.8450\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7885 - val_loss: 0.8418\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7854 - val_loss: 0.8386\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7825 - val_loss: 0.8354\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7795 - val_loss: 0.8323\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7766 - val_loss: 0.8292\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7737 - val_loss: 0.8261\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7709 - val_loss: 0.8231\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7681 - val_loss: 0.8202\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7654 - val_loss: 0.8172\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7627 - val_loss: 0.8144\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7600 - val_loss: 0.8115\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7574 - val_loss: 0.8087\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7548 - val_loss: 0.8060\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7523 - val_loss: 0.8033\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7498 - val_loss: 0.8006\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7473 - val_loss: 0.7980\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7449 - val_loss: 0.7954\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7425 - val_loss: 0.7928\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7401 - val_loss: 0.7903\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7378 - val_loss: 0.7878\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7355 - val_loss: 0.7853\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7333 - val_loss: 0.7829\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7311 - val_loss: 0.7805\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7289 - val_loss: 0.7782\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7267 - val_loss: 0.7759\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7246 - val_loss: 0.7736\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7225 - val_loss: 0.7714\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7204 - val_loss: 0.7692\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7184 - val_loss: 0.7670\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7164 - val_loss: 0.7648\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7144 - val_loss: 0.7627\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7125 - val_loss: 0.7606\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7106 - val_loss: 0.7585\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7087 - val_loss: 0.7565\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7068 - val_loss: 0.7545\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7050 - val_loss: 0.7525\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7032 - val_loss: 0.7506\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7014 - val_loss: 0.7487\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6997 - val_loss: 0.7468\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6979 - val_loss: 0.7449\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6962 - val_loss: 0.7431\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6946 - val_loss: 0.7412\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6929 - val_loss: 0.7394\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6913 - val_loss: 0.7377\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6897 - val_loss: 0.7359\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6881 - val_loss: 0.7342\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6865 - val_loss: 0.7325\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6850 - val_loss: 0.7308\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6835 - val_loss: 0.7291\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6820 - val_loss: 0.7275\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6805 - val_loss: 0.7259\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6790 - val_loss: 0.7243\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6776 - val_loss: 0.7227\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6762 - val_loss: 0.7212\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6748 - val_loss: 0.7196\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6734 - val_loss: 0.7181\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6720 - val_loss: 0.7166\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6706 - val_loss: 0.7151\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6693 - val_loss: 0.7137\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6680 - val_loss: 0.7122\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6667 - val_loss: 0.7108\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6654 - val_loss: 0.7094\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6641 - val_loss: 0.7080\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6628 - val_loss: 0.7066\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6616 - val_loss: 0.7052\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6604 - val_loss: 0.7039\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6591 - val_loss: 0.7025\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6579 - val_loss: 0.7012\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6567 - val_loss: 0.6999\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6555 - val_loss: 0.6986\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6544 - val_loss: 0.6973\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6532 - val_loss: 0.6960\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6521 - val_loss: 0.6947\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6509 - val_loss: 0.6935\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6498 - val_loss: 0.6922\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6487 - val_loss: 0.6910\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6475 - val_loss: 0.6898\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6464 - val_loss: 0.6885\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6453 - val_loss: 0.6873\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6442 - val_loss: 0.6861\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6432 - val_loss: 0.6850\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6421 - val_loss: 0.6838\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6410 - val_loss: 0.6826\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6399 - val_loss: 0.6814\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6389 - val_loss: 0.6803\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6379 - val_loss: 0.6791\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6368 - val_loss: 0.6780\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6358 - val_loss: 0.6768\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6347 - val_loss: 0.6757\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6337 - val_loss: 0.6745\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6327 - val_loss: 0.6734\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6317 - val_loss: 0.6723\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6306 - val_loss: 0.6712\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6296 - val_loss: 0.6701\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6286 - val_loss: 0.6690\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6276 - val_loss: 0.6679\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6266 - val_loss: 0.6668\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6256 - val_loss: 0.6657\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6246 - val_loss: 0.6646\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6236 - val_loss: 0.6635\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6226 - val_loss: 0.6624\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6216 - val_loss: 0.6613\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6206 - val_loss: 0.6603\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6196 - val_loss: 0.6592\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6186 - val_loss: 0.6581\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6176 - val_loss: 0.6570\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6166 - val_loss: 0.6559\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6156 - val_loss: 0.6549\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6146 - val_loss: 0.6538\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6137 - val_loss: 0.6527\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6127 - val_loss: 0.6516\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6117 - val_loss: 0.6506\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6107 - val_loss: 0.6495\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6097 - val_loss: 0.6484\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6087 - val_loss: 0.6473\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6077 - val_loss: 0.6463\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6067 - val_loss: 0.6452\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6057 - val_loss: 0.6441\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6047 - val_loss: 0.6430\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6037 - val_loss: 0.6419\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6027 - val_loss: 0.6409\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6017 - val_loss: 0.6398\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6007 - val_loss: 0.6387\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5997 - val_loss: 0.6376\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5987 - val_loss: 0.6365\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5976 - val_loss: 0.6354\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5966 - val_loss: 0.6343\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5956 - val_loss: 0.6332\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5946 - val_loss: 0.6321\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5936 - val_loss: 0.6310\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5925 - val_loss: 0.6299\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5915 - val_loss: 0.6288\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5905 - val_loss: 0.6277\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5894 - val_loss: 0.6266\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5884 - val_loss: 0.6254\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5873 - val_loss: 0.6243\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5863 - val_loss: 0.6232\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5852 - val_loss: 0.6220\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5841 - val_loss: 0.6209\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5831 - val_loss: 0.6198\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5820 - val_loss: 0.6186\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5809 - val_loss: 0.6175\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5798 - val_loss: 0.6163\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5787 - val_loss: 0.6152\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5776 - val_loss: 0.6140\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5766 - val_loss: 0.6128\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5754 - val_loss: 0.6116\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5743 - val_loss: 0.6104\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5732 - val_loss: 0.6093\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5721 - val_loss: 0.6081\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5710 - val_loss: 0.6069\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5699 - val_loss: 0.6057\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5687 - val_loss: 0.6045\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5676 - val_loss: 0.6032\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5664 - val_loss: 0.6020\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5653 - val_loss: 0.6008\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5641 - val_loss: 0.5996\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5630 - val_loss: 0.5984\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5618 - val_loss: 0.5971\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5606 - val_loss: 0.5959\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5595 - val_loss: 0.5946\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5583 - val_loss: 0.5934\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5571 - val_loss: 0.5921\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5559 - val_loss: 0.5908\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5547 - val_loss: 0.5895\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5535 - val_loss: 0.5883\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5523 - val_loss: 0.5870\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5511 - val_loss: 0.5857\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5499 - val_loss: 0.5844\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5486 - val_loss: 0.5831\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5474 - val_loss: 0.5818\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5461 - val_loss: 0.5805\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5449 - val_loss: 0.5791\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5437 - val_loss: 0.5778\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5424 - val_loss: 0.5765\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5411 - val_loss: 0.5752\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5399 - val_loss: 0.5738\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5386 - val_loss: 0.5725\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5373 - val_loss: 0.5711\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5360 - val_loss: 0.5698\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5347 - val_loss: 0.5684\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5334 - val_loss: 0.5670\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5321 - val_loss: 0.5657\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5308 - val_loss: 0.5643\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5295 - val_loss: 0.5629\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5282 - val_loss: 0.5615\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5269 - val_loss: 0.5601\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5256 - val_loss: 0.5587\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5242 - val_loss: 0.5573\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5229 - val_loss: 0.5559\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5216 - val_loss: 0.5545\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5202 - val_loss: 0.5531\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5189 - val_loss: 0.5517\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5175 - val_loss: 0.5502\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5162 - val_loss: 0.5488\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5148 - val_loss: 0.5473\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5135 - val_loss: 0.5459\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5121 - val_loss: 0.5445\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5107 - val_loss: 0.5430\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5094 - val_loss: 0.5416\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5080 - val_loss: 0.5402\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5066 - val_loss: 0.5387\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5052 - val_loss: 0.5372\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5039 - val_loss: 0.5358\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5025 - val_loss: 0.5343\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5011 - val_loss: 0.5329\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4997 - val_loss: 0.5314\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4983 - val_loss: 0.5299\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4969 - val_loss: 0.5285\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4955 - val_loss: 0.5270\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4942 - val_loss: 0.5255\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4928 - val_loss: 0.5240\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4914 - val_loss: 0.5226\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4900 - val_loss: 0.5211\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4886 - val_loss: 0.5196\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4872 - val_loss: 0.5181\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4858 - val_loss: 0.5167\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4844 - val_loss: 0.5152\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4830 - val_loss: 0.5137\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4816 - val_loss: 0.5123\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4802 - val_loss: 0.5108\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4788 - val_loss: 0.5093\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4774 - val_loss: 0.5078\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4760 - val_loss: 0.5064\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4747 - val_loss: 0.5049\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4733 - val_loss: 0.5034\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4719 - val_loss: 0.5020\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4705 - val_loss: 0.5006\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4692 - val_loss: 0.4991\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4678 - val_loss: 0.4977\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4664 - val_loss: 0.4962\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4651 - val_loss: 0.4948\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4637 - val_loss: 0.4934\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4624 - val_loss: 0.4920\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4610 - val_loss: 0.4905\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4597 - val_loss: 0.4891\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4584 - val_loss: 0.4877\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4571 - val_loss: 0.4864\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4558 - val_loss: 0.4850\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4545 - val_loss: 0.4836\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4532 - val_loss: 0.4822\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4519 - val_loss: 0.4809\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4506 - val_loss: 0.4796\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4494 - val_loss: 0.4782\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4481 - val_loss: 0.4769\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4469 - val_loss: 0.4756\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4457 - val_loss: 0.4743\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4445 - val_loss: 0.4730\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4433 - val_loss: 0.4718\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4421 - val_loss: 0.4705\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4409 - val_loss: 0.4693\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4397 - val_loss: 0.4680\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4386 - val_loss: 0.4668\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4374 - val_loss: 0.4656\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4363 - val_loss: 0.4644\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4352 - val_loss: 0.4632\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4341 - val_loss: 0.4621\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4330 - val_loss: 0.4609\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4319 - val_loss: 0.4598\n",
      "Epoch 613/1000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.4378"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[57], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# history = model.fit(train_features, train_labels, validation_data=(validation_features, validation_labels), epochs=epochs, batch_size=batch_size)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mevaluate(test_features, test_labels)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1856\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1841\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[0;32m   1842\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[0;32m   1843\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1854\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[0;32m   1855\u001B[0m     )\n\u001B[1;32m-> 1856\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1857\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1858\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1859\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1860\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1861\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1862\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1864\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1866\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1867\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1868\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1869\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   1870\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   1871\u001B[0m }\n\u001B[0;32m   1872\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:2285\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   2283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautotune_steps_per_execution:\n\u001B[0;32m   2284\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution_tuner\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m-> 2285\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (\n\u001B[0;32m   2286\u001B[0m     _,\n\u001B[0;32m   2287\u001B[0m     dataset_or_iterator,\n\u001B[0;32m   2288\u001B[0m ) \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():  \u001B[38;5;66;03m# Single epoch.\u001B[39;00m\n\u001B[0;32m   2289\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_metrics()\n\u001B[0;32m   2290\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1339\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[39;00m\n\u001B[0;32m   1340\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncate_execution_to_epoch():\n\u001B[1;32m-> 1341\u001B[0m     data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1342\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_epochs):\n\u001B[0;32m   1343\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:500\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[0;32m    499\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 500\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    502\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    503\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:706\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    702\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    704\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    705\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 706\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    708\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:745\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    742\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fulltype\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\n\u001B[0;32m    743\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types)\n\u001B[0;32m    744\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39mexperimental_set_type(fulltype)\n\u001B[1;32m--> 745\u001B[0m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3421\u001B[0m, in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3420\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3421\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3422\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3423\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3424\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "# history = model.fit(train_features, train_labels, validation_data=(validation_features, validation_labels), epochs=epochs, batch_size=batch_size)\n",
    "history = model.fit(train_features, train_labels, validation_split=0.2, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_features, test_labels)\n",
    "\n",
    "# Extract loss and validation loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "#plt.xlim([1,epochs])\n",
    "#plt.ylim([0,2])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicted values for W_0, W_1, J_0: [1.9449795 4.23119   3.344654 ]\n",
      "Correct values for W_0, W_1, J_0: <PandasArray>\n",
      "[1.944927777886473, 4.241159133574938, 3.3456689269079822]\n",
      "Length: 3, dtype: float64\n",
      "the mean squared error is:  3.0123639701783416e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_data = pd.read_csv(\"Z_values_100.csv\")\n",
    "first_line = new_data.iloc[5]\n",
    "correct_output = first_line[['W_0', 'W_1', 'J_0']].array\n",
    "#input_data = {key: [first_line[key]] for key in inputs}\n",
    "input_data = {key: np.array([first_line[key]]) for key in inputs}\n",
    "predictions = model.predict(input_data)\n",
    "print(\"Predicted values for W_0, W_1, J_0:\", predictions[0])\n",
    "print(\"Correct values for W_0, W_1, J_0:\", correct_output)\n",
    "print(\"the mean squared error is: \", 0.3*np.linalg.norm(predictions[0]-correct_output)**2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
