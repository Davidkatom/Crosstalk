{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "       0_0      0_1      1_0      1_1       2_0       2_1       3_0       3_1  \\\n0 1.000000 1.000000 0.820000 0.320000  0.040000 -0.340000 -0.160000 -0.200000   \n1 1.000000 1.000000 0.700000 0.600000 -0.040000  0.140000 -0.420000 -0.280000   \n2 1.000000 1.000000 0.520000 0.400000 -0.020000 -0.400000 -0.380000 -0.380000   \n3 1.000000 1.000000 0.640000 0.760000 -0.020000  0.380000 -0.580000 -0.460000   \n4 1.000000 1.000000 0.580000 0.620000 -0.360000 -0.280000 -0.440000 -0.460000   \n\n        4_0       4_1  ...       7_1       8_0       8_1       9_0       9_1  \\\n0 -0.020000 -0.080000  ... -0.720000 -0.400000  0.260000 -0.760000  0.800000   \n1 -0.260000 -0.260000  ... -0.120000 -0.580000 -0.480000 -0.560000 -0.720000   \n2 -0.140000 -0.100000  ... -0.320000 -0.760000  0.460000  0.200000  1.000000   \n3 -0.700000 -0.720000  ...  0.000000 -0.400000 -0.260000 -0.280000 -0.700000   \n4 -0.300000 -0.420000  ... -0.700000 -0.200000 -0.320000  0.540000  0.080000   \n\n   decay_0   decay_1      W_0      W_1      J_0  \n0 1.288213 -0.028388 1.334944 3.454920 4.611197  \n1 0.979878  2.065299 2.823135 2.489759 3.153725  \n2 0.438522 -0.289307 3.004403 3.934976 4.238538  \n3 1.591963  1.266298 3.310940 2.432493 2.903198  \n4 1.819276  0.291896 3.732673 3.377953 3.459519  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_0</th>\n      <th>0_1</th>\n      <th>1_0</th>\n      <th>1_1</th>\n      <th>2_0</th>\n      <th>2_1</th>\n      <th>3_0</th>\n      <th>3_1</th>\n      <th>4_0</th>\n      <th>4_1</th>\n      <th>...</th>\n      <th>7_1</th>\n      <th>8_0</th>\n      <th>8_1</th>\n      <th>9_0</th>\n      <th>9_1</th>\n      <th>decay_0</th>\n      <th>decay_1</th>\n      <th>W_0</th>\n      <th>W_1</th>\n      <th>J_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.820000</td>\n      <td>0.320000</td>\n      <td>0.040000</td>\n      <td>-0.340000</td>\n      <td>-0.160000</td>\n      <td>-0.200000</td>\n      <td>-0.020000</td>\n      <td>-0.080000</td>\n      <td>...</td>\n      <td>-0.720000</td>\n      <td>-0.400000</td>\n      <td>0.260000</td>\n      <td>-0.760000</td>\n      <td>0.800000</td>\n      <td>1.288213</td>\n      <td>-0.028388</td>\n      <td>1.334944</td>\n      <td>3.454920</td>\n      <td>4.611197</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.700000</td>\n      <td>0.600000</td>\n      <td>-0.040000</td>\n      <td>0.140000</td>\n      <td>-0.420000</td>\n      <td>-0.280000</td>\n      <td>-0.260000</td>\n      <td>-0.260000</td>\n      <td>...</td>\n      <td>-0.120000</td>\n      <td>-0.580000</td>\n      <td>-0.480000</td>\n      <td>-0.560000</td>\n      <td>-0.720000</td>\n      <td>0.979878</td>\n      <td>2.065299</td>\n      <td>2.823135</td>\n      <td>2.489759</td>\n      <td>3.153725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.520000</td>\n      <td>0.400000</td>\n      <td>-0.020000</td>\n      <td>-0.400000</td>\n      <td>-0.380000</td>\n      <td>-0.380000</td>\n      <td>-0.140000</td>\n      <td>-0.100000</td>\n      <td>...</td>\n      <td>-0.320000</td>\n      <td>-0.760000</td>\n      <td>0.460000</td>\n      <td>0.200000</td>\n      <td>1.000000</td>\n      <td>0.438522</td>\n      <td>-0.289307</td>\n      <td>3.004403</td>\n      <td>3.934976</td>\n      <td>4.238538</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.640000</td>\n      <td>0.760000</td>\n      <td>-0.020000</td>\n      <td>0.380000</td>\n      <td>-0.580000</td>\n      <td>-0.460000</td>\n      <td>-0.700000</td>\n      <td>-0.720000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-0.400000</td>\n      <td>-0.260000</td>\n      <td>-0.280000</td>\n      <td>-0.700000</td>\n      <td>1.591963</td>\n      <td>1.266298</td>\n      <td>3.310940</td>\n      <td>2.432493</td>\n      <td>2.903198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.580000</td>\n      <td>0.620000</td>\n      <td>-0.360000</td>\n      <td>-0.280000</td>\n      <td>-0.440000</td>\n      <td>-0.460000</td>\n      <td>-0.300000</td>\n      <td>-0.420000</td>\n      <td>...</td>\n      <td>-0.700000</td>\n      <td>-0.200000</td>\n      <td>-0.320000</td>\n      <td>0.540000</td>\n      <td>0.080000</td>\n      <td>1.819276</td>\n      <td>0.291896</td>\n      <td>3.732673</td>\n      <td>3.377953</td>\n      <td>3.459519</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.6f}\".format\n",
    "\n",
    "train_df = pd.read_csv(filepath_or_buffer=\"Z_expectation/Z_values_100000.csv\")\n",
    "test_df = pd.read_csv(filepath_or_buffer=\"Z_expectation/Z_values_100.csv\")\n",
    "validation_df = pd.read_csv(filepath_or_buffer=\"Z_expectation/Z_values_10000.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "timesteps = 10  # Corrected number of timesteps\n",
    "# Correcting the extraction of the sequences to include only the first 10 timesteps\n",
    "sequence_0_corrected = train_df[[f\"{i}_0\" for i in range(timesteps)]]\n",
    "sequence_1_corrected = train_df[[f\"{i}_1\" for i in range(timesteps)]]\n",
    "\n",
    "# Reshaping the sequences for LSTM input\n",
    "# The new shape will be [samples, timesteps, features]\n",
    "samples = len(train_df)  # Number of samples\n",
    "\n",
    "sequence_0_reshaped = sequence_0_corrected.values.reshape(samples, timesteps, 1)\n",
    "sequence_1_reshaped = sequence_1_corrected.values.reshape(samples, timesteps, 1)\n",
    "\n",
    "# Stack the sequences together along the last dimension\n",
    "train_features = np.concatenate([sequence_0_reshaped, sequence_1_reshaped], axis=-1)\n",
    "\n",
    "#\n",
    "sequence_0_corrected_test = test_df[[f\"{i}_0\" for i in range(timesteps)]]\n",
    "sequence_1_corrected_test = test_df[[f\"{i}_1\" for i in range(timesteps)]]\n",
    "\n",
    "samples = len(test_df)  # Number of samples\n",
    "sequence_0_reshaped_test = sequence_0_corrected_test.values.reshape(samples, timesteps, 1)\n",
    "sequence_1_reshaped_test = sequence_1_corrected_test.values.reshape(samples, timesteps, 1)\n",
    "\n",
    "test_features = np.concatenate([sequence_0_reshaped_test, sequence_1_reshaped_test], axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.python.keras.regularizers import L2, L1\n",
    "import re\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 1\n",
    "\n",
    "# Get all column names as a list\n",
    "keys = train_df.keys().tolist()\n",
    "\n",
    "# Remove specific columns from the list\n",
    "#keys = [key for key in keys if key not in ['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "#inputs = {key:tf.keras.layers.Input(shape=(1,), name=key) for key in keys}\n",
    "#concatenated_inputs = tf.keras.layers.concatenate(inputs.values())\n",
    "# Prepare data for training\n",
    "#train_features = {key: train_df[key] for key in inputs}\n",
    "train_labels = train_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "# Similarly prepare test and validation data\n",
    "#test_features = {key: test_df[key] for key in inputs}\n",
    "test_labels = test_df[['W_0', 'W_1', 'J_0']]\n",
    "#\n",
    "#validation_features = {key: validation_df[key] for key in inputs}\n",
    "validation_labels = validation_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "\n",
    "n_input = 3  # Number of lag observations as input (this can be tuned)\n",
    "n_features = 10  # Number of features\n",
    "\n",
    "train_generator = TimeseriesGenerator(train_features, train_labels, length=n_input, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(test_features, test_labels, length=n_input, batch_size=batch_size)\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
    "model.add(Dense(3))  # Output layer for 3 parameters w_0, w_1, J_0\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Number of epochs can be tuned\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Create a test generator\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m      5\u001B[0m model\u001B[38;5;241m.\u001B[39mevaluate(test_generator)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3655\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3656\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 3"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=epochs)  # Number of epochs can be tuned\n",
    "# Create a test generator\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_generator)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 10, 1), found shape=(None, 5, 5, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz_sequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_sequences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Extract loss and validation loss\u001B[39;00m\n\u001B[0;32m      8\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m history\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filey34xj_k7.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_5\" is incompatible with the layer: expected shape=(None, 10, 1), found shape=(None, 5, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 100\n",
    "batch_size = 1000\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(z_sequences, target_sequences, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "# Extract loss and validation loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "#plt.xlim([1,epochs])\n",
    "#plt.ylim([0,2])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
