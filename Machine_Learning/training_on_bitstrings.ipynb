{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   0_0  0_1  0_2  0_3  0_4  0_5  0_6  0_7  0_8  0_9  ...  9_95  9_96  9_97  \\\n0    0    0    0    0    0    0    0    0    0    0  ...     2     2     2   \n1    0    0    0    0    0    0    0    0    0    0  ...     0     0     3   \n2    0    0    0    0    0    0    0    0    0    0  ...     0     1     0   \n3    0    0    0    0    0    0    0    0    0    0  ...     3     0     3   \n4    0    0    0    0    0    0    0    0    0    0  ...     1     1     1   \n\n   9_98  9_99  decay_0   decay_1      W_0      W_1      J_0  \n0     2     2 2.123473  2.101471 4.160667 2.129584 4.071764  \n1     0     2 0.557067  1.261318 2.288560 3.381280 2.231517  \n2     3     3 1.357797 -0.558892 3.235920 2.811693 3.467802  \n3     3     3 0.674877 -0.554495 2.702982 2.245201 2.668579  \n4     1     1 1.253716  0.462385 2.295924 3.280174 4.145718  \n\n[5 rows x 1005 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_0</th>\n      <th>0_1</th>\n      <th>0_2</th>\n      <th>0_3</th>\n      <th>0_4</th>\n      <th>0_5</th>\n      <th>0_6</th>\n      <th>0_7</th>\n      <th>0_8</th>\n      <th>0_9</th>\n      <th>...</th>\n      <th>9_95</th>\n      <th>9_96</th>\n      <th>9_97</th>\n      <th>9_98</th>\n      <th>9_99</th>\n      <th>decay_0</th>\n      <th>decay_1</th>\n      <th>W_0</th>\n      <th>W_1</th>\n      <th>J_0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2.123473</td>\n      <td>2.101471</td>\n      <td>4.160667</td>\n      <td>2.129584</td>\n      <td>4.071764</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.557067</td>\n      <td>1.261318</td>\n      <td>2.288560</td>\n      <td>3.381280</td>\n      <td>2.231517</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1.357797</td>\n      <td>-0.558892</td>\n      <td>3.235920</td>\n      <td>2.811693</td>\n      <td>3.467802</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.674877</td>\n      <td>-0.554495</td>\n      <td>2.702982</td>\n      <td>2.245201</td>\n      <td>2.668579</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.253716</td>\n      <td>0.462385</td>\n      <td>2.295924</td>\n      <td>3.280174</td>\n      <td>4.145718</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 1005 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.6f}\".format\n",
    "\n",
    "train_df = pd.read_csv(filepath_or_buffer=\"raw_bitstrings/bitstrings_no_noise_100000.csv\")\n",
    "test_df = pd.read_csv(filepath_or_buffer=\"raw_bitstrings/bitstrings_no_noise_1000.csv\")\n",
    "validation_df = pd.read_csv(filepath_or_buffer=\"raw_bitstrings/bitstrings_no_noise_10000.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from custom_layers import CustomConnectedLayer, CustomConnectedLayer2\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "batch_size = 10000\n",
    "\n",
    "# Get all column names as a list\n",
    "keys = train_df.keys().tolist()\n",
    "\n",
    "# Remove specific columns from the list\n",
    "keys = [key for key in keys if key not in ['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "inputs = {key:tf.keras.layers.Input(shape=(1,), name=key) for key in keys}\n",
    "concatenated_inputs = tf.keras.layers.concatenate(inputs.values())\n",
    "# Prepare data for training\n",
    "train_features = {key: train_df[key] for key in inputs}\n",
    "train_labels = train_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "# Similarly prepare test and validation data\n",
    "test_features = {key: test_df[key] for key in inputs}\n",
    "test_labels = test_df[['W_0', 'W_1', 'J_0']]\n",
    "#\n",
    "validation_features = {key: validation_df[key] for key in inputs}\n",
    "validation_labels = validation_df[['W_0', 'W_1', 'J_0']]\n",
    "\n",
    "input_shape = concatenated_inputs.shape\n",
    "\n",
    "# Replace Dense layers with CustomConnectedLayer\n",
    "hidden_layer_1 = CustomConnectedLayer(1000, 100, activation='relu')(concatenated_inputs)\n",
    "hidden_layer_2 = tf.keras.layers.Dense(100, activation='relu')(hidden_layer_1)\n",
    "hidden_layer_3 = tf.keras.layers.Dense(100, activation='relu')(hidden_layer_2)\n",
    "hidden_layer_4 = tf.keras.layers.Dense(100, activation='relu')(hidden_layer_3)\n",
    "\n",
    "#hidden_layer_2 = CustomConnectedLayer(100, num_groups=1, activation='relu')(hidden_layer_1)\n",
    "#hidden_layer_3 = CustomConnectedLayer(64, num_groups=1, activation='relu')(hidden_layer_2)\n",
    "#hidden_layer_4 = CustomConnectedLayer(64, num_groups=1, activation='relu')(hidden_layer_3)\n",
    "\n",
    "\n",
    "output = tf.keras.layers.Dense(3)(hidden_layer_3) #TODO magic number\n",
    "\n",
    "log_dir = \"logs/gradient_tape/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "10/10 [==============================] - 12s 983ms/step - loss: 6.5284 - val_loss: 1.0859\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 6s 586ms/step - loss: 1.0454 - val_loss: 0.9813\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 0.8522 - val_loss: 0.7621\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 5s 562ms/step - loss: 0.7224 - val_loss: 0.6899\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 6s 569ms/step - loss: 0.6414 - val_loss: 0.6226\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 5s 520ms/step - loss: 0.5890 - val_loss: 0.5824\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 5s 538ms/step - loss: 0.5582 - val_loss: 0.5618\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 6s 642ms/step - loss: 0.5410 - val_loss: 0.5490\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 5s 504ms/step - loss: 0.5300 - val_loss: 0.5410\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 5s 522ms/step - loss: 0.5226 - val_loss: 0.5350\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 5s 563ms/step - loss: 0.5154 - val_loss: 0.5267\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 5s 507ms/step - loss: 0.5084 - val_loss: 0.5187\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 5s 502ms/step - loss: 0.4995 - val_loss: 0.5117\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 5s 521ms/step - loss: 0.4923 - val_loss: 0.5045\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 5s 539ms/step - loss: 0.4849 - val_loss: 0.4972\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 5s 543ms/step - loss: 0.4782 - val_loss: 0.4919\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 5s 509ms/step - loss: 0.4722 - val_loss: 0.4854\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 5s 497ms/step - loss: 0.4667 - val_loss: 0.4819\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.4615 - val_loss: 0.4758\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 5s 518ms/step - loss: 0.4575 - val_loss: 0.4720\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 6s 579ms/step - loss: 0.4533 - val_loss: 0.4682\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 5s 556ms/step - loss: 0.4495 - val_loss: 0.4648\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 5s 503ms/step - loss: 0.4463 - val_loss: 0.4614\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 5s 487ms/step - loss: 0.4434 - val_loss: 0.4611\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 5s 480ms/step - loss: 0.4404 - val_loss: 0.4555\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 0.4375 - val_loss: 0.4534\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 5s 514ms/step - loss: 0.4344 - val_loss: 0.4505\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 5s 568ms/step - loss: 0.4315 - val_loss: 0.4465\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 5s 497ms/step - loss: 0.4278 - val_loss: 0.4448\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 5s 554ms/step - loss: 0.4273 - val_loss: 0.4439\n",
      "16/16 [==============================] - 3s 16ms/step - loss: 0.4052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(train_features, train_labels, validation_data=(validation_features, validation_labels), epochs=epochs, batch_size=batch_size, callbacks=[tensorboard_callback])\n",
    "#history = model.fit(train_features, train_labels, validation_split=0.2, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_features, test_labels)\n",
    "\n",
    "# Extract loss and validation loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "#plt.xlim([1,epochs])\n",
    "#plt.ylim([0,2])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-5ccb22d313e3228e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-5ccb22d313e3228e\");\n          const url = new URL(\"/\", window.location);\n          const port = 6007;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/gradient_tape"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
