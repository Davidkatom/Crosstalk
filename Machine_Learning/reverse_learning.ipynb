{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import np as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.6f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(filepath_or_buffer=\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-09-04_16-28\\large_data.csv\")\n",
    "test_df = pd.read_csv(filepath_or_buffer=\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-09-04_16-28/test.csv\")\n",
    "# validation_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/with_decay/no_j/no_j_1000.csv\")\n",
    "\n",
    "# train_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/all_expectation_values_100000.csv\")\n",
    "# test_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/all_expectation_values_100.csv\")\n",
    "# validation_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/all_expectation_values_10000.csv\")\n",
    "train_df.head()\n",
    "print(len(train_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "class TrigonometricLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, t, num_measurements, **kwargs):\n",
    "        super(TrigonometricLayer, self).__init__(**kwargs)\n",
    "        self.t = t  # Time at which measurements are taken\n",
    "        self.num_measurements = num_measurements  # Number of measurement functions\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize trainable parameters\n",
    "\n",
    "        self.trig_weights = self.add_weight(\n",
    "            name='trig_weights',\n",
    "            shape=(20, 8),\n",
    "            initializer=tf.random_uniform_initializer(minval=0.0, maxval=1.0),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        super(TrigonometricLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute each measurement function based on trainable parameters\n",
    "        w0, w1, j, a1, a2 = inputs[:, 0], inputs[:, 1], inputs[:, 2], inputs[:, 3], inputs[:, 4]\n",
    "\n",
    "        x1 = tf.cos(w0 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x2 = tf.cos(w1 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x3 = tf.cos(j * self.t) * tf.exp(- a1 * self.t)\n",
    "        x4 = tf.sin(w0 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x5 = tf.sin(w1 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x6 = tf.sin(j * self.t) * tf.exp(- a1 * self.t)\n",
    "        x7 = tf.cos((w0 + w1) * self.t) * tf.exp(- a1 * self.t)\n",
    "        x8 = tf.cos((w0 + j) * self.t) * tf.exp(- a1 * self.t)\n",
    "        x9 = tf.cos((w1 + j) * self.t) * tf.exp(- a1 * self.t)\n",
    "        x10 = tf.cos((w1 + j + w0) * self.t) * tf.exp(- a1 * self.t)\n",
    "\n",
    "        x11 = tf.cos(w0 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x12 = tf.cos(w1 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x13 = tf.cos(j * self.t) * tf.exp(- a2 * self.t)\n",
    "        x14 = tf.sin(w0 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x15 = tf.sin(w1 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x16 = tf.sin(j * self.t) * tf.exp(- a2 * self.t)\n",
    "        x17 = tf.cos((w0 + w1) * self.t) * tf.exp(- a2 * self.t)\n",
    "        x18 = tf.cos((w0 + j) * self.t) * tf.exp(- a2 * self.t)\n",
    "        x19 = tf.cos((w1 + j) * self.t) * tf.exp(- a2 * self.t)\n",
    "        x20 = tf.cos((w1 + j + w0) * self.t) * tf.exp(- a2 * self.t)\n",
    "\n",
    "        trig_combinations = tf.stack([\n",
    "            x1, x2, x3, x4, x5, x6, x7, x8, x9, x10,\n",
    "            x11, x12, x13, x14, x15, x16, x17, x18, x19, x20\n",
    "        ], axis=-1)\n",
    "\n",
    "        outputs = tf.matmul(trig_combinations, self.trig_weights)  # Shape: (1, num_features)\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.00005\n",
    "epochs = 300\n",
    "batch_size = 500\n",
    "\n",
    "# Get all column names as a list\n",
    "keys = train_df.keys().tolist()\n",
    "input_keys = ['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]\n",
    "\n",
    "output_keys = [key for key in keys if key not in input_keys]\n",
    "\n",
    "inputs = {key: tf.keras.layers.Input(shape=(1,), name=key) for key in input_keys}\n",
    "concatenated_inputs = tf.keras.layers.concatenate(list(inputs.values()))\n",
    "\n",
    "# Prepare data for training\n",
    "train_features = {key: train_df[key] for key in inputs}\n",
    "train_labels = train_df[output_keys]\n",
    "\n",
    "# Similarly prepare test and validation data\n",
    "test_features = {key: test_df[key] for key in inputs}\n",
    "test_labels = test_df[output_keys]\n",
    "\n",
    "\n",
    "def build_model(input_layer, num_layers, nodes_per_layer=None, default_nodes=64):\n",
    "    # If no list of nodes is provided, use the default number of nodes for all layers\n",
    "    if nodes_per_layer is None:\n",
    "        nodes_per_layer = [default_nodes] * num_layers\n",
    "\n",
    "    # Check if nodes_per_layer has the correct number of layers\n",
    "    assert len(nodes_per_layer) == num_layers, \"Length of nodes_per_layer must match num_layers\"\n",
    "\n",
    "    # Build the hidden layers dynamically\n",
    "    hidden_layer = input_layer\n",
    "    for i in range(num_layers):\n",
    "        hidden_layer = tf.keras.layers.Dense(nodes_per_layer[i], activation='relu')(hidden_layer)\n",
    "\n",
    "    # Output layer (Assuming len(output_keys) is predefined)\n",
    "    output = tf.keras.layers.Dense(len(output_keys))(hidden_layer)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "nodes_per_layer = [32, 64, 64, 64, 64, 64, 64, 8]  # Optional, can be None\n",
    "output = build_model(concatenated_inputs, len(nodes_per_layer), nodes_per_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0199 - val_loss: 0.0216\n",
      "Epoch 2/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0200 - val_loss: 0.0217\n",
      "Epoch 3/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 4/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0198 - val_loss: 0.0215\n",
      "Epoch 5/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0203 - val_loss: 0.0214\n",
      "Epoch 6/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0198 - val_loss: 0.0214\n",
      "Epoch 7/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0196 - val_loss: 0.0213\n",
      "Epoch 8/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0192 - val_loss: 0.0212\n",
      "Epoch 9/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0194 - val_loss: 0.0211\n",
      "Epoch 10/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 11/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 12/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0192 - val_loss: 0.0209\n",
      "Epoch 13/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0193 - val_loss: 0.0209\n",
      "Epoch 14/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0189 - val_loss: 0.0207\n",
      "Epoch 15/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0190 - val_loss: 0.0209\n",
      "Epoch 16/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0193 - val_loss: 0.0207\n",
      "Epoch 17/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 18/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 19/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 20/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0189 - val_loss: 0.0207\n",
      "Epoch 21/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 22/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 23/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 24/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 25/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 26/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0185 - val_loss: 0.0201\n",
      "Epoch 27/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0183 - val_loss: 0.0200\n",
      "Epoch 28/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 29/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 30/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0183 - val_loss: 0.0198\n",
      "Epoch 31/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0180 - val_loss: 0.0198\n",
      "Epoch 32/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 33/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0180 - val_loss: 0.0197\n",
      "Epoch 34/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0179 - val_loss: 0.0197\n",
      "Epoch 35/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0176 - val_loss: 0.0196\n",
      "Epoch 36/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0179 - val_loss: 0.0198\n",
      "Epoch 37/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0179 - val_loss: 0.0195\n",
      "Epoch 38/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0179 - val_loss: 0.0197\n",
      "Epoch 39/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0181 - val_loss: 0.0195\n",
      "Epoch 40/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0177 - val_loss: 0.0195\n",
      "Epoch 41/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0182 - val_loss: 0.0193\n",
      "Epoch 42/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0179 - val_loss: 0.0193\n",
      "Epoch 43/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 44/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 45/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0171 - val_loss: 0.0191\n",
      "Epoch 46/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 47/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 48/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 49/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0172 - val_loss: 0.0191\n",
      "Epoch 50/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 51/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 52/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0172 - val_loss: 0.0188\n",
      "Epoch 53/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0170 - val_loss: 0.0187\n",
      "Epoch 54/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0169 - val_loss: 0.0187\n",
      "Epoch 55/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0175 - val_loss: 0.0188\n",
      "Epoch 56/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0169 - val_loss: 0.0187\n",
      "Epoch 57/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 58/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0171 - val_loss: 0.0186\n",
      "Epoch 59/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 60/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 61/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 62/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0170 - val_loss: 0.0184\n",
      "Epoch 63/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 64/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0166 - val_loss: 0.0184\n",
      "Epoch 65/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0166 - val_loss: 0.0182\n",
      "Epoch 66/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0166 - val_loss: 0.0182\n",
      "Epoch 67/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 68/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0169 - val_loss: 0.0183\n",
      "Epoch 69/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 70/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 71/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 72/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0164 - val_loss: 0.0182\n",
      "Epoch 73/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 74/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0164 - val_loss: 0.0179\n",
      "Epoch 75/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0162 - val_loss: 0.0184\n",
      "Epoch 76/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 77/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0164 - val_loss: 0.0179\n",
      "Epoch 78/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0160 - val_loss: 0.0179\n",
      "Epoch 79/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0163 - val_loss: 0.0178\n",
      "Epoch 80/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0165 - val_loss: 0.0178\n",
      "Epoch 81/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0158 - val_loss: 0.0177\n",
      "Epoch 82/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0159 - val_loss: 0.0176\n",
      "Epoch 83/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0161 - val_loss: 0.0176\n",
      "Epoch 84/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0160 - val_loss: 0.0176\n",
      "Epoch 85/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0160 - val_loss: 0.0176\n",
      "Epoch 86/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0160 - val_loss: 0.0177\n",
      "Epoch 87/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0159 - val_loss: 0.0176\n",
      "Epoch 88/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0156 - val_loss: 0.0174\n",
      "Epoch 89/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 90/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0157 - val_loss: 0.0174\n",
      "Epoch 91/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0159 - val_loss: 0.0173\n",
      "Epoch 92/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 93/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 94/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0156 - val_loss: 0.0173\n",
      "Epoch 95/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0157 - val_loss: 0.0172\n",
      "Epoch 96/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0154 - val_loss: 0.0173\n",
      "Epoch 97/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0156 - val_loss: 0.0171\n",
      "Epoch 98/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0157 - val_loss: 0.0171\n",
      "Epoch 99/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0153 - val_loss: 0.0173\n",
      "Epoch 100/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 101/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0152 - val_loss: 0.0171\n",
      "Epoch 102/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 103/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0154 - val_loss: 0.0170\n",
      "Epoch 104/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 105/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 106/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 107/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 108/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0152 - val_loss: 0.0169\n",
      "Epoch 109/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 110/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 111/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 112/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 113/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0151 - val_loss: 0.0168\n",
      "Epoch 114/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0155 - val_loss: 0.0167\n",
      "Epoch 115/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 116/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 117/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 118/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 119/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 120/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0150 - val_loss: 0.0168\n",
      "Epoch 121/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 122/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 123/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 124/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0145 - val_loss: 0.0165\n",
      "Epoch 125/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0145 - val_loss: 0.0167\n",
      "Epoch 126/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0147 - val_loss: 0.0163\n",
      "Epoch 127/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0146 - val_loss: 0.0163\n",
      "Epoch 128/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0143 - val_loss: 0.0163\n",
      "Epoch 129/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 130/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 131/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0144 - val_loss: 0.0163\n",
      "Epoch 132/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 133/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 134/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 135/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 136/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0142 - val_loss: 0.0163\n",
      "Epoch 137/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0148 - val_loss: 0.0160\n",
      "Epoch 138/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 139/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 140/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 141/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 142/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0140 - val_loss: 0.0159\n",
      "Epoch 143/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0160\n",
      "Epoch 144/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 145/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 146/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 147/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 148/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 149/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 150/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0138 - val_loss: 0.0157\n",
      "Epoch 151/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 152/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 153/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 154/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 155/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 156/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0159\n",
      "Epoch 157/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 158/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 159/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 160/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 161/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 162/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0137 - val_loss: 0.0156\n",
      "Epoch 163/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 164/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 165/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 166/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 167/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 168/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 169/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 170/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 171/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 172/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0137 - val_loss: 0.0154\n",
      "Epoch 173/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 174/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0136 - val_loss: 0.0151\n",
      "Epoch 175/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 176/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 177/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 178/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0135 - val_loss: 0.0153\n",
      "Epoch 179/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 180/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 181/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 182/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 183/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 184/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 185/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.0131 - val_loss: 0.0149\n",
      "Epoch 186/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0132 - val_loss: 0.0149\n",
      "Epoch 187/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0133 - val_loss: 0.0150\n",
      "Epoch 188/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 189/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0132 - val_loss: 0.0151\n",
      "Epoch 190/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 191/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 192/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 193/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 194/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 195/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 196/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0134 - val_loss: 0.0150\n",
      "Epoch 197/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0132 - val_loss: 0.0147\n",
      "Epoch 198/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 199/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 200/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0129 - val_loss: 0.0147\n",
      "Epoch 201/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 202/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 203/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 204/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 205/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0132 - val_loss: 0.0145\n",
      "Epoch 206/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 207/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 208/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0131 - val_loss: 0.0145\n",
      "Epoch 209/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0130 - val_loss: 0.0145\n",
      "Epoch 210/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 211/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 212/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 213/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 214/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 215/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 216/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0130 - val_loss: 0.0143\n",
      "Epoch 217/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 218/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 219/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0125 - val_loss: 0.0143\n",
      "Epoch 220/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 221/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 222/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 223/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 224/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 225/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 226/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 227/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 228/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 229/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 230/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 231/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 232/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 233/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 234/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 235/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 236/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0126 - val_loss: 0.0141\n",
      "Epoch 237/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 238/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0127 - val_loss: 0.0145\n",
      "Epoch 239/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 240/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 241/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 242/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 243/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 244/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 245/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 246/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0124 - val_loss: 0.0138\n",
      "Epoch 247/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 248/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 249/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0123 - val_loss: 0.0138\n",
      "Epoch 250/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 251/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 252/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 253/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 254/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 255/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0121 - val_loss: 0.0138\n",
      "Epoch 256/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0125 - val_loss: 0.0137\n",
      "Epoch 257/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 258/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 259/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 260/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 261/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 262/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 263/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 264/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 265/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 266/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 267/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 268/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0125 - val_loss: 0.0137\n",
      "Epoch 269/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 270/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 271/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 272/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 273/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 274/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 275/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 276/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 277/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 278/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0136\n",
      "Epoch 279/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 280/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 281/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0118 - val_loss: 0.0135\n",
      "Epoch 282/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 283/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 284/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 285/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 286/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 287/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 288/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 289/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 290/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 291/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 292/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 293/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 294/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 295/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 296/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 297/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 298/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 299/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 300/300\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.0115 - val_loss: 0.0131\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0105 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "# history = model.fit(train_features, train_labels, validation_data=(validation_features, validation_labels), epochs=epochs, batch_size=batch_size);\n",
    "history = model.fit(train_features, train_labels, validation_split=0.2, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_features, test_labels)\n",
    "\n",
    "# Extract loss and validation loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "#plt.xlim([1,epochs])\n",
    "#plt.ylim([0,2])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "Predicted values:  [-0.06547321  0.56510997 -0.0729603   0.5645728  -0.67716116 -0.42320794\n",
      " -0.6808224  -0.42941982]\n",
      "Correct values:  <PandasArray>\n",
      "[-0.04104, 0.56048, -0.04104, 0.56048, -0.67072, -0.43712, -0.67072, -0.43712]\n",
      "Length: 8, dtype: float64\n",
      "the mean squared error is:  0.002050460064372477\n",
      "The percent error is:  3.681715541858587\n",
      "{'decay_0': 0.4355366167196668, 'decay_1': 0.5046562211072161, 'W_0': 0.8386818498585731, 'W_1': 2.041854041592219, 'J_0': -1.6803806881788437}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import estimator\n",
    "\n",
    "new_data = pd.read_csv(\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-09-04_16-28/test.csv\")\n",
    "first_line = new_data.iloc[8]\n",
    "correct_output = first_line[output_keys].array\n",
    "\n",
    "input_data = {key: np.array([first_line[key]]) for key in inputs}\n",
    "predictions = model.predict(input_data)\n",
    "print(\"Predicted values: \", predictions[0])\n",
    "print(\"Correct values: \", correct_output)\n",
    "print(\"the mean squared error is: \", np.linalg.norm(predictions[0] - correct_output) ** 2)\n",
    "error = estimator.percent_error(predictions[0], correct_output)\n",
    "print(\"The percent error is: \", error * 100)\n",
    "\n",
    "parameters = {key: first_line[key] for key in input_keys}\n",
    "print(parameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 478.9243469238281, Inputs: [0.50999993, 0.50999993, 0.009999933, 0.009999934, 0.009999925]\n",
      "Step 100, Loss: 188.24420166015625, Inputs: [0.4150736, 1.2955387, 0.85004985, 0.8738238, -0.23045476]\n",
      "Step 200, Loss: 82.04546356201172, Inputs: [0.4566854, 1.1799601, 0.78078467, 1.8167552, -0.5949612]\n",
      "Optimized Inputs: {'decay_0': 0.46180946, 'decay_1': 0.52016675, 'W_0': 0.8406878, 'W_1': 2.0144958, 'J_0': -0.71838945}\n",
      "{'decay_0': 0.4355366167196668, 'decay_1': 0.5046562211072161, 'W_0': 0.8386818498585731, 'W_1': 2.041854041592219, 'J_0': -1.6803806881788437}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "target_outputs = tf.constant(correct_output, dtype=tf.float32)  # Replace with your target values\n",
    "\n",
    "# Initialize the input parameters as variables to optimize\n",
    "initial_guess = {\n",
    "    'decay_0': 0.5,\n",
    "    'decay_1': 0.5,\n",
    "    'W_0': 0,\n",
    "    'W_1': 0,\n",
    "    'J_0': 0\n",
    "}\n",
    "input_vars = {key: tf.Variable(value, dtype=tf.float32) for key, value in initial_guess.items()}\n",
    "\n",
    "\n",
    "# Use the variables as inputs to the model\n",
    "def model_loss(target):\n",
    "    # Pass the variables through the model to get the predicted output\n",
    "    model_inputs = {key: tf.expand_dims(input_vars[key], 0) for key in input_keys}\n",
    "    predicted_outputs = model(model_inputs, training=False)\n",
    "\n",
    "    # Calculate the loss between predicted and target outputs\n",
    "    loss = tf.reduce_mean(tf.abs(predicted_outputs - target))\n",
    "    return loss * 1000\n",
    "\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Optimization loop\n",
    "for step in range(300):  # Adjust the number of steps as needed\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model_loss(target_outputs)\n",
    "    # Compute the gradients of the loss with respect to the input variables\n",
    "    grads = tape.gradient(loss, input_vars.values())\n",
    "    # input_vars['J_0'].assign(-0.64)\n",
    "    # Apply the gradients to the input variables\n",
    "    optimizer.apply_gradients(zip(grads, input_vars.values()))\n",
    "\n",
    "    # Print the loss and current input variables every 100 steps\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss.numpy()}, Inputs: {[input_vars[key].numpy() for key in input_keys]}\")\n",
    "\n",
    "# Final optimized input parameters\n",
    "optimized_inputs = {key: var.numpy() for key, var in input_vars.items()}\n",
    "print(\"Optimized Inputs:\", optimized_inputs)\n",
    "print(parameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46180946, 0.52016675, 0.8406878, 2.0144958, -0.71838945]\n",
      "[0.4355366167196668, 0.5046562211072161, 0.8386818498585731, 2.041854041592219, -1.6803806881788437]\n",
      "47.26177419271624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(list(optimized_inputs.values()))\n",
    "print(list(parameters.values()))\n",
    "\n",
    "error = estimator.percent_error(np.array(list(optimized_inputs.values())), np.array(list(parameters.values())))\n",
    "print(error * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 0.21171358227729797, Inputs: [0.40000385, 0.40000266, -0.09999692, 0.099992916, -0.099789836]\n",
      "[ 0.40452785 -0.06298816 -0.19831074  0.58587569  0.36202902]\n",
      "Step 100, Loss: 0.01242877822369337, Inputs: [0.4291598, -0.07936156, -0.20011015, 0.53970003, -0.65908056]\n",
      "[ 0.40452785 -0.06298816 -0.19831074  0.58587569  0.36202902]\n",
      "Step 200, Loss: 0.006090142764151096, Inputs: [0.39067936, -0.084216975, -0.20674372, 0.5253976, -0.79908645]\n",
      "[ 0.40452785 -0.06298816 -0.19831074  0.58587569  0.36202902]\n",
      "Step 300, Loss: 0.005143921822309494, Inputs: [0.42044893, -0.067303464, -0.21855307, 0.5368339, -0.6253812]\n",
      "[ 0.40452785 -0.06298816 -0.19831074  0.58587569  0.36202902]\n",
      "Error is:  9.683463957946229\n",
      "Step 0, Loss: 0.3371627628803253, Inputs: [0.5999964, 0.40000403, 0.09999664, -0.09999468, -0.09989882]\n",
      "[ 0.59765855  0.28785614  1.35799046 -0.66207581  1.51046066]\n",
      "Step 100, Loss: 0.0036354102194309235, Inputs: [0.62012124, 0.31011045, 1.3695663, -0.66393447, 0.8812371]\n",
      "[ 0.59765855  0.28785614  1.35799046 -0.66207581  1.51046066]\n",
      "Step 200, Loss: 0.004434749484062195, Inputs: [0.5982295, 0.28334492, 1.3612663, -0.6596032, 1.0864701]\n",
      "[ 0.59765855  0.28785614  1.35799046 -0.66207581  1.51046066]\n",
      "Step 300, Loss: 0.00615943968296051, Inputs: [0.59826285, 0.3159022, 1.3694184, -0.64313966, 1.1456536]\n",
      "[ 0.59765855  0.28785614  1.35799046 -0.66207581  1.51046066]\n",
      "Error is:  1.839102393872484\n",
      "Step 0, Loss: 0.20556195080280304, Inputs: [0.5999971, 0.40000352, -0.09999703, -0.09999667, -0.09991696]\n",
      "[ 0.4068675   0.36210502 -0.81484983 -0.4390186   0.90077825]\n",
      "Step 100, Loss: 0.005875851958990097, Inputs: [0.42500728, 0.41524714, -0.8195812, -0.44328406, 0.23728389]\n",
      "[ 0.4068675   0.36210502 -0.81484983 -0.4390186   0.90077825]\n",
      "Step 200, Loss: 0.006155043840408325, Inputs: [0.42519236, 0.36766708, -0.81281924, -0.43948048, 1.0208479]\n",
      "[ 0.4068675   0.36210502 -0.81484983 -0.4390186   0.90077825]\n",
      "Step 300, Loss: 0.006465014070272446, Inputs: [0.4431841, 0.3644649, -0.8182061, -0.4488567, 0.90527797]\n",
      "[ 0.4068675   0.36210502 -0.81484983 -0.4390186   0.90077825]\n",
      "Error is:  5.7797440750336815\n",
      "Step 0, Loss: 0.23771721124649048, Inputs: [0.4000036, 0.599996, -0.09999664, 0.09999468, 0.09989882]\n",
      "[ 0.45511485  0.51739121 -0.22114128  1.1810702  -0.38306336]\n",
      "Step 100, Loss: 0.006533708423376083, Inputs: [0.46021658, 0.5073084, -0.20108174, 1.1587554, -1.2659268]\n",
      "[ 0.45511485  0.51739121 -0.22114128  1.1810702  -0.38306336]\n",
      "Step 200, Loss: 0.0033377408981323242, Inputs: [0.4790149, 0.5192814, -0.215078, 1.165718, -1.5501063]\n",
      "[ 0.45511485  0.51739121 -0.22114128  1.1810702  -0.38306336]\n",
      "Step 300, Loss: 0.0027023637667298317, Inputs: [0.46217546, 0.506215, -0.23684283, 1.1747575, -1.2947419]\n",
      "[ 0.45511485  0.51739121 -0.22114128  1.1810702  -0.38306336]\n",
      "Error is:  3.751751831435711\n",
      "Step 0, Loss: 0.044062770903110504, Inputs: [0.5999964, 0.40000403, 0.09999664, -0.09999468, -0.09989882]\n",
      "[ 0.50549643  0.37102456  0.09559335 -0.1196448  -1.41648669]\n",
      "Step 100, Loss: 0.005463225767016411, Inputs: [0.52935857, 0.39569566, 0.081717014, -0.12569183, 0.21997836]\n",
      "[ 0.50549643  0.37102456  0.09559335 -0.1196448  -1.41648669]\n",
      "Step 200, Loss: 0.006987473927438259, Inputs: [0.5561042, 0.3869406, 0.07780816, -0.074820235, 0.35415763]\n",
      "[ 0.50549643  0.37102456  0.09559335 -0.1196448  -1.41648669]\n",
      "Step 300, Loss: 0.007557679899036884, Inputs: [0.5356683, 0.39486668, 0.0767765, -0.08180009, 0.4016759]\n",
      "[ 0.50549643  0.37102456  0.09559335 -0.1196448  -1.41648669]\n",
      "Error is:  13.093077705788192\n",
      "The mean percent error is:  6.829427992815259\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(5):\n",
    "    line = new_data.iloc[i]\n",
    "    correct_output = line[output_keys].array\n",
    "    parameters = {key: line[key] for key in input_keys}\n",
    "    input_vars = {key: tf.Variable(value, dtype=tf.float32) for key, value in initial_guess.items()}\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "\n",
    "    def model_loss(target):\n",
    "        # Pass the variables through the model to get the predicted output\n",
    "        model_inputs = {key: tf.expand_dims(input_vars[key], 0) for key in input_keys}\n",
    "        predicted_outputs = model(model_inputs, training=False)\n",
    "\n",
    "        # Calculate the loss between predicted and target outputs\n",
    "        loss = tf.reduce_mean(tf.abs(predicted_outputs - target))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    for step in range(400):  # Adjust the number of steps as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model_loss(correct_output)\n",
    "\n",
    "        # Compute the gradients of the loss with respect to the input variables\n",
    "        grads = tape.gradient(loss, input_vars.values())\n",
    "\n",
    "        # Apply the gradients to the input variables\n",
    "        optimizer.apply_gradients(zip(grads, input_vars.values()))\n",
    "\n",
    "        # Print the loss and current input variables every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy()}, Inputs: {[input_vars[key].numpy() for key in input_keys]}\")\n",
    "            print(np.array(list(parameters.values())))\n",
    "\n",
    "    optimized_inputs = {key: var.numpy() for key, var in input_vars.items()}\n",
    "\n",
    "    optimized_inputs = np.array(list(optimized_inputs.values()))\n",
    "    parameters = np.array(list(parameters.values()))\n",
    "\n",
    "    optimized_inputs = optimized_inputs[:-1]\n",
    "    parameters = parameters[:-1]\n",
    "\n",
    "\n",
    "    error = estimator.percent_error(optimized_inputs,parameters)\n",
    "    errors.append(error)\n",
    "    print(\"Error is: \", error * 100)\n",
    "print(\"The mean percent error is: \", np.mean(errors) * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sympy' has no attribute 'assumptions'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mestimator\u001B[39;00m\n\u001B[0;32m      4\u001B[0m new_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mProjects\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mCrosstalk\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mMachine_Learning\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mData/2024-08-28_14-31/test.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m first_line \u001B[38;5;241m=\u001B[39m new_data\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m10\u001B[39m]\n",
      "File \u001B[1;32mC:\\Projects\\Crosstalk\\estimator.py:7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimize\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m curve_fit, least_squares\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m symbols, lambdify\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mSymbolic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m symbolic_evolution\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msp\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcomplex_fit\u001B[39m(batch_x, batch_y):\n",
      "File \u001B[1;32mC:\\Projects\\Crosstalk\\Symbolic\\symbolic_evolution.py:5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Matrix, symbols, exp, I, simplify, sqrt, expand_complex, lambdify\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphysics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantum\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dagger\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphysics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantum\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TensorProduct\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\physics\\__init__.py:5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mA module that helps solving problems in physics.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m units\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmatrices\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mgamma, msigma, minkowski_tensor, mdft\n\u001B[0;32m      8\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124munits\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmgamma\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmsigma\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminkowski_tensor\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmdft\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     12\u001B[0m ]\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\physics\\units\\__init__.py:32\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mDimensional analysis and unit systems.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     28\u001B[0m \n\u001B[0;32m     29\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdimensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dimension, DimensionSystem\n\u001B[1;32m---> 32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munitsystem\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UnitSystem\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m convert_to\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Quantity\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\physics\\units\\unitsystem.py:13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msingleton\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m S\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphysics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munits\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdimensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _QuantityMapper\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphysics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munits\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquantities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Quantity\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdimensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dimension\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mUnitSystem\u001B[39;00m(_QuantityMapper):\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\physics\\units\\quantities.py:9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msympify\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sympify\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphysics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munits\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdimensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _QuantityMapper\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mphysics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01munits\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprefixes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Prefix\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mQuantity\u001B[39;00m(AtomicExpr):\n\u001B[0;32m     13\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;124;03m    Physical quantity: can be a unit of measure, a constant or a generic quantity.\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\physics\\units\\prefixes.py:156\u001B[0m\n\u001B[0;32m    151\u001B[0m         prefixed_units\u001B[38;5;241m.\u001B[39mappend(quantity)\n\u001B[0;32m    153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prefixed_units\n\u001B[1;32m--> 156\u001B[0m yotta \u001B[38;5;241m=\u001B[39m \u001B[43mPrefix\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myotta\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mY\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m24\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m zetta \u001B[38;5;241m=\u001B[39m Prefix(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzetta\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZ\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m21\u001B[39m)\n\u001B[0;32m    158\u001B[0m exa \u001B[38;5;241m=\u001B[39m Prefix(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexa\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m18\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\physics\\units\\prefixes.py:35\u001B[0m, in \u001B[0;36mPrefix.__new__\u001B[1;34m(cls, name, abbrev, exponent, base, latex_repr)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, name, abbrev, exponent, base\u001B[38;5;241m=\u001B[39msympify(\u001B[38;5;241m10\u001B[39m), latex_repr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 35\u001B[0m     name \u001B[38;5;241m=\u001B[39m \u001B[43msympify\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m     abbrev \u001B[38;5;241m=\u001B[39m sympify(abbrev)\n\u001B[0;32m     37\u001B[0m     exponent \u001B[38;5;241m=\u001B[39m sympify(exponent)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\core\\sympify.py:481\u001B[0m, in \u001B[0;36msympify\u001B[1;34m(a, locals, convert_xor, strict, rational, evaluate)\u001B[0m\n\u001B[0;32m    479\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    480\u001B[0m     a \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 481\u001B[0m     expr \u001B[38;5;241m=\u001B[39m \u001B[43mparse_expr\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransformations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransformations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaluate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (TokenError, \u001B[38;5;167;01mSyntaxError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m SympifyError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcould not parse \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m a, exc)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\sympy\\parsing\\sympy_parser.py:1052\u001B[0m, in \u001B[0;36mparse_expr\u001B[1;34m(s, local_dict, transformations, global_dict, evaluate)\u001B[0m\n\u001B[0;32m   1050\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1051\u001B[0m     global_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m-> 1052\u001B[0m     \u001B[43mexec\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfrom sympy import *\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mglobal_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1054\u001B[0m     builtins_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mvars\u001B[39m(builtins)\n\u001B[0;32m   1055\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m name, obj \u001B[38;5;129;01min\u001B[39;00m builtins_dict\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[1;32m<string>:1\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'sympy' has no attribute 'assumptions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import estimator\n",
    "\n",
    "new_data = pd.read_csv(\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-08-28_14-31/test.csv\")\n",
    "first_line = new_data.iloc[10]\n",
    "correct_output = first_line[['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]].array\n",
    "#input_data = {key: [first_line[key]] for key in inputs}\n",
    "input_data = {key: np.array([first_line[key]]) for key in inputs}\n",
    "predictions = model.predict(input_data)\n",
    "print(\"Predicted values: \", predictions[0][0])\n",
    "print(\"Correct values: \", correct_output)\n",
    "print(\"the mean squared error is: \", 0.3 * np.linalg.norm(predictions[0] - correct_output) ** 2)\n",
    "error = estimator.percent_error(predictions[0], correct_output)\n",
    "print(\"The percent error is: \", error * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(new_data)):\n",
    "    line = new_data.iloc[i]\n",
    "\n",
    "    correct_output = line[['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]].array\n",
    "\n",
    "    input_data = {key: np.array([line[key]]) for key in inputs}\n",
    "    predictions = model.predict(input_data)\n",
    "    error.append(estimator.percent_error(predictions[0], correct_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean percent error is:  56.559793507707965\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean percent error is: \", np.mean(error) * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "error_dict = {key: [] for key in ['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]}\n",
    "\n",
    "for i in range(len(new_data)):\n",
    "    line = new_data.iloc[i]\n",
    "\n",
    "    correct_output = line[['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]].array\n",
    "\n",
    "    input_data = {key: np.array([line[key]]) for key in inputs}\n",
    "    predictions = model.predict(input_data)\n",
    "\n",
    "    # Calculate the percent error for each output key and append it to the respective list\n",
    "    for j, key in enumerate(error_dict.keys()):\n",
    "        error_dict[key].append(estimator.percent_error(predictions[0][0][j], correct_output[j]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# Initialize a dictionary to hold the error lists for each output key\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean error for decay_0 is: 21.14048892259431 precent\n",
      "The mean error for decay_1 is: 29.513848007879584 precent\n",
      "The mean error for W_0 is: 408.22536167818157 precent\n",
      "The mean error for W_1 is: 32.036623575115335 precent\n",
      "The mean error for J_0 is: 8072.218115692011 precent\n",
      "total error is:  1712.6268875751566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the error dictionary to a DataFrame\n",
    "error_df = pd.DataFrame(error_dict)\n",
    "\n",
    "# Calculate the mean of each error\n",
    "mean_errors = error_df.mean()\n",
    "\n",
    "# Display the results\n",
    "for key, value in mean_errors.items():\n",
    "    print(f\"The mean error for {key} is: {value * 100} precent\")\n",
    "\n",
    "print(\"total error is: \", mean_errors.mean() * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcustom_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorrect_output\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      2\u001B[0m a \u001B[38;5;241m=\u001B[39m custom_loss(predictions[\u001B[38;5;241m0\u001B[39m], correct_output)\n",
      "Cell \u001B[1;32mIn[5], line 44\u001B[0m, in \u001B[0;36mcustom_loss\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Compute the functions based on the given expressions\u001B[39;00m\n\u001B[0;32m     35\u001B[0m f_true \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     36\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m W_true[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_true[\u001B[38;5;241m0\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     37\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_true[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;241m-\u001B[39m(tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m (J_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_true[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     41\u001B[0m ]\n\u001B[0;32m     43\u001B[0m f_pred \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m---> 44\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(\u001B[43mt_values\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mW_pred\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m0\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     45\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;241m-\u001B[39m(tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m W_pred[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m0\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\n\u001B[0;32m     47\u001B[0m         \u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;241m-\u001B[39m(tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     49\u001B[0m ]\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Compute the absolute difference between the true and predicted functions\u001B[39;00m\n\u001B[0;32m     52\u001B[0m loss_t \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_sum([tf\u001B[38;5;241m.\u001B[39mabs(ft \u001B[38;5;241m-\u001B[39m fp) \u001B[38;5;28;01mfor\u001B[39;00m ft, fp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(f_true, f_pred)], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   5981\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[0;32m   5982\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m-> 5983\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul] name: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(custom_loss(predictions[0], correct_output))\n",
    "a = custom_loss(predictions[0], correct_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
