{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import np as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.6f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(filepath_or_buffer=r'C:\\Projects\\Crosstalk\\Machine_Learning\\Data\\2024-09-05_14-55\\large_data.csv')\n",
    "test_df = pd.read_csv(filepath_or_buffer=\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-09-05_14-55/test.csv\")\n",
    "# validation_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/with_decay/no_j/no_j_1000.csv\")\n",
    "\n",
    "# train_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/all_expectation_values_100000.csv\")\n",
    "# test_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/all_expectation_values_100.csv\")\n",
    "# validation_df = pd.read_csv(filepath_or_buffer=\"Z_with_correlations/all_expectation_values_10000.csv\")\n",
    "train_df.head()\n",
    "print(len(train_df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "class TrigonometricLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, t, num_measurements, **kwargs):\n",
    "        super(TrigonometricLayer, self).__init__(**kwargs)\n",
    "        self.t = t  # Time at which measurements are taken\n",
    "        self.num_measurements = num_measurements  # Number of measurement functions\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize trainable parameters\n",
    "\n",
    "        self.trig_weights = self.add_weight(\n",
    "            name='trig_weights',\n",
    "            shape=(20, 8),\n",
    "            initializer=tf.random_uniform_initializer(minval=0.0, maxval=1.0),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        super(TrigonometricLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute each measurement function based on trainable parameters\n",
    "        w0, w1, j, a1, a2 = inputs[:, 0], inputs[:, 1], inputs[:, 2], inputs[:, 3], inputs[:, 4]\n",
    "\n",
    "        x1 = tf.cos(w0 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x2 = tf.cos(w1 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x3 = tf.cos(j * self.t) * tf.exp(- a1 * self.t)\n",
    "        x4 = tf.sin(w0 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x5 = tf.sin(w1 * self.t) * tf.exp(- a1 * self.t)\n",
    "        x6 = tf.sin(j * self.t) * tf.exp(- a1 * self.t)\n",
    "        x7 = tf.cos((w0 + w1) * self.t) * tf.exp(- a1 * self.t)\n",
    "        x8 = tf.cos((w0 + j) * self.t) * tf.exp(- a1 * self.t)\n",
    "        x9 = tf.cos((w1 + j) * self.t) * tf.exp(- a1 * self.t)\n",
    "        x10 = tf.cos((w1 + j + w0) * self.t) * tf.exp(- a1 * self.t)\n",
    "\n",
    "        x11 = tf.cos(w0 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x12 = tf.cos(w1 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x13 = tf.cos(j * self.t) * tf.exp(- a2 * self.t)\n",
    "        x14 = tf.sin(w0 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x15 = tf.sin(w1 * self.t) * tf.exp(- a2 * self.t)\n",
    "        x16 = tf.sin(j * self.t) * tf.exp(- a2 * self.t)\n",
    "        x17 = tf.cos((w0 + w1) * self.t) * tf.exp(- a2 * self.t)\n",
    "        x18 = tf.cos((w0 + j) * self.t) * tf.exp(- a2 * self.t)\n",
    "        x19 = tf.cos((w1 + j) * self.t) * tf.exp(- a2 * self.t)\n",
    "        x20 = tf.cos((w1 + j + w0) * self.t) * tf.exp(- a2 * self.t)\n",
    "\n",
    "        trig_combinations = tf.stack([\n",
    "            x1, x2, x3, x4, x5, x6, x7, x8, x9, x10,\n",
    "            x11, x12, x13, x14, x15, x16, x17, x18, x19, x20\n",
    "        ], axis=-1)\n",
    "\n",
    "        outputs = tf.matmul(trig_combinations, self.trig_weights)  # Shape: (1, num_features)\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 1500\n",
    "batch_size = 500\n",
    "\n",
    "# Get all column names as a list\n",
    "keys = train_df.keys().tolist()\n",
    "# input_keys = ['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]\n",
    "output_keys = [\"decay_0\", \"decay_1\", \"decay_2\", \"decay_3\", \"W_0\", \"W_1\", \"W_2\", \"W_3\", \"J_0\", \"J_1\", \"J_2\"]\n",
    "\n",
    "output_keys = [key for key in keys if key not in input_keys]\n",
    "\n",
    "inputs = {key: tf.keras.layers.Input(shape=(1,), name=key) for key in input_keys}\n",
    "concatenated_inputs = tf.keras.layers.concatenate(list(inputs.values()))\n",
    "\n",
    "# Prepare data for training\n",
    "train_features = {key: train_df[key] for key in inputs}\n",
    "train_labels = train_df[output_keys]\n",
    "\n",
    "# Similarly prepare test and validation data\n",
    "test_features = {key: test_df[key] for key in inputs}\n",
    "test_labels = test_df[output_keys]\n",
    "\n",
    "\n",
    "def build_model(input_layer, num_layers, nodes_per_layer=None, default_nodes=64):\n",
    "    # If no list of nodes is provided, use the default number of nodes for all layers\n",
    "    if nodes_per_layer is None:\n",
    "        nodes_per_layer = [default_nodes] * num_layers\n",
    "\n",
    "    # Check if nodes_per_layer has the correct number of layers\n",
    "    assert len(nodes_per_layer) == num_layers, \"Length of nodes_per_layer must match num_layers\"\n",
    "\n",
    "    # Build the hidden layers dynamically\n",
    "    hidden_layer = input_layer\n",
    "    for i in range(num_layers):\n",
    "        hidden_layer = tf.keras.layers.Dense(nodes_per_layer[i], activation='relu')(hidden_layer)\n",
    "\n",
    "    # Output layer (Assuming len(output_keys) is predefined)\n",
    "    output = tf.keras.layers.Dense(len(output_keys))(hidden_layer)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "nodes_per_layer = [32, 64, 64, 64, 64, 64, 64, 8]  # Optional, can be None\n",
    "output = build_model(concatenated_inputs, len(nodes_per_layer), nodes_per_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 26ms/step - loss: 0.5435 - val_loss: 0.5401\n",
      "Epoch 2/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.5385 - val_loss: 0.5354\n",
      "Epoch 3/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.5341 - val_loss: 0.5295\n",
      "Epoch 4/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.5278 - val_loss: 0.5212\n",
      "Epoch 5/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.5186 - val_loss: 0.5100\n",
      "Epoch 6/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.5077 - val_loss: 0.5007\n",
      "Epoch 7/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.4982 - val_loss: 0.4950\n",
      "Epoch 8/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.4922 - val_loss: 0.4897\n",
      "Epoch 9/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.4887 - val_loss: 0.4850\n",
      "Epoch 10/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4826 - val_loss: 0.4805\n",
      "Epoch 11/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4791 - val_loss: 0.4763\n",
      "Epoch 12/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4728 - val_loss: 0.4719\n",
      "Epoch 13/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.4690 - val_loss: 0.4677\n",
      "Epoch 14/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4661 - val_loss: 0.4638\n",
      "Epoch 15/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.4613 - val_loss: 0.4601\n",
      "Epoch 16/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4569 - val_loss: 0.4567\n",
      "Epoch 17/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.4547 - val_loss: 0.4535\n",
      "Epoch 18/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4511 - val_loss: 0.4506\n",
      "Epoch 19/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4489 - val_loss: 0.4477\n",
      "Epoch 20/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4450 - val_loss: 0.4448\n",
      "Epoch 21/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4430 - val_loss: 0.4420\n",
      "Epoch 22/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4407 - val_loss: 0.4393\n",
      "Epoch 23/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4370 - val_loss: 0.4365\n",
      "Epoch 24/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4348 - val_loss: 0.4337\n",
      "Epoch 25/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4310 - val_loss: 0.4309\n",
      "Epoch 26/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4282 - val_loss: 0.4277\n",
      "Epoch 27/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4261 - val_loss: 0.4248\n",
      "Epoch 28/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.4228 - val_loss: 0.4219\n",
      "Epoch 29/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.4204 - val_loss: 0.4191\n",
      "Epoch 30/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.4159 - val_loss: 0.4165\n",
      "Epoch 31/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.4149 - val_loss: 0.4138\n",
      "Epoch 32/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.4116 - val_loss: 0.4112\n",
      "Epoch 33/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.4096 - val_loss: 0.4087\n",
      "Epoch 34/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.4059 - val_loss: 0.4063\n",
      "Epoch 35/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.4043 - val_loss: 0.4039\n",
      "Epoch 36/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.4020 - val_loss: 0.4016\n",
      "Epoch 37/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3993 - val_loss: 0.3993\n",
      "Epoch 38/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3978 - val_loss: 0.3971\n",
      "Epoch 39/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3948 - val_loss: 0.3949\n",
      "Epoch 40/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3952 - val_loss: 0.3929\n",
      "Epoch 41/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3908 - val_loss: 0.3909\n",
      "Epoch 42/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3871 - val_loss: 0.3889\n",
      "Epoch 43/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3873 - val_loss: 0.3870\n",
      "Epoch 44/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3855 - val_loss: 0.3850\n",
      "Epoch 45/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3819 - val_loss: 0.3832\n",
      "Epoch 46/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3808 - val_loss: 0.3814\n",
      "Epoch 47/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3803 - val_loss: 0.3796\n",
      "Epoch 48/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3784 - val_loss: 0.3778\n",
      "Epoch 49/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3763 - val_loss: 0.3761\n",
      "Epoch 50/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3747 - val_loss: 0.3745\n",
      "Epoch 51/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3726 - val_loss: 0.3729\n",
      "Epoch 52/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3704 - val_loss: 0.3713\n",
      "Epoch 53/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3687 - val_loss: 0.3698\n",
      "Epoch 54/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3686 - val_loss: 0.3683\n",
      "Epoch 55/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3673 - val_loss: 0.3668\n",
      "Epoch 56/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3635 - val_loss: 0.3654\n",
      "Epoch 57/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3622 - val_loss: 0.3641\n",
      "Epoch 58/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3621 - val_loss: 0.3627\n",
      "Epoch 59/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3602 - val_loss: 0.3614\n",
      "Epoch 60/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3600 - val_loss: 0.3603\n",
      "Epoch 61/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3564 - val_loss: 0.3590\n",
      "Epoch 62/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3577 - val_loss: 0.3579\n",
      "Epoch 63/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3581 - val_loss: 0.3568\n",
      "Epoch 64/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3550 - val_loss: 0.3557\n",
      "Epoch 65/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3540 - val_loss: 0.3547\n",
      "Epoch 66/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3514 - val_loss: 0.3538\n",
      "Epoch 67/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3518 - val_loss: 0.3528\n",
      "Epoch 68/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3516 - val_loss: 0.3520\n",
      "Epoch 69/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3504 - val_loss: 0.3511\n",
      "Epoch 70/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3492 - val_loss: 0.3503\n",
      "Epoch 71/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3475 - val_loss: 0.3496\n",
      "Epoch 72/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3467 - val_loss: 0.3488\n",
      "Epoch 73/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3466 - val_loss: 0.3482\n",
      "Epoch 74/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3461 - val_loss: 0.3475\n",
      "Epoch 75/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3462 - val_loss: 0.3469\n",
      "Epoch 76/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3464 - val_loss: 0.3463\n",
      "Epoch 77/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3427 - val_loss: 0.3458\n",
      "Epoch 78/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3443 - val_loss: 0.3452\n",
      "Epoch 79/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3439 - val_loss: 0.3446\n",
      "Epoch 80/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3411 - val_loss: 0.3441\n",
      "Epoch 81/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3407 - val_loss: 0.3436\n",
      "Epoch 82/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3414 - val_loss: 0.3433\n",
      "Epoch 83/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3410 - val_loss: 0.3428\n",
      "Epoch 84/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3391 - val_loss: 0.3424\n",
      "Epoch 85/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3407 - val_loss: 0.3419\n",
      "Epoch 86/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3405 - val_loss: 0.3415\n",
      "Epoch 87/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3403 - val_loss: 0.3411\n",
      "Epoch 88/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3391 - val_loss: 0.3407\n",
      "Epoch 89/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3376 - val_loss: 0.3402\n",
      "Epoch 90/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3376 - val_loss: 0.3399\n",
      "Epoch 91/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3370 - val_loss: 0.3395\n",
      "Epoch 92/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3375 - val_loss: 0.3391\n",
      "Epoch 93/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3364 - val_loss: 0.3388\n",
      "Epoch 94/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3357 - val_loss: 0.3384\n",
      "Epoch 95/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3367 - val_loss: 0.3381\n",
      "Epoch 96/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3364 - val_loss: 0.3377\n",
      "Epoch 97/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3349 - val_loss: 0.3374\n",
      "Epoch 98/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3357 - val_loss: 0.3372\n",
      "Epoch 99/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3335 - val_loss: 0.3368\n",
      "Epoch 100/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3341 - val_loss: 0.3365\n",
      "Epoch 101/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3347 - val_loss: 0.3362\n",
      "Epoch 102/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3334 - val_loss: 0.3359\n",
      "Epoch 103/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3339 - val_loss: 0.3356\n",
      "Epoch 104/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3347 - val_loss: 0.3353\n",
      "Epoch 105/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3330 - val_loss: 0.3350\n",
      "Epoch 106/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3325 - val_loss: 0.3347\n",
      "Epoch 107/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3326 - val_loss: 0.3344\n",
      "Epoch 108/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3328 - val_loss: 0.3342\n",
      "Epoch 109/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3319 - val_loss: 0.3338\n",
      "Epoch 110/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3312 - val_loss: 0.3336\n",
      "Epoch 111/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3321 - val_loss: 0.3333\n",
      "Epoch 112/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3297 - val_loss: 0.3331\n",
      "Epoch 113/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3314 - val_loss: 0.3327\n",
      "Epoch 114/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3311 - val_loss: 0.3325\n",
      "Epoch 115/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3297 - val_loss: 0.3323\n",
      "Epoch 116/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3291 - val_loss: 0.3320\n",
      "Epoch 117/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3302 - val_loss: 0.3317\n",
      "Epoch 118/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3280 - val_loss: 0.3315\n",
      "Epoch 119/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3284 - val_loss: 0.3312\n",
      "Epoch 120/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3289 - val_loss: 0.3309\n",
      "Epoch 121/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3287 - val_loss: 0.3307\n",
      "Epoch 122/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3289 - val_loss: 0.3305\n",
      "Epoch 123/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3278 - val_loss: 0.3302\n",
      "Epoch 124/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3277 - val_loss: 0.3300\n",
      "Epoch 125/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3282 - val_loss: 0.3297\n",
      "Epoch 126/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3266 - val_loss: 0.3294\n",
      "Epoch 127/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3270 - val_loss: 0.3292\n",
      "Epoch 128/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3281 - val_loss: 0.3290\n",
      "Epoch 129/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3281 - val_loss: 0.3287\n",
      "Epoch 130/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3258 - val_loss: 0.3284\n",
      "Epoch 131/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3259 - val_loss: 0.3282\n",
      "Epoch 132/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3263 - val_loss: 0.3279\n",
      "Epoch 133/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3261 - val_loss: 0.3277\n",
      "Epoch 134/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3258 - val_loss: 0.3275\n",
      "Epoch 135/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3231 - val_loss: 0.3272\n",
      "Epoch 136/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3254 - val_loss: 0.3270\n",
      "Epoch 137/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3237 - val_loss: 0.3268\n",
      "Epoch 138/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3243 - val_loss: 0.3265\n",
      "Epoch 139/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3225 - val_loss: 0.3263\n",
      "Epoch 140/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3234 - val_loss: 0.3261\n",
      "Epoch 141/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3233 - val_loss: 0.3259\n",
      "Epoch 142/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3228 - val_loss: 0.3256\n",
      "Epoch 143/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3233 - val_loss: 0.3254\n",
      "Epoch 144/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3224 - val_loss: 0.3252\n",
      "Epoch 145/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3235 - val_loss: 0.3250\n",
      "Epoch 146/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3211 - val_loss: 0.3247\n",
      "Epoch 147/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3217 - val_loss: 0.3246\n",
      "Epoch 148/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3211 - val_loss: 0.3243\n",
      "Epoch 149/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3205 - val_loss: 0.3241\n",
      "Epoch 150/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3228 - val_loss: 0.3239\n",
      "Epoch 151/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3207 - val_loss: 0.3237\n",
      "Epoch 152/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3210 - val_loss: 0.3235\n",
      "Epoch 153/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3206 - val_loss: 0.3233\n",
      "Epoch 154/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3199 - val_loss: 0.3231\n",
      "Epoch 155/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3199 - val_loss: 0.3228\n",
      "Epoch 156/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3199 - val_loss: 0.3226\n",
      "Epoch 157/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3192 - val_loss: 0.3225\n",
      "Epoch 158/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3216 - val_loss: 0.3223\n",
      "Epoch 159/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3201 - val_loss: 0.3221\n",
      "Epoch 160/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3201 - val_loss: 0.3219\n",
      "Epoch 161/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3190 - val_loss: 0.3216\n",
      "Epoch 162/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3188 - val_loss: 0.3215\n",
      "Epoch 163/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3211 - val_loss: 0.3213\n",
      "Epoch 164/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3184 - val_loss: 0.3211\n",
      "Epoch 165/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3196 - val_loss: 0.3210\n",
      "Epoch 166/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3185 - val_loss: 0.3208\n",
      "Epoch 167/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3198 - val_loss: 0.3205\n",
      "Epoch 168/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3180 - val_loss: 0.3203\n",
      "Epoch 169/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3190 - val_loss: 0.3202\n",
      "Epoch 170/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3182 - val_loss: 0.3200\n",
      "Epoch 171/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3200 - val_loss: 0.3199\n",
      "Epoch 172/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3166 - val_loss: 0.3197\n",
      "Epoch 173/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3172 - val_loss: 0.3195\n",
      "Epoch 174/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3174 - val_loss: 0.3193\n",
      "Epoch 175/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3182 - val_loss: 0.3192\n",
      "Epoch 176/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3177 - val_loss: 0.3190\n",
      "Epoch 177/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3169 - val_loss: 0.3188\n",
      "Epoch 178/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3180 - val_loss: 0.3188\n",
      "Epoch 179/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3173 - val_loss: 0.3186\n",
      "Epoch 180/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3147 - val_loss: 0.3184\n",
      "Epoch 181/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3164 - val_loss: 0.3183\n",
      "Epoch 182/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3184 - val_loss: 0.3181\n",
      "Epoch 183/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3164 - val_loss: 0.3179\n",
      "Epoch 184/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3166 - val_loss: 0.3178\n",
      "Epoch 185/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3162 - val_loss: 0.3176\n",
      "Epoch 186/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3157 - val_loss: 0.3175\n",
      "Epoch 187/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3161 - val_loss: 0.3174\n",
      "Epoch 188/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3157 - val_loss: 0.3172\n",
      "Epoch 189/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3149 - val_loss: 0.3171\n",
      "Epoch 190/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3163 - val_loss: 0.3169\n",
      "Epoch 191/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3155 - val_loss: 0.3168\n",
      "Epoch 192/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3155 - val_loss: 0.3167\n",
      "Epoch 193/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3138 - val_loss: 0.3165\n",
      "Epoch 194/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3137 - val_loss: 0.3165\n",
      "Epoch 195/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3150 - val_loss: 0.3162\n",
      "Epoch 196/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3143 - val_loss: 0.3160\n",
      "Epoch 197/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3142 - val_loss: 0.3160\n",
      "Epoch 198/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3141 - val_loss: 0.3158\n",
      "Epoch 199/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3142 - val_loss: 0.3157\n",
      "Epoch 200/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3151 - val_loss: 0.3156\n",
      "Epoch 201/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3112 - val_loss: 0.3154\n",
      "Epoch 202/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3131 - val_loss: 0.3153\n",
      "Epoch 203/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3123 - val_loss: 0.3152\n",
      "Epoch 204/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3129 - val_loss: 0.3151\n",
      "Epoch 205/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3132 - val_loss: 0.3149\n",
      "Epoch 206/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3125 - val_loss: 0.3148\n",
      "Epoch 207/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3129 - val_loss: 0.3147\n",
      "Epoch 208/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3144 - val_loss: 0.3146\n",
      "Epoch 209/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3125 - val_loss: 0.3145\n",
      "Epoch 210/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3128 - val_loss: 0.3143\n",
      "Epoch 211/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3120 - val_loss: 0.3142\n",
      "Epoch 212/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3125 - val_loss: 0.3141\n",
      "Epoch 213/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3110 - val_loss: 0.3140\n",
      "Epoch 214/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3113 - val_loss: 0.3139\n",
      "Epoch 215/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3131 - val_loss: 0.3138\n",
      "Epoch 216/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3117 - val_loss: 0.3137\n",
      "Epoch 217/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3132 - val_loss: 0.3135\n",
      "Epoch 218/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3111 - val_loss: 0.3135\n",
      "Epoch 219/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3116 - val_loss: 0.3133\n",
      "Epoch 220/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3118 - val_loss: 0.3132\n",
      "Epoch 221/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3119 - val_loss: 0.3132\n",
      "Epoch 222/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3108 - val_loss: 0.3131\n",
      "Epoch 223/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3121 - val_loss: 0.3130\n",
      "Epoch 224/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3121 - val_loss: 0.3128\n",
      "Epoch 225/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3116 - val_loss: 0.3128\n",
      "Epoch 226/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3107 - val_loss: 0.3126\n",
      "Epoch 227/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3103 - val_loss: 0.3125\n",
      "Epoch 228/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3112 - val_loss: 0.3124\n",
      "Epoch 229/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3105 - val_loss: 0.3123\n",
      "Epoch 230/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3105 - val_loss: 0.3122\n",
      "Epoch 231/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3106 - val_loss: 0.3121\n",
      "Epoch 232/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3098 - val_loss: 0.3120\n",
      "Epoch 233/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3106 - val_loss: 0.3119\n",
      "Epoch 234/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3082 - val_loss: 0.3119\n",
      "Epoch 235/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3111 - val_loss: 0.3117\n",
      "Epoch 236/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3093 - val_loss: 0.3117\n",
      "Epoch 237/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3119 - val_loss: 0.3116\n",
      "Epoch 238/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3087 - val_loss: 0.3114\n",
      "Epoch 239/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3114 - val_loss: 0.3114\n",
      "Epoch 240/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3093 - val_loss: 0.3113\n",
      "Epoch 241/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3100 - val_loss: 0.3112\n",
      "Epoch 242/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3077 - val_loss: 0.3111\n",
      "Epoch 243/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3086 - val_loss: 0.3110\n",
      "Epoch 244/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3090 - val_loss: 0.3109\n",
      "Epoch 245/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3101 - val_loss: 0.3108\n",
      "Epoch 246/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3107 - val_loss: 0.3108\n",
      "Epoch 247/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3109 - val_loss: 0.3107\n",
      "Epoch 248/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3077 - val_loss: 0.3106\n",
      "Epoch 249/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3096 - val_loss: 0.3105\n",
      "Epoch 250/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3098 - val_loss: 0.3104\n",
      "Epoch 251/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3095 - val_loss: 0.3103\n",
      "Epoch 252/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3088 - val_loss: 0.3103\n",
      "Epoch 253/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3084 - val_loss: 0.3102\n",
      "Epoch 254/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3077 - val_loss: 0.3101\n",
      "Epoch 255/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3085 - val_loss: 0.3100\n",
      "Epoch 256/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3077 - val_loss: 0.3099\n",
      "Epoch 257/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3080 - val_loss: 0.3098\n",
      "Epoch 258/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3067 - val_loss: 0.3097\n",
      "Epoch 259/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3085 - val_loss: 0.3096\n",
      "Epoch 260/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3086 - val_loss: 0.3096\n",
      "Epoch 261/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3082 - val_loss: 0.3095\n",
      "Epoch 262/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3083 - val_loss: 0.3095\n",
      "Epoch 263/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3061 - val_loss: 0.3093\n",
      "Epoch 264/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3079 - val_loss: 0.3093\n",
      "Epoch 265/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3053 - val_loss: 0.3092\n",
      "Epoch 266/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3074 - val_loss: 0.3092\n",
      "Epoch 267/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3060 - val_loss: 0.3091\n",
      "Epoch 268/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3062 - val_loss: 0.3090\n",
      "Epoch 269/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3067 - val_loss: 0.3089\n",
      "Epoch 270/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3072 - val_loss: 0.3088\n",
      "Epoch 271/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3059 - val_loss: 0.3088\n",
      "Epoch 272/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3054 - val_loss: 0.3087\n",
      "Epoch 273/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3064 - val_loss: 0.3086\n",
      "Epoch 274/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3084 - val_loss: 0.3086\n",
      "Epoch 275/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3076 - val_loss: 0.3085\n",
      "Epoch 276/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - loss: 0.3066 - val_loss: 0.3084\n",
      "Epoch 277/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.3056 - val_loss: 0.3084\n",
      "Epoch 278/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3073 - val_loss: 0.3083\n",
      "Epoch 279/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3064 - val_loss: 0.3082\n",
      "Epoch 280/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3074 - val_loss: 0.3081\n",
      "Epoch 281/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3061 - val_loss: 0.3081\n",
      "Epoch 282/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3052 - val_loss: 0.3080\n",
      "Epoch 283/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3060 - val_loss: 0.3079\n",
      "Epoch 284/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.3064 - val_loss: 0.3079\n",
      "Epoch 285/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.3072 - val_loss: 0.3078\n",
      "Epoch 286/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3060 - val_loss: 0.3077\n",
      "Epoch 287/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3068 - val_loss: 0.3076\n",
      "Epoch 288/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3053 - val_loss: 0.3076\n",
      "Epoch 289/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3062 - val_loss: 0.3075\n",
      "Epoch 290/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3054 - val_loss: 0.3074\n",
      "Epoch 291/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3056 - val_loss: 0.3074\n",
      "Epoch 292/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3048 - val_loss: 0.3073\n",
      "Epoch 293/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3058 - val_loss: 0.3072\n",
      "Epoch 294/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3050 - val_loss: 0.3072\n",
      "Epoch 295/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3045 - val_loss: 0.3072\n",
      "Epoch 296/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3048 - val_loss: 0.3070\n",
      "Epoch 297/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3058 - val_loss: 0.3070\n",
      "Epoch 298/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3054 - val_loss: 0.3069\n",
      "Epoch 299/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3055 - val_loss: 0.3069\n",
      "Epoch 300/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3043 - val_loss: 0.3068\n",
      "Epoch 301/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3060 - val_loss: 0.3068\n",
      "Epoch 302/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3050 - val_loss: 0.3067\n",
      "Epoch 303/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3041 - val_loss: 0.3066\n",
      "Epoch 304/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3043 - val_loss: 0.3065\n",
      "Epoch 305/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3035 - val_loss: 0.3065\n",
      "Epoch 306/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3054 - val_loss: 0.3065\n",
      "Epoch 307/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3042 - val_loss: 0.3064\n",
      "Epoch 308/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3051 - val_loss: 0.3063\n",
      "Epoch 309/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3052 - val_loss: 0.3063\n",
      "Epoch 310/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3048 - val_loss: 0.3063\n",
      "Epoch 311/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3035 - val_loss: 0.3061\n",
      "Epoch 312/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3038 - val_loss: 0.3062\n",
      "Epoch 313/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3047 - val_loss: 0.3060\n",
      "Epoch 314/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3049 - val_loss: 0.3060\n",
      "Epoch 315/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3049 - val_loss: 0.3059\n",
      "Epoch 316/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3046 - val_loss: 0.3058\n",
      "Epoch 317/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3037 - val_loss: 0.3058\n",
      "Epoch 318/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3020 - val_loss: 0.3057\n",
      "Epoch 319/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3049 - val_loss: 0.3057\n",
      "Epoch 320/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3038 - val_loss: 0.3056\n",
      "Epoch 321/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3036 - val_loss: 0.3056\n",
      "Epoch 322/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3037 - val_loss: 0.3055\n",
      "Epoch 323/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3039 - val_loss: 0.3055\n",
      "Epoch 324/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3029 - val_loss: 0.3055\n",
      "Epoch 325/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3039 - val_loss: 0.3053\n",
      "Epoch 326/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3038 - val_loss: 0.3053\n",
      "Epoch 327/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3034 - val_loss: 0.3053\n",
      "Epoch 328/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3043 - val_loss: 0.3053\n",
      "Epoch 329/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3047 - val_loss: 0.3051\n",
      "Epoch 330/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3031 - val_loss: 0.3051\n",
      "Epoch 331/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3026 - val_loss: 0.3050\n",
      "Epoch 332/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3039 - val_loss: 0.3050\n",
      "Epoch 333/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3030 - val_loss: 0.3050\n",
      "Epoch 334/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3046 - val_loss: 0.3049\n",
      "Epoch 335/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3033 - val_loss: 0.3049\n",
      "Epoch 336/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3021 - val_loss: 0.3049\n",
      "Epoch 337/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3037 - val_loss: 0.3047\n",
      "Epoch 338/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3029 - val_loss: 0.3048\n",
      "Epoch 339/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3021 - val_loss: 0.3046\n",
      "Epoch 340/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3033 - val_loss: 0.3046\n",
      "Epoch 341/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3031 - val_loss: 0.3046\n",
      "Epoch 342/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3033 - val_loss: 0.3045\n",
      "Epoch 343/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3035 - val_loss: 0.3045\n",
      "Epoch 344/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3018 - val_loss: 0.3044\n",
      "Epoch 345/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3030 - val_loss: 0.3045\n",
      "Epoch 346/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3025 - val_loss: 0.3044\n",
      "Epoch 347/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3032 - val_loss: 0.3044\n",
      "Epoch 348/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3037 - val_loss: 0.3043\n",
      "Epoch 349/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3024 - val_loss: 0.3043\n",
      "Epoch 350/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3014 - val_loss: 0.3042\n",
      "Epoch 351/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3025 - val_loss: 0.3041\n",
      "Epoch 352/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3030 - val_loss: 0.3041\n",
      "Epoch 353/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3022 - val_loss: 0.3041\n",
      "Epoch 354/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3024 - val_loss: 0.3040\n",
      "Epoch 355/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3023 - val_loss: 0.3040\n",
      "Epoch 356/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3017 - val_loss: 0.3041\n",
      "Epoch 357/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3020 - val_loss: 0.3039\n",
      "Epoch 358/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3011 - val_loss: 0.3038\n",
      "Epoch 359/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3025 - val_loss: 0.3038\n",
      "Epoch 360/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3014 - val_loss: 0.3038\n",
      "Epoch 361/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3033 - val_loss: 0.3037\n",
      "Epoch 362/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3017 - val_loss: 0.3037\n",
      "Epoch 363/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3011 - val_loss: 0.3037\n",
      "Epoch 364/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3023 - val_loss: 0.3036\n",
      "Epoch 365/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3030 - val_loss: 0.3036\n",
      "Epoch 366/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3000 - val_loss: 0.3035\n",
      "Epoch 367/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2998 - val_loss: 0.3035\n",
      "Epoch 368/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3017 - val_loss: 0.3034\n",
      "Epoch 369/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3011 - val_loss: 0.3034\n",
      "Epoch 370/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3009 - val_loss: 0.3034\n",
      "Epoch 371/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3008 - val_loss: 0.3033\n",
      "Epoch 372/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3021 - val_loss: 0.3033\n",
      "Epoch 373/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3002 - val_loss: 0.3032\n",
      "Epoch 374/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3026 - val_loss: 0.3032\n",
      "Epoch 375/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3021 - val_loss: 0.3032\n",
      "Epoch 376/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.3030 - val_loss: 0.3031\n",
      "Epoch 377/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3010 - val_loss: 0.3031\n",
      "Epoch 378/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3000 - val_loss: 0.3031\n",
      "Epoch 379/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3036 - val_loss: 0.3032\n",
      "Epoch 380/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3023 - val_loss: 0.3030\n",
      "Epoch 381/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3012 - val_loss: 0.3030\n",
      "Epoch 382/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3005 - val_loss: 0.3030\n",
      "Epoch 383/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3011 - val_loss: 0.3030\n",
      "Epoch 384/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3014 - val_loss: 0.3030\n",
      "Epoch 385/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3018 - val_loss: 0.3029\n",
      "Epoch 386/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3014 - val_loss: 0.3028\n",
      "Epoch 387/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3022 - val_loss: 0.3028\n",
      "Epoch 388/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3006 - val_loss: 0.3028\n",
      "Epoch 389/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2998 - val_loss: 0.3027\n",
      "Epoch 390/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3013 - val_loss: 0.3027\n",
      "Epoch 391/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3006 - val_loss: 0.3027\n",
      "Epoch 392/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3016 - val_loss: 0.3027\n",
      "Epoch 393/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3022 - val_loss: 0.3027\n",
      "Epoch 394/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.3004 - val_loss: 0.3026\n",
      "Epoch 395/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2990 - val_loss: 0.3025\n",
      "Epoch 396/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3014 - val_loss: 0.3025\n",
      "Epoch 397/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3007 - val_loss: 0.3025\n",
      "Epoch 398/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3012 - val_loss: 0.3025\n",
      "Epoch 399/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3018 - val_loss: 0.3024\n",
      "Epoch 400/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3001 - val_loss: 0.3024\n",
      "Epoch 401/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3013 - val_loss: 0.3024\n",
      "Epoch 402/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2998 - val_loss: 0.3023\n",
      "Epoch 403/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3002 - val_loss: 0.3024\n",
      "Epoch 404/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3011 - val_loss: 0.3023\n",
      "Epoch 405/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3016 - val_loss: 0.3023\n",
      "Epoch 406/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3022 - val_loss: 0.3023\n",
      "Epoch 407/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3006 - val_loss: 0.3022\n",
      "Epoch 408/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3000 - val_loss: 0.3022\n",
      "Epoch 409/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3012 - val_loss: 0.3022\n",
      "Epoch 410/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3010 - val_loss: 0.3022\n",
      "Epoch 411/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3002 - val_loss: 0.3021\n",
      "Epoch 412/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3017 - val_loss: 0.3020\n",
      "Epoch 413/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3008 - val_loss: 0.3020\n",
      "Epoch 414/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3009 - val_loss: 0.3020\n",
      "Epoch 415/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3009 - val_loss: 0.3020\n",
      "Epoch 416/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.3018 - val_loss: 0.3020\n",
      "Epoch 417/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2998 - val_loss: 0.3019\n",
      "Epoch 418/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3018 - val_loss: 0.3019\n",
      "Epoch 419/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3006 - val_loss: 0.3019\n",
      "Epoch 420/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2994 - val_loss: 0.3019\n",
      "Epoch 421/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2999 - val_loss: 0.3018\n",
      "Epoch 422/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3017 - val_loss: 0.3018\n",
      "Epoch 423/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3002 - val_loss: 0.3018\n",
      "Epoch 424/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3037 - val_loss: 0.3018\n",
      "Epoch 425/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3003 - val_loss: 0.3017\n",
      "Epoch 426/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2990 - val_loss: 0.3017\n",
      "Epoch 427/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3005 - val_loss: 0.3017\n",
      "Epoch 428/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3020 - val_loss: 0.3017\n",
      "Epoch 429/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2993 - val_loss: 0.3017\n",
      "Epoch 430/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2995 - val_loss: 0.3016\n",
      "Epoch 431/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3005 - val_loss: 0.3016\n",
      "Epoch 432/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2996 - val_loss: 0.3016\n",
      "Epoch 433/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3007 - val_loss: 0.3016\n",
      "Epoch 434/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3006 - val_loss: 0.3015\n",
      "Epoch 435/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3006 - val_loss: 0.3015\n",
      "Epoch 436/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3000 - val_loss: 0.3015\n",
      "Epoch 437/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3003 - val_loss: 0.3015\n",
      "Epoch 438/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3011 - val_loss: 0.3015\n",
      "Epoch 439/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2990 - val_loss: 0.3014\n",
      "Epoch 440/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3003 - val_loss: 0.3014\n",
      "Epoch 441/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2992 - val_loss: 0.3014\n",
      "Epoch 442/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3005 - val_loss: 0.3013\n",
      "Epoch 443/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2990 - val_loss: 0.3014\n",
      "Epoch 444/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2995 - val_loss: 0.3013\n",
      "Epoch 445/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2991 - val_loss: 0.3013\n",
      "Epoch 446/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2997 - val_loss: 0.3013\n",
      "Epoch 447/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2984 - val_loss: 0.3013\n",
      "Epoch 448/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.3001 - val_loss: 0.3012\n",
      "Epoch 449/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3005 - val_loss: 0.3012\n",
      "Epoch 450/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2997 - val_loss: 0.3012\n",
      "Epoch 451/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2994 - val_loss: 0.3012\n",
      "Epoch 452/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2997 - val_loss: 0.3012\n",
      "Epoch 453/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2996 - val_loss: 0.3011\n",
      "Epoch 454/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2997 - val_loss: 0.3011\n",
      "Epoch 455/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2987 - val_loss: 0.3011\n",
      "Epoch 456/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2992 - val_loss: 0.3011\n",
      "Epoch 457/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2997 - val_loss: 0.3011\n",
      "Epoch 458/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3007 - val_loss: 0.3011\n",
      "Epoch 459/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2984 - val_loss: 0.3011\n",
      "Epoch 460/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3003 - val_loss: 0.3011\n",
      "Epoch 461/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2995 - val_loss: 0.3010\n",
      "Epoch 462/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2993 - val_loss: 0.3010\n",
      "Epoch 463/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3002 - val_loss: 0.3009\n",
      "Epoch 464/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2983 - val_loss: 0.3010\n",
      "Epoch 465/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3003 - val_loss: 0.3009\n",
      "Epoch 466/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3001 - val_loss: 0.3009\n",
      "Epoch 467/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3000 - val_loss: 0.3009\n",
      "Epoch 468/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3000 - val_loss: 0.3008\n",
      "Epoch 469/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2994 - val_loss: 0.3008\n",
      "Epoch 470/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2996 - val_loss: 0.3008\n",
      "Epoch 471/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2997 - val_loss: 0.3008\n",
      "Epoch 472/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3001 - val_loss: 0.3007\n",
      "Epoch 473/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3009 - val_loss: 0.3008\n",
      "Epoch 474/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2978 - val_loss: 0.3007\n",
      "Epoch 475/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2998 - val_loss: 0.3008\n",
      "Epoch 476/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2993 - val_loss: 0.3007\n",
      "Epoch 477/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3006 - val_loss: 0.3007\n",
      "Epoch 478/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2999 - val_loss: 0.3007\n",
      "Epoch 479/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2994 - val_loss: 0.3007\n",
      "Epoch 480/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3015 - val_loss: 0.3006\n",
      "Epoch 481/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3010 - val_loss: 0.3007\n",
      "Epoch 482/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2994 - val_loss: 0.3006\n",
      "Epoch 483/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2991 - val_loss: 0.3006\n",
      "Epoch 484/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 0.2986 - val_loss: 0.3006\n",
      "Epoch 485/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2989 - val_loss: 0.3006\n",
      "Epoch 486/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3008 - val_loss: 0.3006\n",
      "Epoch 487/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2994 - val_loss: 0.3005\n",
      "Epoch 488/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2986 - val_loss: 0.3005\n",
      "Epoch 489/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2996 - val_loss: 0.3005\n",
      "Epoch 490/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2995 - val_loss: 0.3005\n",
      "Epoch 491/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2999 - val_loss: 0.3005\n",
      "Epoch 492/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2997 - val_loss: 0.3005\n",
      "Epoch 493/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2975 - val_loss: 0.3005\n",
      "Epoch 494/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2992 - val_loss: 0.3004\n",
      "Epoch 495/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2985 - val_loss: 0.3004\n",
      "Epoch 496/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2983 - val_loss: 0.3004\n",
      "Epoch 497/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2988 - val_loss: 0.3004\n",
      "Epoch 498/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2987 - val_loss: 0.3004\n",
      "Epoch 499/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2982 - val_loss: 0.3004\n",
      "Epoch 500/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2979 - val_loss: 0.3004\n",
      "Epoch 501/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2981 - val_loss: 0.3004\n",
      "Epoch 502/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.3001 - val_loss: 0.3003\n",
      "Epoch 503/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2988 - val_loss: 0.3003\n",
      "Epoch 504/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2997 - val_loss: 0.3003\n",
      "Epoch 505/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2986 - val_loss: 0.3003\n",
      "Epoch 506/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2977 - val_loss: 0.3002\n",
      "Epoch 507/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2977 - val_loss: 0.3003\n",
      "Epoch 508/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3011 - val_loss: 0.3002\n",
      "Epoch 509/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2986 - val_loss: 0.3002\n",
      "Epoch 510/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3007 - val_loss: 0.3002\n",
      "Epoch 511/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3001 - val_loss: 0.3003\n",
      "Epoch 512/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.3001 - val_loss: 0.3002\n",
      "Epoch 513/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2995 - val_loss: 0.3002\n",
      "Epoch 514/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2985 - val_loss: 0.3001\n",
      "Epoch 515/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2980 - val_loss: 0.3001\n",
      "Epoch 516/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2981 - val_loss: 0.3001\n",
      "Epoch 517/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2985 - val_loss: 0.3001\n",
      "Epoch 518/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2968 - val_loss: 0.3001\n",
      "Epoch 519/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2995 - val_loss: 0.3000\n",
      "Epoch 520/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2974 - val_loss: 0.3000\n",
      "Epoch 521/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2979 - val_loss: 0.3000\n",
      "Epoch 522/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2997 - val_loss: 0.3000\n",
      "Epoch 523/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2977 - val_loss: 0.3000\n",
      "Epoch 524/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.2990 - val_loss: 0.3000\n",
      "Epoch 525/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.2985 - val_loss: 0.3000\n",
      "Epoch 526/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2977 - val_loss: 0.3000\n",
      "Epoch 527/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2986 - val_loss: 0.3000\n",
      "Epoch 528/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.2989 - val_loss: 0.3000\n",
      "Epoch 529/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.2993 - val_loss: 0.2999\n",
      "Epoch 530/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2993 - val_loss: 0.3000\n",
      "Epoch 531/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2971 - val_loss: 0.2999\n",
      "Epoch 532/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2986 - val_loss: 0.2999\n",
      "Epoch 533/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2970 - val_loss: 0.2999\n",
      "Epoch 534/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2985 - val_loss: 0.2998\n",
      "Epoch 535/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2992 - val_loss: 0.2998\n",
      "Epoch 536/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2986 - val_loss: 0.2998\n",
      "Epoch 537/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2987 - val_loss: 0.2998\n",
      "Epoch 538/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2971 - val_loss: 0.2998\n",
      "Epoch 539/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2980 - val_loss: 0.2998\n",
      "Epoch 540/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2987 - val_loss: 0.2999\n",
      "Epoch 541/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2988 - val_loss: 0.2999\n",
      "Epoch 542/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2999 - val_loss: 0.2998\n",
      "Epoch 543/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2983 - val_loss: 0.2998\n",
      "Epoch 544/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2979 - val_loss: 0.2997\n",
      "Epoch 545/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2986 - val_loss: 0.2997\n",
      "Epoch 546/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2977 - val_loss: 0.2997\n",
      "Epoch 547/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2990 - val_loss: 0.2997\n",
      "Epoch 548/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2979 - val_loss: 0.2997\n",
      "Epoch 549/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2991 - val_loss: 0.2997\n",
      "Epoch 550/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2992 - val_loss: 0.2997\n",
      "Epoch 551/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2968 - val_loss: 0.2996\n",
      "Epoch 552/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2982 - val_loss: 0.2996\n",
      "Epoch 553/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2964 - val_loss: 0.2997\n",
      "Epoch 554/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2979 - val_loss: 0.2996\n",
      "Epoch 555/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2983 - val_loss: 0.2996\n",
      "Epoch 556/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2977 - val_loss: 0.2996\n",
      "Epoch 557/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2988 - val_loss: 0.2996\n",
      "Epoch 558/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2984 - val_loss: 0.2996\n",
      "Epoch 559/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2966 - val_loss: 0.2996\n",
      "Epoch 560/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2971 - val_loss: 0.2995\n",
      "Epoch 561/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2977 - val_loss: 0.2996\n",
      "Epoch 562/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2966 - val_loss: 0.2996\n",
      "Epoch 563/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2981 - val_loss: 0.2995\n",
      "Epoch 564/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2981 - val_loss: 0.2995\n",
      "Epoch 565/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2974 - val_loss: 0.2995\n",
      "Epoch 566/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2973 - val_loss: 0.2995\n",
      "Epoch 567/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2974 - val_loss: 0.2995\n",
      "Epoch 568/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2982 - val_loss: 0.2995\n",
      "Epoch 569/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2981 - val_loss: 0.2995\n",
      "Epoch 570/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2987 - val_loss: 0.2995\n",
      "Epoch 571/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2980 - val_loss: 0.2994\n",
      "Epoch 572/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2996 - val_loss: 0.2994\n",
      "Epoch 573/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2968 - val_loss: 0.2995\n",
      "Epoch 574/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2978 - val_loss: 0.2994\n",
      "Epoch 575/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2966 - val_loss: 0.2994\n",
      "Epoch 576/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2974 - val_loss: 0.2994\n",
      "Epoch 577/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2987 - val_loss: 0.2994\n",
      "Epoch 578/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2987 - val_loss: 0.2994\n",
      "Epoch 579/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2977 - val_loss: 0.2993\n",
      "Epoch 580/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2980 - val_loss: 0.2993\n",
      "Epoch 581/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2977 - val_loss: 0.2993\n",
      "Epoch 582/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2985 - val_loss: 0.2993\n",
      "Epoch 583/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2982 - val_loss: 0.2993\n",
      "Epoch 584/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2981 - val_loss: 0.2993\n",
      "Epoch 585/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2976 - val_loss: 0.2993\n",
      "Epoch 586/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2979 - val_loss: 0.2993\n",
      "Epoch 587/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2993 - val_loss: 0.2993\n",
      "Epoch 588/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2978 - val_loss: 0.2993\n",
      "Epoch 589/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2992 - val_loss: 0.2992\n",
      "Epoch 590/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2978 - val_loss: 0.2993\n",
      "Epoch 591/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2987 - val_loss: 0.2992\n",
      "Epoch 592/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2971 - val_loss: 0.2992\n",
      "Epoch 593/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2979 - val_loss: 0.2992\n",
      "Epoch 594/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2989 - val_loss: 0.2992\n",
      "Epoch 595/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2979 - val_loss: 0.2992\n",
      "Epoch 596/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2981 - val_loss: 0.2992\n",
      "Epoch 597/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2994 - val_loss: 0.2992\n",
      "Epoch 598/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2982 - val_loss: 0.2991\n",
      "Epoch 599/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2986 - val_loss: 0.2991\n",
      "Epoch 600/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2973 - val_loss: 0.2991\n",
      "Epoch 601/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2990 - val_loss: 0.2991\n",
      "Epoch 602/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2983 - val_loss: 0.2991\n",
      "Epoch 603/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2979 - val_loss: 0.2991\n",
      "Epoch 604/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2974 - val_loss: 0.2991\n",
      "Epoch 605/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2988 - val_loss: 0.2991\n",
      "Epoch 606/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2985 - val_loss: 0.2990\n",
      "Epoch 607/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.3000 - val_loss: 0.2990\n",
      "Epoch 608/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2989 - val_loss: 0.2990\n",
      "Epoch 609/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2977 - val_loss: 0.2990\n",
      "Epoch 610/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2962 - val_loss: 0.2990\n",
      "Epoch 611/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2977 - val_loss: 0.2990\n",
      "Epoch 612/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2990 - val_loss: 0.2990\n",
      "Epoch 613/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2974 - val_loss: 0.2989\n",
      "Epoch 614/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2974 - val_loss: 0.2990\n",
      "Epoch 615/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2974 - val_loss: 0.2990\n",
      "Epoch 616/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2989 - val_loss: 0.2989\n",
      "Epoch 617/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2975 - val_loss: 0.2990\n",
      "Epoch 618/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2978 - val_loss: 0.2990\n",
      "Epoch 619/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2976 - val_loss: 0.2989\n",
      "Epoch 620/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2985 - val_loss: 0.2989\n",
      "Epoch 621/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2978 - val_loss: 0.2989\n",
      "Epoch 622/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2971 - val_loss: 0.2989\n",
      "Epoch 623/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2983 - val_loss: 0.2988\n",
      "Epoch 624/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2977 - val_loss: 0.2989\n",
      "Epoch 625/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2988 - val_loss: 0.2989\n",
      "Epoch 626/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2974 - val_loss: 0.2988\n",
      "Epoch 627/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2987 - val_loss: 0.2988\n",
      "Epoch 628/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2976 - val_loss: 0.2988\n",
      "Epoch 629/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2972 - val_loss: 0.2988\n",
      "Epoch 630/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2970 - val_loss: 0.2990\n",
      "Epoch 631/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2959 - val_loss: 0.2988\n",
      "Epoch 632/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2982 - val_loss: 0.2988\n",
      "Epoch 633/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2963 - val_loss: 0.2988\n",
      "Epoch 634/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2984 - val_loss: 0.2987\n",
      "Epoch 635/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2990 - val_loss: 0.2987\n",
      "Epoch 636/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2976 - val_loss: 0.2988\n",
      "Epoch 637/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2975 - val_loss: 0.2987\n",
      "Epoch 638/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2974 - val_loss: 0.2987\n",
      "Epoch 639/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2966 - val_loss: 0.2987\n",
      "Epoch 640/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.2975 - val_loss: 0.2987\n",
      "Epoch 641/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.2963 - val_loss: 0.2987\n",
      "Epoch 642/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2968 - val_loss: 0.2987\n",
      "Epoch 643/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2970 - val_loss: 0.2987\n",
      "Epoch 644/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2983 - val_loss: 0.2987\n",
      "Epoch 645/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2978 - val_loss: 0.2987\n",
      "Epoch 646/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2987 - val_loss: 0.2987\n",
      "Epoch 647/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2986 - val_loss: 0.2987\n",
      "Epoch 648/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2974 - val_loss: 0.2986\n",
      "Epoch 649/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2965 - val_loss: 0.2986\n",
      "Epoch 650/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2967 - val_loss: 0.2986\n",
      "Epoch 651/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2957 - val_loss: 0.2986\n",
      "Epoch 652/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2963 - val_loss: 0.2986\n",
      "Epoch 653/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2992 - val_loss: 0.2986\n",
      "Epoch 654/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2985 - val_loss: 0.2985\n",
      "Epoch 655/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2984 - val_loss: 0.2987\n",
      "Epoch 656/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2965 - val_loss: 0.2986\n",
      "Epoch 657/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2981 - val_loss: 0.2986\n",
      "Epoch 658/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2971 - val_loss: 0.2985\n",
      "Epoch 659/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2978 - val_loss: 0.2985\n",
      "Epoch 660/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2992 - val_loss: 0.2986\n",
      "Epoch 661/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2983 - val_loss: 0.2985\n",
      "Epoch 662/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2982 - val_loss: 0.2985\n",
      "Epoch 663/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2969 - val_loss: 0.2985\n",
      "Epoch 664/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2976 - val_loss: 0.2985\n",
      "Epoch 665/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2968 - val_loss: 0.2985\n",
      "Epoch 666/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2961 - val_loss: 0.2984\n",
      "Epoch 667/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2974 - val_loss: 0.2984\n",
      "Epoch 668/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2969 - val_loss: 0.2984\n",
      "Epoch 669/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2972 - val_loss: 0.2985\n",
      "Epoch 670/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2973 - val_loss: 0.2984\n",
      "Epoch 671/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2969 - val_loss: 0.2984\n",
      "Epoch 672/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2977 - val_loss: 0.2984\n",
      "Epoch 673/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2969 - val_loss: 0.2984\n",
      "Epoch 674/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2982 - val_loss: 0.2984\n",
      "Epoch 675/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2964 - val_loss: 0.2984\n",
      "Epoch 676/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2964 - val_loss: 0.2983\n",
      "Epoch 677/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2964 - val_loss: 0.2984\n",
      "Epoch 678/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2949 - val_loss: 0.2984\n",
      "Epoch 679/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2967 - val_loss: 0.2983\n",
      "Epoch 680/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2993 - val_loss: 0.2983\n",
      "Epoch 681/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2969 - val_loss: 0.2983\n",
      "Epoch 682/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2961 - val_loss: 0.2983\n",
      "Epoch 683/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2969 - val_loss: 0.2983\n",
      "Epoch 684/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2957 - val_loss: 0.2983\n",
      "Epoch 685/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2984 - val_loss: 0.2983\n",
      "Epoch 686/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2977 - val_loss: 0.2983\n",
      "Epoch 687/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2968 - val_loss: 0.2983\n",
      "Epoch 688/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2974 - val_loss: 0.2982\n",
      "Epoch 689/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2975 - val_loss: 0.2983\n",
      "Epoch 690/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2968 - val_loss: 0.2983\n",
      "Epoch 691/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2969 - val_loss: 0.2982\n",
      "Epoch 692/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2966 - val_loss: 0.2982\n",
      "Epoch 693/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.2972 - val_loss: 0.2982\n",
      "Epoch 694/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.2974 - val_loss: 0.2982\n",
      "Epoch 695/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2962 - val_loss: 0.2982\n",
      "Epoch 696/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2976 - val_loss: 0.2982\n",
      "Epoch 697/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2956 - val_loss: 0.2982\n",
      "Epoch 698/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2956 - val_loss: 0.2982\n",
      "Epoch 699/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2988 - val_loss: 0.2982\n",
      "Epoch 700/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2965 - val_loss: 0.2982\n",
      "Epoch 701/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2969 - val_loss: 0.2981\n",
      "Epoch 702/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2960 - val_loss: 0.2982\n",
      "Epoch 703/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2976 - val_loss: 0.2981\n",
      "Epoch 704/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2961 - val_loss: 0.2981\n",
      "Epoch 705/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2974 - val_loss: 0.2981\n",
      "Epoch 706/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2972 - val_loss: 0.2981\n",
      "Epoch 707/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.2977 - val_loss: 0.2981\n",
      "Epoch 708/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2971 - val_loss: 0.2981\n",
      "Epoch 709/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2963 - val_loss: 0.2980\n",
      "Epoch 710/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2964 - val_loss: 0.2980\n",
      "Epoch 711/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2976 - val_loss: 0.2980\n",
      "Epoch 712/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2976 - val_loss: 0.2980\n",
      "Epoch 713/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2960 - val_loss: 0.2980\n",
      "Epoch 714/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2952 - val_loss: 0.2980\n",
      "Epoch 715/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2958 - val_loss: 0.2980\n",
      "Epoch 716/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2968 - val_loss: 0.2980\n",
      "Epoch 717/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2959 - val_loss: 0.2980\n",
      "Epoch 718/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2971 - val_loss: 0.2980\n",
      "Epoch 719/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2972 - val_loss: 0.2979\n",
      "Epoch 720/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2965 - val_loss: 0.2979\n",
      "Epoch 721/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2976 - val_loss: 0.2979\n",
      "Epoch 722/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2962 - val_loss: 0.2979\n",
      "Epoch 723/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2964 - val_loss: 0.2979\n",
      "Epoch 724/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2945 - val_loss: 0.2979\n",
      "Epoch 725/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2970 - val_loss: 0.2979\n",
      "Epoch 726/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2974 - val_loss: 0.2979\n",
      "Epoch 727/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2967 - val_loss: 0.2979\n",
      "Epoch 728/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2970 - val_loss: 0.2979\n",
      "Epoch 729/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2954 - val_loss: 0.2978\n",
      "Epoch 730/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2963 - val_loss: 0.2978\n",
      "Epoch 731/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2970 - val_loss: 0.2978\n",
      "Epoch 732/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2959 - val_loss: 0.2978\n",
      "Epoch 733/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2978\n",
      "Epoch 734/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2974 - val_loss: 0.2978\n",
      "Epoch 735/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2969 - val_loss: 0.2978\n",
      "Epoch 736/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2974 - val_loss: 0.2978\n",
      "Epoch 737/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2984 - val_loss: 0.2978\n",
      "Epoch 738/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2963 - val_loss: 0.2978\n",
      "Epoch 739/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2972 - val_loss: 0.2978\n",
      "Epoch 740/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2965 - val_loss: 0.2978\n",
      "Epoch 741/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2968 - val_loss: 0.2978\n",
      "Epoch 742/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2957 - val_loss: 0.2977\n",
      "Epoch 743/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2958 - val_loss: 0.2977\n",
      "Epoch 744/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2968 - val_loss: 0.2977\n",
      "Epoch 745/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2965 - val_loss: 0.2978\n",
      "Epoch 746/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2964 - val_loss: 0.2977\n",
      "Epoch 747/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2983 - val_loss: 0.2977\n",
      "Epoch 748/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2949 - val_loss: 0.2976\n",
      "Epoch 749/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2955 - val_loss: 0.2976\n",
      "Epoch 750/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2960 - val_loss: 0.2976\n",
      "Epoch 751/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2962 - val_loss: 0.2977\n",
      "Epoch 752/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2974 - val_loss: 0.2976\n",
      "Epoch 753/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2961 - val_loss: 0.2976\n",
      "Epoch 754/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2964 - val_loss: 0.2976\n",
      "Epoch 755/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2958 - val_loss: 0.2976\n",
      "Epoch 756/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2963 - val_loss: 0.2977\n",
      "Epoch 757/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2971 - val_loss: 0.2976\n",
      "Epoch 758/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2950 - val_loss: 0.2976\n",
      "Epoch 759/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2966 - val_loss: 0.2976\n",
      "Epoch 760/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2970 - val_loss: 0.2975\n",
      "Epoch 761/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2967 - val_loss: 0.2975\n",
      "Epoch 762/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2963 - val_loss: 0.2975\n",
      "Epoch 763/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2963 - val_loss: 0.2975\n",
      "Epoch 764/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2967 - val_loss: 0.2976\n",
      "Epoch 765/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2965 - val_loss: 0.2975\n",
      "Epoch 766/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2972 - val_loss: 0.2975\n",
      "Epoch 767/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2965 - val_loss: 0.2975\n",
      "Epoch 768/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2975\n",
      "Epoch 769/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2963 - val_loss: 0.2975\n",
      "Epoch 770/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2976 - val_loss: 0.2975\n",
      "Epoch 771/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2972 - val_loss: 0.2974\n",
      "Epoch 772/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2960 - val_loss: 0.2974\n",
      "Epoch 773/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2974\n",
      "Epoch 774/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2974\n",
      "Epoch 775/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2958 - val_loss: 0.2974\n",
      "Epoch 776/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2971 - val_loss: 0.2975\n",
      "Epoch 777/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2972 - val_loss: 0.2974\n",
      "Epoch 778/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2969 - val_loss: 0.2974\n",
      "Epoch 779/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2979 - val_loss: 0.2973\n",
      "Epoch 780/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2956 - val_loss: 0.2974\n",
      "Epoch 781/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2965 - val_loss: 0.2974\n",
      "Epoch 782/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2973 - val_loss: 0.2973\n",
      "Epoch 783/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2983 - val_loss: 0.2973\n",
      "Epoch 784/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2966 - val_loss: 0.2973\n",
      "Epoch 785/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2965 - val_loss: 0.2974\n",
      "Epoch 786/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2973\n",
      "Epoch 787/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2950 - val_loss: 0.2973\n",
      "Epoch 788/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2961 - val_loss: 0.2973\n",
      "Epoch 789/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2964 - val_loss: 0.2973\n",
      "Epoch 790/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2964 - val_loss: 0.2973\n",
      "Epoch 791/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2960 - val_loss: 0.2973\n",
      "Epoch 792/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2960 - val_loss: 0.2973\n",
      "Epoch 793/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2972\n",
      "Epoch 794/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2969 - val_loss: 0.2972\n",
      "Epoch 795/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2944 - val_loss: 0.2972\n",
      "Epoch 796/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2968 - val_loss: 0.2973\n",
      "Epoch 797/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2962 - val_loss: 0.2973\n",
      "Epoch 798/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2971 - val_loss: 0.2972\n",
      "Epoch 799/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2972\n",
      "Epoch 800/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2956 - val_loss: 0.2973\n",
      "Epoch 801/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2967 - val_loss: 0.2971\n",
      "Epoch 802/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2971\n",
      "Epoch 803/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2955 - val_loss: 0.2972\n",
      "Epoch 804/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2972\n",
      "Epoch 805/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2971\n",
      "Epoch 806/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2948 - val_loss: 0.2971\n",
      "Epoch 807/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2955 - val_loss: 0.2971\n",
      "Epoch 808/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2960 - val_loss: 0.2971\n",
      "Epoch 809/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2971 - val_loss: 0.2971\n",
      "Epoch 810/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2952 - val_loss: 0.2971\n",
      "Epoch 811/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2974 - val_loss: 0.2970\n",
      "Epoch 812/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2971 - val_loss: 0.2971\n",
      "Epoch 813/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2971\n",
      "Epoch 814/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2968 - val_loss: 0.2970\n",
      "Epoch 815/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2951 - val_loss: 0.2971\n",
      "Epoch 816/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2965 - val_loss: 0.2970\n",
      "Epoch 817/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2947 - val_loss: 0.2970\n",
      "Epoch 818/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2968 - val_loss: 0.2970\n",
      "Epoch 819/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2964 - val_loss: 0.2970\n",
      "Epoch 820/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2963 - val_loss: 0.2970\n",
      "Epoch 821/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2956 - val_loss: 0.2970\n",
      "Epoch 822/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2970\n",
      "Epoch 823/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2961 - val_loss: 0.2970\n",
      "Epoch 824/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2971 - val_loss: 0.2970\n",
      "Epoch 825/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2969\n",
      "Epoch 826/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2958 - val_loss: 0.2969\n",
      "Epoch 827/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2957 - val_loss: 0.2969\n",
      "Epoch 828/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2969\n",
      "Epoch 829/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2948 - val_loss: 0.2969\n",
      "Epoch 830/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2958 - val_loss: 0.2969\n",
      "Epoch 831/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2959 - val_loss: 0.2968\n",
      "Epoch 832/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2958 - val_loss: 0.2969\n",
      "Epoch 833/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2954 - val_loss: 0.2969\n",
      "Epoch 834/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2983 - val_loss: 0.2968\n",
      "Epoch 835/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2945 - val_loss: 0.2970\n",
      "Epoch 836/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2947 - val_loss: 0.2969\n",
      "Epoch 837/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2958 - val_loss: 0.2968\n",
      "Epoch 838/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2960 - val_loss: 0.2968\n",
      "Epoch 839/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2951 - val_loss: 0.2968\n",
      "Epoch 840/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2951 - val_loss: 0.2968\n",
      "Epoch 841/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2969 - val_loss: 0.2968\n",
      "Epoch 842/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2950 - val_loss: 0.2968\n",
      "Epoch 843/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2964 - val_loss: 0.2967\n",
      "Epoch 844/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2968\n",
      "Epoch 845/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2968\n",
      "Epoch 846/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2945 - val_loss: 0.2967\n",
      "Epoch 847/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2962 - val_loss: 0.2967\n",
      "Epoch 848/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2950 - val_loss: 0.2967\n",
      "Epoch 849/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2967\n",
      "Epoch 850/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2962 - val_loss: 0.2967\n",
      "Epoch 851/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2967\n",
      "Epoch 852/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2967\n",
      "Epoch 853/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2962 - val_loss: 0.2967\n",
      "Epoch 854/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2966\n",
      "Epoch 855/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2967 - val_loss: 0.2966\n",
      "Epoch 856/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2967 - val_loss: 0.2966\n",
      "Epoch 857/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2966\n",
      "Epoch 858/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2967\n",
      "Epoch 859/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2960 - val_loss: 0.2966\n",
      "Epoch 860/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2950 - val_loss: 0.2966\n",
      "Epoch 861/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2966\n",
      "Epoch 862/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2950 - val_loss: 0.2965\n",
      "Epoch 863/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2948 - val_loss: 0.2966\n",
      "Epoch 864/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2943 - val_loss: 0.2966\n",
      "Epoch 865/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2940 - val_loss: 0.2965\n",
      "Epoch 866/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2966 - val_loss: 0.2966\n",
      "Epoch 867/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2966\n",
      "Epoch 868/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2941 - val_loss: 0.2965\n",
      "Epoch 869/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2965\n",
      "Epoch 870/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2933 - val_loss: 0.2965\n",
      "Epoch 871/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2947 - val_loss: 0.2965\n",
      "Epoch 872/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2959 - val_loss: 0.2965\n",
      "Epoch 873/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2969 - val_loss: 0.2964\n",
      "Epoch 874/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2964\n",
      "Epoch 875/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2964\n",
      "Epoch 876/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2966 - val_loss: 0.2964\n",
      "Epoch 877/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2964\n",
      "Epoch 878/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2965 - val_loss: 0.2964\n",
      "Epoch 879/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2954 - val_loss: 0.2964\n",
      "Epoch 880/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2952 - val_loss: 0.2965\n",
      "Epoch 881/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2955 - val_loss: 0.2964\n",
      "Epoch 882/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2950 - val_loss: 0.2963\n",
      "Epoch 883/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2951 - val_loss: 0.2963\n",
      "Epoch 884/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2964\n",
      "Epoch 885/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2951 - val_loss: 0.2963\n",
      "Epoch 886/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2958 - val_loss: 0.2963\n",
      "Epoch 887/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2951 - val_loss: 0.2963\n",
      "Epoch 888/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2954 - val_loss: 0.2963\n",
      "Epoch 889/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2954 - val_loss: 0.2963\n",
      "Epoch 890/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2948 - val_loss: 0.2963\n",
      "Epoch 891/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2948 - val_loss: 0.2963\n",
      "Epoch 892/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2954 - val_loss: 0.2963\n",
      "Epoch 893/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2946 - val_loss: 0.2963\n",
      "Epoch 894/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2955 - val_loss: 0.2962\n",
      "Epoch 895/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2955 - val_loss: 0.2962\n",
      "Epoch 896/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2962 - val_loss: 0.2962\n",
      "Epoch 897/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2956 - val_loss: 0.2963\n",
      "Epoch 898/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2948 - val_loss: 0.2962\n",
      "Epoch 899/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2949 - val_loss: 0.2962\n",
      "Epoch 900/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2940 - val_loss: 0.2962\n",
      "Epoch 901/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2957 - val_loss: 0.2962\n",
      "Epoch 902/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2944 - val_loss: 0.2962\n",
      "Epoch 903/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2958 - val_loss: 0.2962\n",
      "Epoch 904/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2938 - val_loss: 0.2962\n",
      "Epoch 905/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2961\n",
      "Epoch 906/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2946 - val_loss: 0.2961\n",
      "Epoch 907/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2961\n",
      "Epoch 908/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2938 - val_loss: 0.2961\n",
      "Epoch 909/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2949 - val_loss: 0.2961\n",
      "Epoch 910/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2936 - val_loss: 0.2961\n",
      "Epoch 911/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2955 - val_loss: 0.2961\n",
      "Epoch 912/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2947 - val_loss: 0.2961\n",
      "Epoch 913/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2958 - val_loss: 0.2961\n",
      "Epoch 914/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2942 - val_loss: 0.2960\n",
      "Epoch 915/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2946 - val_loss: 0.2960\n",
      "Epoch 916/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2952 - val_loss: 0.2960\n",
      "Epoch 917/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2954 - val_loss: 0.2960\n",
      "Epoch 918/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2942 - val_loss: 0.2960\n",
      "Epoch 919/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2950 - val_loss: 0.2960\n",
      "Epoch 920/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2954 - val_loss: 0.2960\n",
      "Epoch 921/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2945 - val_loss: 0.2960\n",
      "Epoch 922/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2941 - val_loss: 0.2960\n",
      "Epoch 923/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2935 - val_loss: 0.2959\n",
      "Epoch 924/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2951 - val_loss: 0.2960\n",
      "Epoch 925/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2938 - val_loss: 0.2960\n",
      "Epoch 926/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2944 - val_loss: 0.2960\n",
      "Epoch 927/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2946 - val_loss: 0.2959\n",
      "Epoch 928/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2959\n",
      "Epoch 929/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2948 - val_loss: 0.2959\n",
      "Epoch 930/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2959\n",
      "Epoch 931/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2940 - val_loss: 0.2959\n",
      "Epoch 932/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2942 - val_loss: 0.2959\n",
      "Epoch 933/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2959 - val_loss: 0.2959\n",
      "Epoch 934/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2937 - val_loss: 0.2958\n",
      "Epoch 935/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2955 - val_loss: 0.2958\n",
      "Epoch 936/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2950 - val_loss: 0.2958\n",
      "Epoch 937/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2934 - val_loss: 0.2958\n",
      "Epoch 938/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2958\n",
      "Epoch 939/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2956 - val_loss: 0.2958\n",
      "Epoch 940/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2958\n",
      "Epoch 941/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2937 - val_loss: 0.2958\n",
      "Epoch 942/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2934 - val_loss: 0.2958\n",
      "Epoch 943/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2952 - val_loss: 0.2958\n",
      "Epoch 944/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2954 - val_loss: 0.2958\n",
      "Epoch 945/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2958\n",
      "Epoch 946/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2940 - val_loss: 0.2957\n",
      "Epoch 947/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2929 - val_loss: 0.2957\n",
      "Epoch 948/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2953 - val_loss: 0.2958\n",
      "Epoch 949/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2938 - val_loss: 0.2957\n",
      "Epoch 950/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2943 - val_loss: 0.2957\n",
      "Epoch 951/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2961 - val_loss: 0.2957\n",
      "Epoch 952/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2938 - val_loss: 0.2956\n",
      "Epoch 953/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2929 - val_loss: 0.2956\n",
      "Epoch 954/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2957 - val_loss: 0.2956\n",
      "Epoch 955/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2954 - val_loss: 0.2957\n",
      "Epoch 956/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2944 - val_loss: 0.2956\n",
      "Epoch 957/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2943 - val_loss: 0.2956\n",
      "Epoch 958/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2949 - val_loss: 0.2956\n",
      "Epoch 959/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2949 - val_loss: 0.2956\n",
      "Epoch 960/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2955\n",
      "Epoch 961/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2928 - val_loss: 0.2956\n",
      "Epoch 962/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2944 - val_loss: 0.2956\n",
      "Epoch 963/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2933 - val_loss: 0.2956\n",
      "Epoch 964/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2940 - val_loss: 0.2955\n",
      "Epoch 965/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2949 - val_loss: 0.2955\n",
      "Epoch 966/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2946 - val_loss: 0.2955\n",
      "Epoch 967/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2945 - val_loss: 0.2955\n",
      "Epoch 968/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2944 - val_loss: 0.2955\n",
      "Epoch 969/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2952 - val_loss: 0.2955\n",
      "Epoch 970/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2947 - val_loss: 0.2955\n",
      "Epoch 971/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2949 - val_loss: 0.2954\n",
      "Epoch 972/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2939 - val_loss: 0.2954\n",
      "Epoch 973/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2945 - val_loss: 0.2954\n",
      "Epoch 974/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2945 - val_loss: 0.2954\n",
      "Epoch 975/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2943 - val_loss: 0.2954\n",
      "Epoch 976/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2942 - val_loss: 0.2954\n",
      "Epoch 977/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2949 - val_loss: 0.2954\n",
      "Epoch 978/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2949 - val_loss: 0.2954\n",
      "Epoch 979/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2938 - val_loss: 0.2953\n",
      "Epoch 980/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2936 - val_loss: 0.2954\n",
      "Epoch 981/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2955 - val_loss: 0.2953\n",
      "Epoch 982/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2941 - val_loss: 0.2953\n",
      "Epoch 983/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2953 - val_loss: 0.2953\n",
      "Epoch 984/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2942 - val_loss: 0.2953\n",
      "Epoch 985/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2951 - val_loss: 0.2953\n",
      "Epoch 986/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2936 - val_loss: 0.2953\n",
      "Epoch 987/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2953\n",
      "Epoch 988/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2952\n",
      "Epoch 989/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2941 - val_loss: 0.2952\n",
      "Epoch 990/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2946 - val_loss: 0.2953\n",
      "Epoch 991/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2947 - val_loss: 0.2952\n",
      "Epoch 992/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2934 - val_loss: 0.2953\n",
      "Epoch 993/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2936 - val_loss: 0.2952\n",
      "Epoch 994/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2948 - val_loss: 0.2951\n",
      "Epoch 995/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2950 - val_loss: 0.2951\n",
      "Epoch 996/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2940 - val_loss: 0.2951\n",
      "Epoch 997/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2941 - val_loss: 0.2951\n",
      "Epoch 998/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2933 - val_loss: 0.2951\n",
      "Epoch 999/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2952 - val_loss: 0.2951\n",
      "Epoch 1000/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2947 - val_loss: 0.2951\n",
      "Epoch 1001/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2928 - val_loss: 0.2950\n",
      "Epoch 1002/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2948 - val_loss: 0.2950\n",
      "Epoch 1003/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2942 - val_loss: 0.2950\n",
      "Epoch 1004/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2942 - val_loss: 0.2950\n",
      "Epoch 1005/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2943 - val_loss: 0.2950\n",
      "Epoch 1006/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2957 - val_loss: 0.2950\n",
      "Epoch 1007/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2947 - val_loss: 0.2949\n",
      "Epoch 1008/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2956 - val_loss: 0.2950\n",
      "Epoch 1009/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2944 - val_loss: 0.2950\n",
      "Epoch 1010/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2928 - val_loss: 0.2949\n",
      "Epoch 1011/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2934 - val_loss: 0.2949\n",
      "Epoch 1012/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2933 - val_loss: 0.2949\n",
      "Epoch 1013/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2937 - val_loss: 0.2949\n",
      "Epoch 1014/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2945 - val_loss: 0.2948\n",
      "Epoch 1015/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2927 - val_loss: 0.2949\n",
      "Epoch 1016/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2942 - val_loss: 0.2948\n",
      "Epoch 1017/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2933 - val_loss: 0.2948\n",
      "Epoch 1018/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2930 - val_loss: 0.2948\n",
      "Epoch 1019/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2956 - val_loss: 0.2948\n",
      "Epoch 1020/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2945 - val_loss: 0.2947\n",
      "Epoch 1021/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2935 - val_loss: 0.2947\n",
      "Epoch 1022/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2921 - val_loss: 0.2947\n",
      "Epoch 1023/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2933 - val_loss: 0.2947\n",
      "Epoch 1024/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2940 - val_loss: 0.2947\n",
      "Epoch 1025/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2942 - val_loss: 0.2947\n",
      "Epoch 1026/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2953 - val_loss: 0.2947\n",
      "Epoch 1027/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2929 - val_loss: 0.2947\n",
      "Epoch 1028/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2926 - val_loss: 0.2946\n",
      "Epoch 1029/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2933 - val_loss: 0.2946\n",
      "Epoch 1030/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2941 - val_loss: 0.2946\n",
      "Epoch 1031/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2943 - val_loss: 0.2946\n",
      "Epoch 1032/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2937 - val_loss: 0.2945\n",
      "Epoch 1033/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2938 - val_loss: 0.2946\n",
      "Epoch 1034/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2929 - val_loss: 0.2945\n",
      "Epoch 1035/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2939 - val_loss: 0.2944\n",
      "Epoch 1036/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2933 - val_loss: 0.2945\n",
      "Epoch 1037/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2924 - val_loss: 0.2944\n",
      "Epoch 1038/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2933 - val_loss: 0.2944\n",
      "Epoch 1039/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2928 - val_loss: 0.2944\n",
      "Epoch 1040/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2932 - val_loss: 0.2944\n",
      "Epoch 1041/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2937 - val_loss: 0.2944\n",
      "Epoch 1042/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2936 - val_loss: 0.2944\n",
      "Epoch 1043/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2937 - val_loss: 0.2943\n",
      "Epoch 1044/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2928 - val_loss: 0.2943\n",
      "Epoch 1045/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2933 - val_loss: 0.2943\n",
      "Epoch 1046/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2915 - val_loss: 0.2943\n",
      "Epoch 1047/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2917 - val_loss: 0.2943\n",
      "Epoch 1048/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2946 - val_loss: 0.2942\n",
      "Epoch 1049/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2935 - val_loss: 0.2942\n",
      "Epoch 1050/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2919 - val_loss: 0.2942\n",
      "Epoch 1051/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2931 - val_loss: 0.2941\n",
      "Epoch 1052/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2922 - val_loss: 0.2941\n",
      "Epoch 1053/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2922 - val_loss: 0.2942\n",
      "Epoch 1054/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2936 - val_loss: 0.2941\n",
      "Epoch 1055/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2926 - val_loss: 0.2941\n",
      "Epoch 1056/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.2931 - val_loss: 0.2941\n",
      "Epoch 1057/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2923 - val_loss: 0.2940\n",
      "Epoch 1058/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2928 - val_loss: 0.2940\n",
      "Epoch 1059/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2939 - val_loss: 0.2940\n",
      "Epoch 1060/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2923 - val_loss: 0.2939\n",
      "Epoch 1061/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2925 - val_loss: 0.2939\n",
      "Epoch 1062/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2936 - val_loss: 0.2939\n",
      "Epoch 1063/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2923 - val_loss: 0.2939\n",
      "Epoch 1064/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2933 - val_loss: 0.2939\n",
      "Epoch 1065/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2926 - val_loss: 0.2938\n",
      "Epoch 1066/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2930 - val_loss: 0.2938\n",
      "Epoch 1067/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2917 - val_loss: 0.2938\n",
      "Epoch 1068/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2919 - val_loss: 0.2937\n",
      "Epoch 1069/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2941 - val_loss: 0.2937\n",
      "Epoch 1070/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2936 - val_loss: 0.2937\n",
      "Epoch 1071/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2932 - val_loss: 0.2937\n",
      "Epoch 1072/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2927 - val_loss: 0.2938\n",
      "Epoch 1073/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2925 - val_loss: 0.2936\n",
      "Epoch 1074/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2922 - val_loss: 0.2936\n",
      "Epoch 1075/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2927 - val_loss: 0.2936\n",
      "Epoch 1076/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2935 - val_loss: 0.2936\n",
      "Epoch 1077/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2924 - val_loss: 0.2935\n",
      "Epoch 1078/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2924 - val_loss: 0.2935\n",
      "Epoch 1079/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2915 - val_loss: 0.2935\n",
      "Epoch 1080/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2929 - val_loss: 0.2934\n",
      "Epoch 1081/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2921 - val_loss: 0.2934\n",
      "Epoch 1082/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2911 - val_loss: 0.2934\n",
      "Epoch 1083/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2927 - val_loss: 0.2934\n",
      "Epoch 1084/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2925 - val_loss: 0.2934\n",
      "Epoch 1085/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2928 - val_loss: 0.2934\n",
      "Epoch 1086/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2925 - val_loss: 0.2934\n",
      "Epoch 1087/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2928 - val_loss: 0.2933\n",
      "Epoch 1088/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2906 - val_loss: 0.2932\n",
      "Epoch 1089/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2926 - val_loss: 0.2932\n",
      "Epoch 1090/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2919 - val_loss: 0.2932\n",
      "Epoch 1091/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2931 - val_loss: 0.2931\n",
      "Epoch 1092/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2915 - val_loss: 0.2931\n",
      "Epoch 1093/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2913 - val_loss: 0.2931\n",
      "Epoch 1094/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2920 - val_loss: 0.2930\n",
      "Epoch 1095/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2926 - val_loss: 0.2930\n",
      "Epoch 1096/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2917 - val_loss: 0.2930\n",
      "Epoch 1097/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2917 - val_loss: 0.2931\n",
      "Epoch 1098/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2917 - val_loss: 0.2929\n",
      "Epoch 1099/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2929 - val_loss: 0.2929\n",
      "Epoch 1100/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2912 - val_loss: 0.2929\n",
      "Epoch 1101/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2917 - val_loss: 0.2929\n",
      "Epoch 1102/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2923 - val_loss: 0.2928\n",
      "Epoch 1103/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2923 - val_loss: 0.2928\n",
      "Epoch 1104/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2918 - val_loss: 0.2928\n",
      "Epoch 1105/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2918 - val_loss: 0.2928\n",
      "Epoch 1106/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2911 - val_loss: 0.2927\n",
      "Epoch 1107/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2915 - val_loss: 0.2927\n",
      "Epoch 1108/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2935 - val_loss: 0.2926\n",
      "Epoch 1109/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2911 - val_loss: 0.2927\n",
      "Epoch 1110/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2921 - val_loss: 0.2926\n",
      "Epoch 1111/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2923 - val_loss: 0.2926\n",
      "Epoch 1112/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2922 - val_loss: 0.2926\n",
      "Epoch 1113/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2910 - val_loss: 0.2926\n",
      "Epoch 1114/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2899 - val_loss: 0.2925\n",
      "Epoch 1115/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2901 - val_loss: 0.2925\n",
      "Epoch 1116/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2920 - val_loss: 0.2925\n",
      "Epoch 1117/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2917 - val_loss: 0.2924\n",
      "Epoch 1118/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2923 - val_loss: 0.2924\n",
      "Epoch 1119/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2925 - val_loss: 0.2924\n",
      "Epoch 1120/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2905 - val_loss: 0.2923\n",
      "Epoch 1121/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2930 - val_loss: 0.2923\n",
      "Epoch 1122/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2894 - val_loss: 0.2923\n",
      "Epoch 1123/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2911 - val_loss: 0.2923\n",
      "Epoch 1124/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2914 - val_loss: 0.2922\n",
      "Epoch 1125/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2913 - val_loss: 0.2922\n",
      "Epoch 1126/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2894 - val_loss: 0.2922\n",
      "Epoch 1127/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2915 - val_loss: 0.2921\n",
      "Epoch 1128/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2915 - val_loss: 0.2921\n",
      "Epoch 1129/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2909 - val_loss: 0.2921\n",
      "Epoch 1130/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2906 - val_loss: 0.2922\n",
      "Epoch 1131/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2905 - val_loss: 0.2920\n",
      "Epoch 1132/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2921\n",
      "Epoch 1133/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2901 - val_loss: 0.2920\n",
      "Epoch 1134/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2911 - val_loss: 0.2919\n",
      "Epoch 1135/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2927 - val_loss: 0.2919\n",
      "Epoch 1136/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2901 - val_loss: 0.2919\n",
      "Epoch 1137/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2920 - val_loss: 0.2919\n",
      "Epoch 1138/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2914 - val_loss: 0.2918\n",
      "Epoch 1139/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2913 - val_loss: 0.2918\n",
      "Epoch 1140/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2936 - val_loss: 0.2918\n",
      "Epoch 1141/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2918\n",
      "Epoch 1142/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2901 - val_loss: 0.2917\n",
      "Epoch 1143/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2915 - val_loss: 0.2917\n",
      "Epoch 1144/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2902 - val_loss: 0.2917\n",
      "Epoch 1145/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2913 - val_loss: 0.2916\n",
      "Epoch 1146/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2899 - val_loss: 0.2916\n",
      "Epoch 1147/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2916\n",
      "Epoch 1148/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2902 - val_loss: 0.2916\n",
      "Epoch 1149/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2928 - val_loss: 0.2915\n",
      "Epoch 1150/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2923 - val_loss: 0.2915\n",
      "Epoch 1151/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2900 - val_loss: 0.2915\n",
      "Epoch 1152/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2917 - val_loss: 0.2915\n",
      "Epoch 1153/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2913 - val_loss: 0.2914\n",
      "Epoch 1154/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2904 - val_loss: 0.2915\n",
      "Epoch 1155/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2910 - val_loss: 0.2914\n",
      "Epoch 1156/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2911 - val_loss: 0.2913\n",
      "Epoch 1157/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2900 - val_loss: 0.2913\n",
      "Epoch 1158/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2906 - val_loss: 0.2913\n",
      "Epoch 1159/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2913\n",
      "Epoch 1160/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2914 - val_loss: 0.2913\n",
      "Epoch 1161/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2926 - val_loss: 0.2912\n",
      "Epoch 1162/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2911 - val_loss: 0.2912\n",
      "Epoch 1163/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2906 - val_loss: 0.2912\n",
      "Epoch 1164/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2912\n",
      "Epoch 1165/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2911\n",
      "Epoch 1166/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2914 - val_loss: 0.2911\n",
      "Epoch 1167/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2905 - val_loss: 0.2911\n",
      "Epoch 1168/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2908 - val_loss: 0.2911\n",
      "Epoch 1169/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2900 - val_loss: 0.2910\n",
      "Epoch 1170/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2900 - val_loss: 0.2910\n",
      "Epoch 1171/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2905 - val_loss: 0.2910\n",
      "Epoch 1172/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2915 - val_loss: 0.2909\n",
      "Epoch 1173/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2897 - val_loss: 0.2910\n",
      "Epoch 1174/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2892 - val_loss: 0.2909\n",
      "Epoch 1175/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2895 - val_loss: 0.2910\n",
      "Epoch 1176/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2897 - val_loss: 0.2909\n",
      "Epoch 1177/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2906 - val_loss: 0.2909\n",
      "Epoch 1178/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2893 - val_loss: 0.2908\n",
      "Epoch 1179/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2892 - val_loss: 0.2908\n",
      "Epoch 1180/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2903 - val_loss: 0.2908\n",
      "Epoch 1181/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2905 - val_loss: 0.2908\n",
      "Epoch 1182/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2907\n",
      "Epoch 1183/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2909 - val_loss: 0.2908\n",
      "Epoch 1184/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2901 - val_loss: 0.2907\n",
      "Epoch 1185/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2899 - val_loss: 0.2907\n",
      "Epoch 1186/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2909 - val_loss: 0.2907\n",
      "Epoch 1187/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2895 - val_loss: 0.2906\n",
      "Epoch 1188/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2888 - val_loss: 0.2907\n",
      "Epoch 1189/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2898 - val_loss: 0.2906\n",
      "Epoch 1190/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2891 - val_loss: 0.2906\n",
      "Epoch 1191/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2899 - val_loss: 0.2906\n",
      "Epoch 1192/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2906\n",
      "Epoch 1193/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2903 - val_loss: 0.2905\n",
      "Epoch 1194/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2898 - val_loss: 0.2905\n",
      "Epoch 1195/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2897 - val_loss: 0.2905\n",
      "Epoch 1196/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2897 - val_loss: 0.2905\n",
      "Epoch 1197/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2906\n",
      "Epoch 1198/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2895 - val_loss: 0.2905\n",
      "Epoch 1199/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2892 - val_loss: 0.2904\n",
      "Epoch 1200/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2904\n",
      "Epoch 1201/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2891 - val_loss: 0.2904\n",
      "Epoch 1202/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2893 - val_loss: 0.2903\n",
      "Epoch 1203/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2903 - val_loss: 0.2904\n",
      "Epoch 1204/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2891 - val_loss: 0.2904\n",
      "Epoch 1205/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2897 - val_loss: 0.2903\n",
      "Epoch 1206/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2902 - val_loss: 0.2903\n",
      "Epoch 1207/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2895 - val_loss: 0.2903\n",
      "Epoch 1208/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2900 - val_loss: 0.2902\n",
      "Epoch 1209/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2891 - val_loss: 0.2902\n",
      "Epoch 1210/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2883 - val_loss: 0.2902\n",
      "Epoch 1211/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2882 - val_loss: 0.2902\n",
      "Epoch 1212/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 0.2887 - val_loss: 0.2902\n",
      "Epoch 1213/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2897 - val_loss: 0.2902\n",
      "Epoch 1214/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2897 - val_loss: 0.2901\n",
      "Epoch 1215/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2906 - val_loss: 0.2901\n",
      "Epoch 1216/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2902\n",
      "Epoch 1217/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2903 - val_loss: 0.2902\n",
      "Epoch 1218/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2891 - val_loss: 0.2901\n",
      "Epoch 1219/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2898 - val_loss: 0.2901\n",
      "Epoch 1220/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2894 - val_loss: 0.2902\n",
      "Epoch 1221/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2884 - val_loss: 0.2901\n",
      "Epoch 1222/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2894 - val_loss: 0.2900\n",
      "Epoch 1223/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2894 - val_loss: 0.2900\n",
      "Epoch 1224/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2908 - val_loss: 0.2900\n",
      "Epoch 1225/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2892 - val_loss: 0.2900\n",
      "Epoch 1226/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2900 - val_loss: 0.2900\n",
      "Epoch 1227/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2893 - val_loss: 0.2899\n",
      "Epoch 1228/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2895 - val_loss: 0.2899\n",
      "Epoch 1229/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2901 - val_loss: 0.2899\n",
      "Epoch 1230/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2897 - val_loss: 0.2899\n",
      "Epoch 1231/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2893 - val_loss: 0.2899\n",
      "Epoch 1232/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2882 - val_loss: 0.2899\n",
      "Epoch 1233/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2898 - val_loss: 0.2899\n",
      "Epoch 1234/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2886 - val_loss: 0.2898\n",
      "Epoch 1235/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2876 - val_loss: 0.2898\n",
      "Epoch 1236/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2893 - val_loss: 0.2898\n",
      "Epoch 1237/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2888 - val_loss: 0.2898\n",
      "Epoch 1238/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2898\n",
      "Epoch 1239/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2891 - val_loss: 0.2898\n",
      "Epoch 1240/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2901 - val_loss: 0.2897\n",
      "Epoch 1241/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2888 - val_loss: 0.2898\n",
      "Epoch 1242/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2892 - val_loss: 0.2897\n",
      "Epoch 1243/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2891 - val_loss: 0.2897\n",
      "Epoch 1244/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2874 - val_loss: 0.2897\n",
      "Epoch 1245/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2892 - val_loss: 0.2897\n",
      "Epoch 1246/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2903 - val_loss: 0.2897\n",
      "Epoch 1247/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2897\n",
      "Epoch 1248/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2894 - val_loss: 0.2896\n",
      "Epoch 1249/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2877 - val_loss: 0.2897\n",
      "Epoch 1250/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2893 - val_loss: 0.2896\n",
      "Epoch 1251/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2893 - val_loss: 0.2896\n",
      "Epoch 1252/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2896\n",
      "Epoch 1253/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2894 - val_loss: 0.2896\n",
      "Epoch 1254/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2892 - val_loss: 0.2896\n",
      "Epoch 1255/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2875 - val_loss: 0.2895\n",
      "Epoch 1256/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2897 - val_loss: 0.2896\n",
      "Epoch 1257/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2884 - val_loss: 0.2895\n",
      "Epoch 1258/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2883 - val_loss: 0.2895\n",
      "Epoch 1259/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2881 - val_loss: 0.2895\n",
      "Epoch 1260/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2895\n",
      "Epoch 1261/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2888 - val_loss: 0.2895\n",
      "Epoch 1262/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2888 - val_loss: 0.2895\n",
      "Epoch 1263/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2885 - val_loss: 0.2895\n",
      "Epoch 1264/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2885 - val_loss: 0.2895\n",
      "Epoch 1265/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2874 - val_loss: 0.2894\n",
      "Epoch 1266/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2884 - val_loss: 0.2895\n",
      "Epoch 1267/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2894\n",
      "Epoch 1268/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2883 - val_loss: 0.2894\n",
      "Epoch 1269/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2880 - val_loss: 0.2894\n",
      "Epoch 1270/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2887 - val_loss: 0.2894\n",
      "Epoch 1271/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2877 - val_loss: 0.2894\n",
      "Epoch 1272/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2893 - val_loss: 0.2894\n",
      "Epoch 1273/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2883 - val_loss: 0.2894\n",
      "Epoch 1274/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2895 - val_loss: 0.2894\n",
      "Epoch 1275/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2881 - val_loss: 0.2893\n",
      "Epoch 1276/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2884 - val_loss: 0.2893\n",
      "Epoch 1277/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2897 - val_loss: 0.2893\n",
      "Epoch 1278/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2874 - val_loss: 0.2893\n",
      "Epoch 1279/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2885 - val_loss: 0.2894\n",
      "Epoch 1280/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2897 - val_loss: 0.2893\n",
      "Epoch 1281/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2893 - val_loss: 0.2893\n",
      "Epoch 1282/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2892\n",
      "Epoch 1283/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2869 - val_loss: 0.2892\n",
      "Epoch 1284/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2889 - val_loss: 0.2892\n",
      "Epoch 1285/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2887 - val_loss: 0.2893\n",
      "Epoch 1286/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2892\n",
      "Epoch 1287/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2893 - val_loss: 0.2892\n",
      "Epoch 1288/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2892\n",
      "Epoch 1289/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2906 - val_loss: 0.2892\n",
      "Epoch 1290/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2903 - val_loss: 0.2892\n",
      "Epoch 1291/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2887 - val_loss: 0.2892\n",
      "Epoch 1292/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2892 - val_loss: 0.2891\n",
      "Epoch 1293/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2892 - val_loss: 0.2892\n",
      "Epoch 1294/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2871 - val_loss: 0.2892\n",
      "Epoch 1295/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2892\n",
      "Epoch 1296/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2883 - val_loss: 0.2891\n",
      "Epoch 1297/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2888 - val_loss: 0.2891\n",
      "Epoch 1298/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2889 - val_loss: 0.2891\n",
      "Epoch 1299/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2902 - val_loss: 0.2891\n",
      "Epoch 1300/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2891\n",
      "Epoch 1301/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2891\n",
      "Epoch 1302/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2891\n",
      "Epoch 1303/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2891\n",
      "Epoch 1304/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2888 - val_loss: 0.2890\n",
      "Epoch 1305/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2891\n",
      "Epoch 1306/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2891\n",
      "Epoch 1307/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2892 - val_loss: 0.2890\n",
      "Epoch 1308/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2891\n",
      "Epoch 1309/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2884 - val_loss: 0.2890\n",
      "Epoch 1310/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2893 - val_loss: 0.2890\n",
      "Epoch 1311/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2881 - val_loss: 0.2890\n",
      "Epoch 1312/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2875 - val_loss: 0.2890\n",
      "Epoch 1313/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2884 - val_loss: 0.2890\n",
      "Epoch 1314/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2877 - val_loss: 0.2890\n",
      "Epoch 1315/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2885 - val_loss: 0.2890\n",
      "Epoch 1316/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2874 - val_loss: 0.2890\n",
      "Epoch 1317/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2890\n",
      "Epoch 1318/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2899 - val_loss: 0.2890\n",
      "Epoch 1319/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2878 - val_loss: 0.2890\n",
      "Epoch 1320/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2878 - val_loss: 0.2889\n",
      "Epoch 1321/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2888 - val_loss: 0.2890\n",
      "Epoch 1322/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2882 - val_loss: 0.2889\n",
      "Epoch 1323/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2883 - val_loss: 0.2889\n",
      "Epoch 1324/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2899 - val_loss: 0.2889\n",
      "Epoch 1325/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2886 - val_loss: 0.2889\n",
      "Epoch 1326/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2890 - val_loss: 0.2889\n",
      "Epoch 1327/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2888 - val_loss: 0.2888\n",
      "Epoch 1328/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2893 - val_loss: 0.2889\n",
      "Epoch 1329/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2891 - val_loss: 0.2889\n",
      "Epoch 1330/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2885 - val_loss: 0.2889\n",
      "Epoch 1331/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2894 - val_loss: 0.2889\n",
      "Epoch 1332/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2874 - val_loss: 0.2888\n",
      "Epoch 1333/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2866 - val_loss: 0.2889\n",
      "Epoch 1334/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2865 - val_loss: 0.2888\n",
      "Epoch 1335/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2881 - val_loss: 0.2888\n",
      "Epoch 1336/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2883 - val_loss: 0.2888\n",
      "Epoch 1337/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2886 - val_loss: 0.2888\n",
      "Epoch 1338/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2882 - val_loss: 0.2888\n",
      "Epoch 1339/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2879 - val_loss: 0.2888\n",
      "Epoch 1340/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2870 - val_loss: 0.2888\n",
      "Epoch 1341/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2871 - val_loss: 0.2888\n",
      "Epoch 1342/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2868 - val_loss: 0.2889\n",
      "Epoch 1343/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2874 - val_loss: 0.2887\n",
      "Epoch 1344/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2886 - val_loss: 0.2887\n",
      "Epoch 1345/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2887\n",
      "Epoch 1346/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2888\n",
      "Epoch 1347/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2887\n",
      "Epoch 1348/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2871 - val_loss: 0.2887\n",
      "Epoch 1349/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2887\n",
      "Epoch 1350/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2888\n",
      "Epoch 1351/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2865 - val_loss: 0.2887\n",
      "Epoch 1352/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2877 - val_loss: 0.2887\n",
      "Epoch 1353/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2879 - val_loss: 0.2887\n",
      "Epoch 1354/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2887\n",
      "Epoch 1355/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2864 - val_loss: 0.2887\n",
      "Epoch 1356/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2891 - val_loss: 0.2887\n",
      "Epoch 1357/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2870 - val_loss: 0.2887\n",
      "Epoch 1358/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2889 - val_loss: 0.2887\n",
      "Epoch 1359/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2881 - val_loss: 0.2887\n",
      "Epoch 1360/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2887\n",
      "Epoch 1361/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2883 - val_loss: 0.2887\n",
      "Epoch 1362/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2887\n",
      "Epoch 1363/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2886\n",
      "Epoch 1364/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2883 - val_loss: 0.2886\n",
      "Epoch 1365/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2876 - val_loss: 0.2887\n",
      "Epoch 1366/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2867 - val_loss: 0.2887\n",
      "Epoch 1367/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2874 - val_loss: 0.2886\n",
      "Epoch 1368/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2879 - val_loss: 0.2886\n",
      "Epoch 1369/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2889 - val_loss: 0.2886\n",
      "Epoch 1370/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2869 - val_loss: 0.2886\n",
      "Epoch 1371/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2879 - val_loss: 0.2887\n",
      "Epoch 1372/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2886\n",
      "Epoch 1373/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2864 - val_loss: 0.2886\n",
      "Epoch 1374/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2881 - val_loss: 0.2885\n",
      "Epoch 1375/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2886\n",
      "Epoch 1376/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2886\n",
      "Epoch 1377/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2888 - val_loss: 0.2886\n",
      "Epoch 1378/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2870 - val_loss: 0.2886\n",
      "Epoch 1379/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2891 - val_loss: 0.2886\n",
      "Epoch 1380/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2889 - val_loss: 0.2885\n",
      "Epoch 1381/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2870 - val_loss: 0.2886\n",
      "Epoch 1382/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2865 - val_loss: 0.2885\n",
      "Epoch 1383/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2877 - val_loss: 0.2885\n",
      "Epoch 1384/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2864 - val_loss: 0.2885\n",
      "Epoch 1385/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2857 - val_loss: 0.2885\n",
      "Epoch 1386/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2881 - val_loss: 0.2885\n",
      "Epoch 1387/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2860 - val_loss: 0.2885\n",
      "Epoch 1388/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2890 - val_loss: 0.2885\n",
      "Epoch 1389/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2876 - val_loss: 0.2885\n",
      "Epoch 1390/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2872 - val_loss: 0.2885\n",
      "Epoch 1391/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2876 - val_loss: 0.2885\n",
      "Epoch 1392/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2877 - val_loss: 0.2885\n",
      "Epoch 1393/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2874 - val_loss: 0.2885\n",
      "Epoch 1394/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2877 - val_loss: 0.2885\n",
      "Epoch 1395/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2885\n",
      "Epoch 1396/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2871 - val_loss: 0.2885\n",
      "Epoch 1397/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2878 - val_loss: 0.2884\n",
      "Epoch 1398/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2868 - val_loss: 0.2884\n",
      "Epoch 1399/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2872 - val_loss: 0.2885\n",
      "Epoch 1400/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2876 - val_loss: 0.2884\n",
      "Epoch 1401/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2864 - val_loss: 0.2884\n",
      "Epoch 1402/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2886 - val_loss: 0.2884\n",
      "Epoch 1403/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2868 - val_loss: 0.2884\n",
      "Epoch 1404/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2868 - val_loss: 0.2884\n",
      "Epoch 1405/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2879 - val_loss: 0.2884\n",
      "Epoch 1406/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2875 - val_loss: 0.2884\n",
      "Epoch 1407/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2862 - val_loss: 0.2884\n",
      "Epoch 1408/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2884\n",
      "Epoch 1409/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2879 - val_loss: 0.2884\n",
      "Epoch 1410/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2869 - val_loss: 0.2884\n",
      "Epoch 1411/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2883\n",
      "Epoch 1412/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2864 - val_loss: 0.2883\n",
      "Epoch 1413/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2858 - val_loss: 0.2884\n",
      "Epoch 1414/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2884 - val_loss: 0.2883\n",
      "Epoch 1415/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2864 - val_loss: 0.2883\n",
      "Epoch 1416/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2883 - val_loss: 0.2883\n",
      "Epoch 1417/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2881 - val_loss: 0.2883\n",
      "Epoch 1418/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2876 - val_loss: 0.2883\n",
      "Epoch 1419/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2865 - val_loss: 0.2883\n",
      "Epoch 1420/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2877 - val_loss: 0.2883\n",
      "Epoch 1421/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2885 - val_loss: 0.2883\n",
      "Epoch 1422/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2881 - val_loss: 0.2883\n",
      "Epoch 1423/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2876 - val_loss: 0.2883\n",
      "Epoch 1424/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2884\n",
      "Epoch 1425/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2883\n",
      "Epoch 1426/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2881 - val_loss: 0.2883\n",
      "Epoch 1427/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2865 - val_loss: 0.2884\n",
      "Epoch 1428/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2876 - val_loss: 0.2883\n",
      "Epoch 1429/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2870 - val_loss: 0.2883\n",
      "Epoch 1430/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2882 - val_loss: 0.2884\n",
      "Epoch 1431/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2884\n",
      "Epoch 1432/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2883 - val_loss: 0.2883\n",
      "Epoch 1433/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2877 - val_loss: 0.2883\n",
      "Epoch 1434/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2870 - val_loss: 0.2882\n",
      "Epoch 1435/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2883\n",
      "Epoch 1436/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2862 - val_loss: 0.2883\n",
      "Epoch 1437/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2875 - val_loss: 0.2883\n",
      "Epoch 1438/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2874 - val_loss: 0.2883\n",
      "Epoch 1439/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2867 - val_loss: 0.2883\n",
      "Epoch 1440/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2893 - val_loss: 0.2882\n",
      "Epoch 1441/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2867 - val_loss: 0.2883\n",
      "Epoch 1442/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2854 - val_loss: 0.2882\n",
      "Epoch 1443/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2871 - val_loss: 0.2882\n",
      "Epoch 1444/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2870 - val_loss: 0.2882\n",
      "Epoch 1445/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2887 - val_loss: 0.2882\n",
      "Epoch 1446/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2870 - val_loss: 0.2882\n",
      "Epoch 1447/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2886 - val_loss: 0.2883\n",
      "Epoch 1448/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.2869 - val_loss: 0.2883\n",
      "Epoch 1449/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2871 - val_loss: 0.2882\n",
      "Epoch 1450/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2874 - val_loss: 0.2882\n",
      "Epoch 1451/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.2857 - val_loss: 0.2882\n",
      "Epoch 1452/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2883 - val_loss: 0.2882\n",
      "Epoch 1453/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2872 - val_loss: 0.2882\n",
      "Epoch 1454/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2886 - val_loss: 0.2882\n",
      "Epoch 1455/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2882 - val_loss: 0.2882\n",
      "Epoch 1456/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2858 - val_loss: 0.2882\n",
      "Epoch 1457/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2887 - val_loss: 0.2882\n",
      "Epoch 1458/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2865 - val_loss: 0.2882\n",
      "Epoch 1459/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2875 - val_loss: 0.2882\n",
      "Epoch 1460/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2872 - val_loss: 0.2883\n",
      "Epoch 1461/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2882\n",
      "Epoch 1462/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2861 - val_loss: 0.2882\n",
      "Epoch 1463/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2879 - val_loss: 0.2882\n",
      "Epoch 1464/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2879 - val_loss: 0.2881\n",
      "Epoch 1465/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2868 - val_loss: 0.2881\n",
      "Epoch 1466/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2869 - val_loss: 0.2881\n",
      "Epoch 1467/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2862 - val_loss: 0.2881\n",
      "Epoch 1468/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 0.2857 - val_loss: 0.2881\n",
      "Epoch 1469/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2881\n",
      "Epoch 1470/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2874 - val_loss: 0.2881\n",
      "Epoch 1471/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2863 - val_loss: 0.2881\n",
      "Epoch 1472/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2864 - val_loss: 0.2882\n",
      "Epoch 1473/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2876 - val_loss: 0.2881\n",
      "Epoch 1474/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2871 - val_loss: 0.2881\n",
      "Epoch 1475/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2865 - val_loss: 0.2881\n",
      "Epoch 1476/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2879 - val_loss: 0.2881\n",
      "Epoch 1477/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2855 - val_loss: 0.2881\n",
      "Epoch 1478/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2881\n",
      "Epoch 1479/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2868 - val_loss: 0.2882\n",
      "Epoch 1480/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2878 - val_loss: 0.2881\n",
      "Epoch 1481/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2873 - val_loss: 0.2881\n",
      "Epoch 1482/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2888 - val_loss: 0.2881\n",
      "Epoch 1483/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2880 - val_loss: 0.2881\n",
      "Epoch 1484/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2862 - val_loss: 0.2881\n",
      "Epoch 1485/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2867 - val_loss: 0.2881\n",
      "Epoch 1486/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2861 - val_loss: 0.2881\n",
      "Epoch 1487/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2868 - val_loss: 0.2881\n",
      "Epoch 1488/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2864 - val_loss: 0.2881\n",
      "Epoch 1489/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2866 - val_loss: 0.2881\n",
      "Epoch 1490/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2870 - val_loss: 0.2881\n",
      "Epoch 1491/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2854 - val_loss: 0.2881\n",
      "Epoch 1492/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2870 - val_loss: 0.2881\n",
      "Epoch 1493/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2873 - val_loss: 0.2880\n",
      "Epoch 1494/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2870 - val_loss: 0.2881\n",
      "Epoch 1495/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2874 - val_loss: 0.2881\n",
      "Epoch 1496/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2875 - val_loss: 0.2880\n",
      "Epoch 1497/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2857 - val_loss: 0.2880\n",
      "Epoch 1498/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2858 - val_loss: 0.2881\n",
      "Epoch 1499/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - loss: 0.2879 - val_loss: 0.2880\n",
      "Epoch 1500/1500\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - loss: 0.2861 - val_loss: 0.2880\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.2794 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "# history = model.fit(train_features, train_labels, validation_data=(validation_features, validation_labels), epochs=epochs, batch_size=batch_size);\n",
    "history = model.fit(train_features, train_labels, validation_split=0.2, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_features, test_labels)\n",
    "\n",
    "# Extract loss and validation loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x800 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "#plt.xlim([1,epochs])\n",
    "#plt.ylim([0,2])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "Predicted values:  [ 0.60925096  0.60762167  0.6366116   0.7385786   0.7261518   0.5364983\n",
      "  0.5405651   0.7319324  -0.00789839  0.00844979 -0.1754753  -0.12729967\n",
      "  0.72550195 -0.01640368 -0.00578597  0.20115474  0.40421823  0.40113717\n",
      "  0.01219076  0.04978742  0.02240224  0.01722529]\n",
      "Correct values:  <PandasArray>\n",
      "[            0.71336,              0.4192,             0.65296,\n",
      "             0.74744,             0.92952,             0.63728,\n",
      "             0.46904,             0.74168,            -0.59056,\n",
      "            -0.64264,            -0.16192,             -0.1472,\n",
      "             0.92784,            -0.42784,            -0.48648,\n",
      "             0.20128,  0.3282398872357129,  0.0923867376245052,\n",
      "  1.2366318984348703,  0.8698146232047075, -0.2384655358219716,\n",
      " -0.5068562809753492]\n",
      "Length: 22, dtype: float64\n",
      "the mean squared error is:  3.9242069021307646\n",
      "The percent error is:  127.24393094747077\n",
      "{'decay_0': 0.3385567502983899, 'decay_1': 0.4881396638245256, 'W_0': 0.2401736419926808, 'W_1': 0.3096126947082128, 'J_0': -0.5881311322718885}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import estimator\n",
    "\n",
    "new_data = pd.read_csv(\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-09-05_14-55/test.csv\")\n",
    "first_line = new_data.iloc[15]\n",
    "correct_output = first_line[output_keys].array\n",
    "\n",
    "input_data = {key: np.array([first_line[key]]) for key in inputs}\n",
    "predictions = model.predict(input_data)\n",
    "print(\"Predicted values: \", predictions[0])\n",
    "print(\"Correct values: \", correct_output)\n",
    "print(\"the mean squared error is: \", np.linalg.norm(predictions[0] - correct_output) ** 2)\n",
    "error = estimator.percent_error(predictions[0], correct_output)\n",
    "print(\"The percent error is: \", error * 100)\n",
    "\n",
    "parameters = {key: first_line[key] for key in input_keys}\n",
    "print(parameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 313.7186279296875, Inputs: [0.49000007, 0.5099998, 0.009999923, 0.009999931, -0.009999933]\n",
      "Step 100, Loss: 283.5638427734375, Inputs: [0.321322, 0.44878635, 0.2612131, 0.27821043, -0.59903115]\n",
      "Step 200, Loss: 283.3408203125, Inputs: [0.3209291, 0.4474852, 0.26336724, 0.2790787, -0.6029598]\n",
      "Optimized Inputs: {'decay_0': 0.3203789, 'decay_1': 0.44580993, 'W_0': 0.26002544, 'W_1': 0.27874523, 'J_0': -0.6056155}\n",
      "{'decay_0': 0.3385567502983899, 'decay_1': 0.4881396638245256, 'W_0': 0.2401736419926808, 'W_1': 0.3096126947082128, 'J_0': -0.5881311322718885}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "target_outputs = tf.constant(correct_output, dtype=tf.float32)  # Replace with your target values\n",
    "\n",
    "# Initialize the input parameters as variables to optimize\n",
    "initial_guess = {\n",
    "    'decay_0': 0.5,\n",
    "    'decay_1': 0.5,\n",
    "    'W_0': 0,\n",
    "    'W_1': 0,\n",
    "    'J_0': 0\n",
    "}\n",
    "input_vars = {key: tf.Variable(value, dtype=tf.float32) for key, value in initial_guess.items()}\n",
    "\n",
    "\n",
    "# Use the variables as inputs to the model\n",
    "def model_loss(target):\n",
    "    # Pass the variables through the model to get the predicted output\n",
    "    model_inputs = {key: tf.expand_dims(input_vars[key], 0) for key in input_keys}\n",
    "    predicted_outputs = model(model_inputs, training=False)\n",
    "\n",
    "    # Calculate the loss between predicted and target outputs\n",
    "    loss = tf.reduce_mean(tf.abs(predicted_outputs - target))\n",
    "    return loss * 1000\n",
    "\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Optimization loop\n",
    "for step in range(300):  # Adjust the number of steps as needed\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model_loss(target_outputs)\n",
    "    # Compute the gradients of the loss with respect to the input variables\n",
    "    grads = tape.gradient(loss, input_vars.values())\n",
    "    # input_vars['J_0'].assign(-0.64)\n",
    "    # Apply the gradients to the input variables\n",
    "    optimizer.apply_gradients(zip(grads, input_vars.values()))\n",
    "\n",
    "    # Print the loss and current input variables every 100 steps\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss: {loss.numpy()}, Inputs: {[input_vars[key].numpy() for key in input_keys]}\")\n",
    "\n",
    "# Final optimized input parameters\n",
    "optimized_inputs = {key: var.numpy() for key, var in input_vars.items()}\n",
    "print(\"Optimized Inputs:\", optimized_inputs)\n",
    "print(parameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3203789, 0.44580993, 0.26002544, 0.27874523, -0.6056155]\n",
      "[0.3385567502983899, 0.4881396638245256, 0.2401736419926808, 0.3096126947082128, -0.5881311322718885]\n",
      "7.190681342321792\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(list(optimized_inputs.values()))\n",
    "print(list(parameters.values()))\n",
    "\n",
    "error = estimator.percent_error(np.array(list(optimized_inputs.values())), np.array(list(parameters.values())))\n",
    "print(error * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 0.33710402250289917, Inputs: [0.59999365, 0.4000951, -0.0999943, 0.09998842, -0.09998962]\n",
      "[ 0.56130986  0.31298694 -1.01076092  1.55675042  0.31244982]\n",
      "Step 100, Loss: 0.2493424415588379, Inputs: [0.51420885, 0.23822734, -1.0728618, 1.2809224, 0.3925895]\n",
      "[ 0.56130986  0.31298694 -1.01076092  1.55675042  0.31244982]\n",
      "Step 200, Loss: 0.24865196645259857, Inputs: [0.52702117, 0.22601393, -1.0606803, 1.264077, 0.36213458]\n",
      "[ 0.56130986  0.31298694 -1.01076092  1.55675042  0.31244982]\n",
      "Step 300, Loss: 0.2484048753976822, Inputs: [0.5449683, 0.23124817, -1.0300922, 1.3302926, 0.3035993]\n",
      "[ 0.56130986  0.31298694 -1.01076092  1.55675042  0.31244982]\n",
      "Step 400, Loss: 0.2483113408088684, Inputs: [0.52717435, 0.217561, -1.046369, 1.346109, 0.36613786]\n",
      "[ 0.56130986  0.31298694 -1.01076092  1.55675042  0.31244982]\n",
      "Error is:  21.715782345124786\n",
      "Step 0, Loss: 0.4559907913208008, Inputs: [0.59999377, 0.5995527, -0.09999333, -0.09998662, -0.0999803]\n",
      "[ 0.57011267  0.23190745 -0.77779781 -0.31146485 -0.63297384]\n",
      "Step 100, Loss: 0.38495609164237976, Inputs: [0.57413006, 1.3214909, -0.7590416, -0.7508039, -0.7127783]\n",
      "[ 0.57011267  0.23190745 -0.77779781 -0.31146485 -0.63297384]\n",
      "Step 200, Loss: 0.3861565887928009, Inputs: [0.57883966, 1.317525, -0.77685857, -0.74482155, -0.6763379]\n",
      "[ 0.57011267  0.23190745 -0.77779781 -0.31146485 -0.63297384]\n",
      "Step 300, Loss: 0.3853381276130676, Inputs: [0.5783182, 1.2763098, -0.7769538, -0.8043425, -0.6771905]\n",
      "[ 0.57011267  0.23190745 -0.77779781 -0.31146485 -0.63297384]\n",
      "Step 400, Loss: 0.38514482975006104, Inputs: [0.559905, 1.312122, -0.7791679, -0.8090469, -0.6991916]\n",
      "[ 0.57011267  0.23190745 -0.77779781 -0.31146485 -0.63297384]\n",
      "Error is:  63.161196845042475\n",
      "Step 0, Loss: 0.3006400763988495, Inputs: [0.40000737, 0.59991777, 0.09994958, -0.09998963, -0.09997573]\n",
      "[ 0.36011756  0.40200718  0.12585096 -1.32429151 -0.64027057]\n",
      "Step 100, Loss: 0.2525171935558319, Inputs: [0.35811895, 0.57773596, 0.09424408, -1.948586, -0.6136963]\n",
      "[ 0.36011756  0.40200718  0.12585096 -1.32429151 -0.64027057]\n",
      "Step 200, Loss: 0.2536470293998718, Inputs: [0.37258998, 0.55875605, 0.0823879, -2.056311, -0.58202624]\n",
      "[ 0.36011756  0.40200718  0.12585096 -1.32429151 -0.64027057]\n",
      "Step 300, Loss: 0.2522052526473999, Inputs: [0.36157727, 0.5692126, 0.06530601, -1.9528371, -0.6210527]\n",
      "[ 0.36011756  0.40200718  0.12585096 -1.32429151 -0.64027057]\n",
      "Step 400, Loss: 0.25237730145454407, Inputs: [0.36480668, 0.5698115, 0.10799946, -1.9418147, -0.6022481]\n",
      "[ 0.36011756  0.40200718  0.12585096 -1.32429151 -0.64027057]\n",
      "Error is:  46.792486785946345\n",
      "Step 0, Loss: 0.33293405175209045, Inputs: [0.40000838, 0.40060303, -0.09999388, -0.099990726, -0.09998497]\n",
      "[ 0.31182487  0.33740791 -0.02842058 -1.37122576 -0.24741076]\n",
      "Step 100, Loss: 0.28057482838630676, Inputs: [0.31823426, 0.22613892, -0.031118017, -1.2107848, -0.24150212]\n",
      "[ 0.31182487  0.33740791 -0.02842058 -1.37122576 -0.24741076]\n",
      "Step 200, Loss: 0.2816725969314575, Inputs: [0.31998354, 0.24891299, -0.03686278, -1.2223988, -0.22742894]\n",
      "[ 0.31182487  0.33740791 -0.02842058 -1.37122576 -0.24741076]\n",
      "Step 300, Loss: 0.28031203150749207, Inputs: [0.31894794, 0.23571694, -0.021383129, -1.2299974, -0.26433957]\n",
      "[ 0.31182487  0.33740791 -0.02842058 -1.37122576 -0.24741076]\n",
      "Step 400, Loss: 0.2826182544231415, Inputs: [0.34158012, 0.2185813, -0.0076033236, -1.2549593, -0.24730305]\n",
      "[ 0.31182487  0.33740791 -0.02842058 -1.37122576 -0.24741076]\n",
      "Error is:  23.53292076452844\n",
      "Step 0, Loss: 0.4785187542438507, Inputs: [0.59999377, 0.42310292, -0.09999362, -0.09998414, -0.09997914]\n",
      "[ 0.53643504  0.06777857 -0.35301135 -1.25805421 -1.31464695]\n",
      "Step 100, Loss: 0.39154088497161865, Inputs: [0.54934496, -0.25430727, -0.40979582, -1.073922, -1.2831002]\n",
      "[ 0.53643504  0.06777857 -0.35301135 -1.25805421 -1.31464695]\n",
      "Step 200, Loss: 0.3925274908542633, Inputs: [0.55411774, -0.3075991, -0.36742344, -1.0931728, -1.2573467]\n",
      "[ 0.53643504  0.06777857 -0.35301135 -1.25805421 -1.31464695]\n",
      "Step 300, Loss: 0.39513275027275085, Inputs: [0.55688816, -0.08949635, -0.40308598, -1.2481252, -1.352158]\n",
      "[ 0.53643504  0.06777857 -0.35301135 -1.25805421 -1.31464695]\n",
      "Step 400, Loss: 0.39228248596191406, Inputs: [0.51405996, -0.07818495, -0.37753692, -1.1869361, -1.3179064]\n",
      "[ 0.53643504  0.06777857 -0.35301135 -1.25805421 -1.31464695]\n",
      "Error is:  8.6067726576537\n",
      "Step 0, Loss: 0.2092674821615219, Inputs: [0.59999436, 0.59938014, -0.09999375, -0.09998688, -0.09998018]\n",
      "[ 0.58868874  0.55961716 -0.51027536 -0.79004771  0.16425345]\n",
      "Step 100, Loss: 0.1634901911020279, Inputs: [0.56849927, 0.34268212, -0.5015732, -0.6459669, 0.21415529]\n",
      "[ 0.58868874  0.55961716 -0.51027536 -0.79004771  0.16425345]\n",
      "Step 200, Loss: 0.16377514600753784, Inputs: [0.5880645, 0.37871456, -0.4649804, -0.6828319, 0.19278687]\n",
      "[ 0.58868874  0.55961716 -0.51027536 -0.79004771  0.16425345]\n",
      "Step 300, Loss: 0.1650012582540512, Inputs: [0.6147251, 0.43788865, -0.4802487, -0.69540966, 0.16421673]\n",
      "[ 0.58868874  0.55961716 -0.51027536 -0.79004771  0.16425345]\n",
      "Step 400, Loss: 0.1642158180475235, Inputs: [0.5923019, 0.4312809, -0.4665092, -0.7332488, 0.15792477]\n",
      "[ 0.58868874  0.55961716 -0.51027536 -0.79004771  0.16425345]\n",
      "Error is:  18.84686781574304\n",
      "Step 0, Loss: 0.24407677352428436, Inputs: [0.5999938, 0.5998198, -0.09999387, -0.09998601, -0.09998903]\n",
      "[ 0.38298075  0.5002671  -1.12356752 -0.22708049  0.36133997]\n",
      "Step 100, Loss: 0.18495702743530273, Inputs: [0.2965443, 1.5202551, -1.1836216, -0.701413, 0.26506063]\n",
      "[ 0.38298075  0.5002671  -1.12356752 -0.22708049  0.36133997]\n",
      "Step 200, Loss: 0.18302594125270844, Inputs: [0.42219535, 1.0007576, -1.0807357, -0.40595964, 0.28233537]\n",
      "[ 0.38298075  0.5002671  -1.12356752 -0.22708049  0.36133997]\n",
      "Step 300, Loss: 0.18439818918704987, Inputs: [0.3632852, 1.1106896, -1.1012417, -0.50661355, 0.25749713]\n",
      "[ 0.38298075  0.5002671  -1.12356752 -0.22708049  0.36133997]\n",
      "Step 400, Loss: 0.18355798721313477, Inputs: [0.36742893, 1.0687141, -1.0868106, -0.38700497, 0.258619]\n",
      "[ 0.38298075  0.5002671  -1.12356752 -0.22708049  0.36133997]\n",
      "Error is:  47.20645125858995\n",
      "Step 0, Loss: 0.33935874700546265, Inputs: [0.4000069, 0.40015554, -0.098241806, -0.0999903, 0.09999031]\n",
      "[ 0.17289079  0.31792351 -0.57628478 -1.03636561  1.17976907]\n",
      "Step 100, Loss: 0.2625768482685089, Inputs: [0.15785766, 0.37872878, -0.5895394, -1.0680845, 1.1436164]\n",
      "[ 0.17289079  0.31792351 -0.57628478 -1.03636561  1.17976907]\n",
      "Step 200, Loss: 0.26244986057281494, Inputs: [0.13907985, 0.34010148, -0.58251673, -1.0650537, 1.1865567]\n",
      "[ 0.17289079  0.31792351 -0.57628478 -1.03636561  1.17976907]\n",
      "Step 300, Loss: 0.2612112760543823, Inputs: [0.1579007, 0.3550516, -0.60184485, -1.0200933, 1.1667993]\n",
      "[ 0.17289079  0.31792351 -0.57628478 -1.03636561  1.17976907]\n",
      "Step 400, Loss: 0.26154327392578125, Inputs: [0.166134, 0.36916456, -0.5881106, -1.0684106, 1.1513346]\n",
      "[ 0.17289079  0.31792351 -0.57628478 -1.03636561  1.17976907]\n",
      "Error is:  3.8801773531081856\n",
      "Step 0, Loss: 0.2797040641307831, Inputs: [0.4000296, 0.400684, 0.099993266, 0.09998835, 0.09998573]\n",
      "[0.3251041  0.62799371 0.4110494  0.13641419 0.3090593 ]\n",
      "Step 100, Loss: 0.2405458390712738, Inputs: [0.22953622, 1.1987976, 0.32465243, 0.27453044, 0.46025628]\n",
      "[0.3251041  0.62799371 0.4110494  0.13641419 0.3090593 ]\n",
      "Step 200, Loss: 0.24155963957309723, Inputs: [0.27092814, 1.1171951, 0.33844128, 0.25212434, 0.44949052]\n",
      "[0.3251041  0.62799371 0.4110494  0.13641419 0.3090593 ]\n",
      "Step 300, Loss: 0.24041444063186646, Inputs: [0.22397402, 1.1630659, 0.33995718, 0.27008432, 0.4032878]\n",
      "[0.3251041  0.62799371 0.4110494  0.13641419 0.3090593 ]\n",
      "Step 400, Loss: 0.2409742921590805, Inputs: [0.24695739, 1.1884421, 0.3380538, 0.29951176, 0.40859035]\n",
      "[0.3251041  0.62799371 0.4110494  0.13641419 0.3090593 ]\n",
      "Error is:  54.2104454468459\n",
      "Step 0, Loss: 0.3795450031757355, Inputs: [0.59995466, 0.5998968, 0.09999379, -0.099986136, 0.0999907]\n",
      "[ 0.21782438  0.6861045   0.88028349 -0.58658575 -0.08523464]\n",
      "Step 100, Loss: 0.3251937925815582, Inputs: [0.17220679, 0.99777424, 0.86466235, -1.0606263, -0.059731547]\n",
      "[ 0.21782438  0.6861045   0.88028349 -0.58658575 -0.08523464]\n",
      "Step 200, Loss: 0.32360222935676575, Inputs: [0.19402744, 1.0278112, 0.8658143, -1.1203692, -0.033911504]\n",
      "[ 0.21782438  0.6861045   0.88028349 -0.58658575 -0.08523464]\n",
      "Step 300, Loss: 0.32505956292152405, Inputs: [0.18257006, 1.0199162, 0.862426, -1.1746438, -0.032987177]\n",
      "[ 0.21782438  0.6861045   0.88028349 -0.58658575 -0.08523464]\n",
      "Step 400, Loss: 0.3249535858631134, Inputs: [0.21520482, 1.0162785, 0.88330513, -1.1872841, -0.083470814]\n",
      "[ 0.21782438  0.6861045   0.88028349 -0.58658575 -0.08523464]\n",
      "Error is:  47.7477487661637\n",
      "The mean percent error is:  33.57008500387465\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(10):\n",
    "    line = new_data.iloc[i]\n",
    "    correct_output = line[output_keys].array\n",
    "    parameters = {key: line[key] for key in input_keys}\n",
    "    input_vars = {key: tf.Variable(value, dtype=tf.float32) for key, value in initial_guess.items()}\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "\n",
    "    def model_loss(target):\n",
    "        # Pass the variables through the model to get the predicted output\n",
    "        model_inputs = {key: tf.expand_dims(input_vars[key], 0) for key in input_keys}\n",
    "        predicted_outputs = model(model_inputs, training=False)\n",
    "\n",
    "        # Calculate the loss between predicted and target outputs\n",
    "        loss = tf.reduce_mean(tf.abs(predicted_outputs - target))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    for step in range(500):  # Adjust the number of steps as needed\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = model_loss(correct_output)\n",
    "\n",
    "        # Compute the gradients of the loss with respect to the input variables\n",
    "        grads = tape.gradient(loss, input_vars.values())\n",
    "\n",
    "        # Apply the gradients to the input variables\n",
    "        optimizer.apply_gradients(zip(grads, input_vars.values()))\n",
    "\n",
    "        # Print the loss and current input variables every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy()}, Inputs: {[input_vars[key].numpy() for key in input_keys]}\")\n",
    "            print(np.array(list(parameters.values())))\n",
    "\n",
    "    optimized_inputs = {key: var.numpy() for key, var in input_vars.items()}\n",
    "\n",
    "    optimized_inputs = np.array(list(optimized_inputs.values()))\n",
    "    parameters = np.array(list(parameters.values()))\n",
    "\n",
    "    # optimized_inputs = optimized_inputs[:-1]\n",
    "    # parameters = parameters[:-1]\n",
    "\n",
    "\n",
    "    error = estimator.percent_error(optimized_inputs,parameters)\n",
    "    errors.append(error)\n",
    "    print(\"Error is: \", error * 100)\n",
    "print(\"The mean percent error is: \", np.mean(errors) * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "Predicted values:  0.25585717\n",
      "Correct values:  <PandasArray>\n",
      "[ 1.109304248656438, 0.1669449844863293,  1.361796655829442,\n",
      "  1.612846174712094, -0.643076477415179]\n",
      "Length: 5, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[158], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPredicted values: \u001B[39m\u001B[38;5;124m\"\u001B[39m, predictions[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCorrect values: \u001B[39m\u001B[38;5;124m\"\u001B[39m, correct_output)\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe mean squared error is: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0.3\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(\u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcorrect_output\u001B[49m) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     13\u001B[0m error \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mpercent_error(predictions[\u001B[38;5;241m0\u001B[39m], correct_output)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe percent error is: \u001B[39m\u001B[38;5;124m\"\u001B[39m, error \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\arrays\\numpy_.py:145\u001B[0m, in \u001B[0;36mPandasArray.__array_ufunc__\u001B[1;34m(self, ufunc, method, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array_ufunc__\u001B[39m(\u001B[38;5;28mself\u001B[39m, ufunc: np\u001B[38;5;241m.\u001B[39mufunc, method: \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;66;03m# Lightly modified version of\u001B[39;00m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;66;03m# https://numpy.org/doc/stable/reference/generated/numpy.lib.mixins.NDArrayOperatorsMixin.html\u001B[39;00m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;66;03m# The primary modification is not boxing scalar return values\u001B[39;00m\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;66;03m# in PandasArray, since pandas' ExtensionArrays are 1-d.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m     out \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m\"\u001B[39m, ())\n\u001B[1;32m--> 145\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_dispatch_ufunc_to_dunder_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mufunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m    149\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx:113\u001B[0m, in \u001B[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m     79\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[1;32m---> 81\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:198\u001B[0m, in \u001B[0;36mOpsMixin.__rsub__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__rsub__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__rsub__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m--> 198\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mroperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrsub\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\arrays\\numpy_.py:445\u001B[0m, in \u001B[0;36mPandasArray._cmp_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m    443\u001B[0m other \u001B[38;5;241m=\u001B[39m ensure_wrapped_if_datetimelike(other)\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 445\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mpd_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ndarray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m op \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mdivmod\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m op \u001B[38;5;129;01mis\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mrdivmod:\n\u001B[0;32m    448\u001B[0m     a, b \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001B[0m, in \u001B[0;36marithmetic_op\u001B[1;34m(left, right, op)\u001B[0m\n\u001B[0;32m    228\u001B[0m     _bool_arith_check(op, left, right)\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001B[39;00m\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001B[39;00m\n\u001B[1;32m--> 232\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43m_na_arithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[1;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[0;32m    168\u001B[0m     func \u001B[38;5;241m=\u001B[39m partial(expressions\u001B[38;5;241m.\u001B[39mevaluate, op)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 171\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cmp \u001B[38;5;129;01mand\u001B[39;00m (is_object_dtype(left\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(right)):\n\u001B[0;32m    174\u001B[0m         \u001B[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001B[39;00m\n\u001B[0;32m    175\u001B[0m         \u001B[38;5;66;03m#  on the non-missing values)\u001B[39;00m\n\u001B[0;32m    176\u001B[0m         \u001B[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001B[39;00m\n\u001B[0;32m    177\u001B[0m         \u001B[38;5;66;03m#  incorrectly, see GH#32047\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(op, a, b, use_numexpr)\u001B[0m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m op_str \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_numexpr:\n\u001B[0;32m    238\u001B[0m         \u001B[38;5;66;03m# error: \"None\" not callable\u001B[39;00m\n\u001B[1;32m--> 239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001B[0m, in \u001B[0;36m_evaluate_standard\u001B[1;34m(op, op_str, a, b)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _TEST_MODE:\n\u001B[0;32m     69\u001B[0m     _store_test_result(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\pandas\\core\\roperator.py:15\u001B[0m, in \u001B[0;36mrsub\u001B[1;34m(left, right)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrsub\u001B[39m(left, right):\n\u001B[1;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mright\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mleft\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (8,) (5,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import estimator\n",
    "\n",
    "new_data = pd.read_csv(\"C:\\Projects\\Crosstalk\\Machine_Learning\\Data/2024-08-28_14-31/test.csv\")\n",
    "first_line = new_data.iloc[10]\n",
    "correct_output = first_line[['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]].array\n",
    "#input_data = {key: [first_line[key]] for key in inputs}\n",
    "input_data = {key: np.array([first_line[key]]) for key in inputs}\n",
    "predictions = model.predict(input_data)\n",
    "print(\"Predicted values: \", predictions[0][0])\n",
    "print(\"Correct values: \", correct_output)\n",
    "print(\"the mean squared error is: \", 0.3 * np.linalg.norm(predictions[0] - correct_output) ** 2)\n",
    "error = estimator.percent_error(predictions[0], correct_output)\n",
    "print(\"The percent error is: \", error * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(len(new_data)):\n",
    "    line = new_data.iloc[i]\n",
    "\n",
    "    correct_output = line[['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]].array\n",
    "\n",
    "    input_data = {key: np.array([line[key]]) for key in inputs}\n",
    "    predictions = model.predict(input_data)\n",
    "    error.append(estimator.percent_error(predictions[0], correct_output))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean percent error is:  56.559793507707965\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean percent error is: \", np.mean(error) * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "error_dict = {key: [] for key in ['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]}\n",
    "\n",
    "for i in range(len(new_data)):\n",
    "    line = new_data.iloc[i]\n",
    "\n",
    "    correct_output = line[['decay_0', 'decay_1', 'W_0', 'W_1', \"J_0\"]].array\n",
    "\n",
    "    input_data = {key: np.array([line[key]]) for key in inputs}\n",
    "    predictions = model.predict(input_data)\n",
    "\n",
    "    # Calculate the percent error for each output key and append it to the respective list\n",
    "    for j, key in enumerate(error_dict.keys()):\n",
    "        error_dict[key].append(estimator.percent_error(predictions[0][0][j], correct_output[j]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# Initialize a dictionary to hold the error lists for each output key\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean error for decay_0 is: 21.14048892259431 precent\n",
      "The mean error for decay_1 is: 29.513848007879584 precent\n",
      "The mean error for W_0 is: 408.22536167818157 precent\n",
      "The mean error for W_1 is: 32.036623575115335 precent\n",
      "The mean error for J_0 is: 8072.218115692011 precent\n",
      "total error is:  1712.6268875751566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the error dictionary to a DataFrame\n",
    "error_df = pd.DataFrame(error_dict)\n",
    "\n",
    "# Calculate the mean of each error\n",
    "mean_errors = error_df.mean()\n",
    "\n",
    "# Display the results\n",
    "for key, value in mean_errors.items():\n",
    "    print(f\"The mean error for {key} is: {value * 100} precent\")\n",
    "\n",
    "print(\"total error is: \", mean_errors.mean() * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcustom_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorrect_output\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      2\u001B[0m a \u001B[38;5;241m=\u001B[39m custom_loss(predictions[\u001B[38;5;241m0\u001B[39m], correct_output)\n",
      "Cell \u001B[1;32mIn[5], line 44\u001B[0m, in \u001B[0;36mcustom_loss\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Compute the functions based on the given expressions\u001B[39;00m\n\u001B[0;32m     35\u001B[0m f_true \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     36\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m W_true[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_true[\u001B[38;5;241m0\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     37\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_true[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;241m-\u001B[39m(tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m (J_true[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_true[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_true[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     41\u001B[0m ]\n\u001B[0;32m     43\u001B[0m f_pred \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m---> 44\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(\u001B[43mt_values\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mW_pred\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m0\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     45\u001B[0m     (tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39mcos(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;241m-\u001B[39m(tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m W_pred[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m0\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\n\u001B[0;32m     47\u001B[0m         \u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;241m-\u001B[39m(tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m+\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(t_values \u001B[38;5;241m*\u001B[39m (J_pred[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m W_pred[\u001B[38;5;241m1\u001B[39m]))) \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mA_pred[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m t_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     49\u001B[0m ]\n\u001B[0;32m     51\u001B[0m \u001B[38;5;66;03m# Compute the absolute difference between the true and predicted functions\u001B[39;00m\n\u001B[0;32m     52\u001B[0m loss_t \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_sum([tf\u001B[38;5;241m.\u001B[39mabs(ft \u001B[38;5;241m-\u001B[39m fp) \u001B[38;5;28;01mfor\u001B[39;00m ft, fp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(f_true, f_pred)], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Crosstalk\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   5981\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[0;32m   5982\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m-> 5983\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul] name: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(custom_loss(predictions[0], correct_output))\n",
    "a = custom_loss(predictions[0], correct_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
